{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "driverTransformers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPqgrbIx4x6EfpLqT+ObVvX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhruvaBansal00/ConfidentMT/blob/master/driverTransformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgXrhFN_g0aC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd drive/My Drive/ConfidentMachineTranslation/flores\n",
        "!pwd\n",
        "!ls\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/ConfidentMachineTranslation/flores/src/')\n",
        "!pip install fairseq sacrebleu sentencepiece fastBPE sacremoses xgboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvO2MafPg_l7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prints how much GPU RAM is available\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9Dw5oxhhHYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Methods for CLI with fairseq - WIP\n",
        "import os\n",
        "import glob\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "class FairseqWrapper:\n",
        "\n",
        "    def runFairseqGenerate(self, dataFolder, sourceLang, targetLang, fwModel, beam, lenpen, dataSet, removeBpe, saveFile):\n",
        "        !fairseq-generate $dataFolder --source-lang $sourceLang --target-lang $targetLang \\\n",
        "        --path $fwModel --beam $beam --lenpen $lenpen --gen-subset $dataSet --remove-bpe=$removeBpe --sacrebleu > $saveFile\n",
        "\n",
        "    def runFairseqScore(self, translations, groundTruth, saveFile, metric):\n",
        "        !fairseq-score --sys $translations --ref $groundTruth --$metric > $saveFile\n",
        "    \n",
        "    def runFairseqPreprocessLM(self, srcdict, preprocCommand, bpeTranslations, dest):\n",
        "        !fairseq-preprocess --only-source --srcdict $srcdict --$preprocCommand $bpeTranslations \\\n",
        "        --destdir $dest --workers 20\n",
        "    \n",
        "    def runFairseqPreprocessBinarize(self, srcLang, trgLang, srcdict, preprocCommand, bpeTranslations, destdir):\n",
        "        !fairseq-preprocess --source-lang $srcLang --target-lang $trgLang --srcdict $srcdict\\\n",
        "        --$preprocCommand $bpeTranslations --destdir $destdir --joined-dictionary --workers 20\n",
        "\n",
        "    def runFairseqEvalLM(self, preprocFile, lmModel, batchSize, maxTokens, dataSet, saveFile):\n",
        "        !fairseq-eval-lm $preprocFile --path $lmModel --batch-size $batchSize --max-tokens $maxTokens \\\n",
        "        --output-word-probs --sample-break-mode eos --gen-subset $dataSet > $saveFile\n",
        "\n",
        "    def deleteFolder(self, folder):\n",
        "        print(\"Deleting contents in folder: \" + str(folder))\n",
        "        for f in tqdm(glob.glob(folder)):\n",
        "            !rm $f\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fh8j0C1hIQb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "10720a93-86e8-49c4-a314-9059da2b9d00"
      },
      "source": [
        "import translationUtils\n",
        "from translation import Translation\n",
        "import dataUtils\n",
        "import classification\n",
        "import thresholding\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import regression\n",
        "import transformerUtils \n",
        "\n",
        "trainTranslations = dataUtils.createObjectsFromFile(\"valid\")\n",
        "testTranslations = dataUtils.createObjectsFromFile(\"test\")\n",
        "\n",
        "print(\"Train elements = \" + str(len(trainTranslations)))\n",
        "print(\"Test elements = \" + str(len(testTranslations)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train elements = 2559\n",
            "Test elements = 2835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsxTc9NeGolz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "1aafdeb5-a06b-41f6-c890-6fcb36252d7e"
      },
      "source": [
        "params = {\n",
        "    'hidden_dim': 128,\n",
        "    'num_heads': 2,\n",
        "    'feedforward_dim': 2048,\n",
        "    'dim_k': 96,\n",
        "    'dim_v': 96,\n",
        "    'dim_q': 96,\n",
        "    'max_length': 100,\n",
        "    'batch_size': 100,\n",
        "    'verbosity': 1,\n",
        "    'lr': 5e-3,\n",
        "    'eps': 1e-8,\n",
        "    'epochs': 25\n",
        "}\n",
        "model = transformerUtils.getClassifierTransformer(trainTranslations, testTranslations, 15, params)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time = 0.6627747535705566, epoch 1, loss = 34.73843765258789, 39.76651692390442 seconds per 1 epochs\n",
            "time = 1.3315394918123882, epoch 2, loss = 13.549247741699219, 40.12575650215149 seconds per 1 epochs\n",
            "time = 1.998296860853831, epoch 3, loss = 13.515931129455566, 40.005321979522705 seconds per 1 epochs\n",
            "time = 2.6677593986193338, epoch 4, loss = 13.178577423095703, 40.16760540008545 seconds per 1 epochs\n",
            "time = 3.3306435028711956, epoch 5, loss = 13.123237609863281, 39.772926330566406 seconds per 1 epochs\n",
            "time = 3.991691835721334, epoch 6, loss = 12.826220512390137, 39.66277456283569 seconds per 1 epochs\n",
            "time = 4.647988299528758, epoch 7, loss = 12.177009582519531, 39.377650022506714 seconds per 1 epochs\n",
            "time = 5.309111400445302, epoch 8, loss = 11.250484466552734, 39.6672739982605 seconds per 1 epochs\n",
            "time = 5.962142479419708, epoch 9, loss = 10.085058212280273, 39.181755781173706 seconds per 1 epochs\n",
            "time = 6.618878515561422, epoch 10, loss = 6.109194278717041, 39.40397906303406 seconds per 1 epochs\n",
            "time = 7.270962822437286, epoch 11, loss = 3.8461012840270996, 39.125030279159546 seconds per 1 epochs\n",
            "time = 7.922711710135142, epoch 12, loss = 5.328978538513184, 39.10477113723755 seconds per 1 epochs\n",
            "time = 8.5752077460289, epoch 13, loss = 5.529305934906006, 39.14943814277649 seconds per 1 epochs\n",
            "time = 9.225506202379863, epoch 14, loss = 9.06325626373291, 39.01766014099121 seconds per 1 epochs\n",
            "time = 9.881015149752299, epoch 15, loss = 4.426951885223389, 39.330406665802 seconds per 1 epochs\n",
            "time = 10.531964969635009, epoch 16, loss = 4.283048629760742, 39.0568323135376 seconds per 1 epochs\n",
            "time = 11.178951255480449, epoch 17, loss = 3.276850461959839, 38.81903409957886 seconds per 1 epochs\n",
            "time = 11.822094118595123, epoch 18, loss = 2.2566587924957275, 38.588451623916626 seconds per 1 epochs\n",
            "time = 12.466437021891275, epoch 19, loss = 2.204657793045044, 38.660428047180176 seconds per 1 epochs\n",
            "time = 13.108515314261119, epoch 20, loss = 2.1497273445129395, 38.52458143234253 seconds per 1 epochs\n",
            "time = 13.754809927940368, epoch 21, loss = 2.239152431488037, 38.77756404876709 seconds per 1 epochs\n",
            "time = 14.39606210788091, epoch 22, loss = 2.8798508644104004, 38.47498536109924 seconds per 1 epochs\n",
            "time = 15.042820473512014, epoch 23, loss = 3.3032472133636475, 38.80536866188049 seconds per 1 epochs\n",
            "time = 15.687486759821574, epoch 24, loss = 2.914846181869507, 38.679855823516846 seconds per 1 epochs\n",
            "time = 16.33607801993688, epoch 25, loss = 3.1462368965148926, 38.91533327102661 seconds per 1 epochs\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}