{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "driverTransformers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNw2BpYpA3YAXEPEx+jtiTn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhruvaBansal00/ConfidentMT/blob/master/driverTransformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgXrhFN_g0aC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "512c5c31-7469-4d3e-d061-7f377ae993a2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd drive/My Drive/ConfidentMachineTranslation/flores\n",
        "!pwd\n",
        "!ls\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/ConfidentMachineTranslation/flores/src/')\n",
        "!pip install fairseq sacrebleu sentencepiece fastBPE sacremoses xgboost"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/ConfidentMachineTranslation/flores\n",
            "/content/drive/My Drive/ConfidentMachineTranslation/flores\n",
            "analysis\t       DeprecatedColabScripts\t prepare-sien.sh\n",
            "backward_models        driver.ipynb\t\t Resources\n",
            "checkpoints\t       driverTransformers.ipynb  scripts\n",
            "ClassificationDataset  Ensembles\t\t sentencepiece_models\n",
            "configs\t\t       language_models\t\t src\n",
            "data\t\t       LoadEn-Si.ipynb\n",
            "data-bin\t       noisychannel\n",
            "Requirement already satisfied: fairseq in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (1.4.12)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.91)\n",
            "Requirement already satisfied: fastBPE in /usr/local/lib/python3.6/dist-packages (0.1.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (0.0.43)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.5.1+cu101)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.41.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.20)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (1.7.0)\n",
            "Requirement already satisfied: mecab-python3==0.996.5 in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (0.996.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses) (0.15.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvO2MafPg_l7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "cd0c391e-e3d0-4931-f77a-f8f601114e8f"
      },
      "source": [
        "# prints how much GPU RAM is available\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  | Proc size: 159.5 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9Dw5oxhhHYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Methods for CLI with fairseq - WIP\n",
        "import os\n",
        "import glob\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "class FairseqWrapper:\n",
        "\n",
        "    def runFairseqGenerate(self, dataFolder, sourceLang, targetLang, fwModel, beam, lenpen, dataSet, removeBpe, saveFile):\n",
        "        !fairseq-generate $dataFolder --source-lang $sourceLang --target-lang $targetLang \\\n",
        "        --path $fwModel --beam $beam --lenpen $lenpen --gen-subset $dataSet --remove-bpe=$removeBpe --sacrebleu > $saveFile\n",
        "\n",
        "    def runFairseqScore(self, translations, groundTruth, saveFile, metric):\n",
        "        !fairseq-score --sys $translations --ref $groundTruth --$metric > $saveFile\n",
        "    \n",
        "    def runFairseqPreprocessLM(self, srcdict, preprocCommand, bpeTranslations, dest):\n",
        "        !fairseq-preprocess --only-source --srcdict $srcdict --$preprocCommand $bpeTranslations \\\n",
        "        --destdir $dest --workers 20\n",
        "    \n",
        "    def runFairseqPreprocessBinarize(self, srcLang, trgLang, srcdict, preprocCommand, bpeTranslations, destdir):\n",
        "        !fairseq-preprocess --source-lang $srcLang --target-lang $trgLang --srcdict $srcdict\\\n",
        "        --$preprocCommand $bpeTranslations --destdir $destdir --joined-dictionary --workers 20\n",
        "\n",
        "    def runFairseqEvalLM(self, preprocFile, lmModel, batchSize, maxTokens, dataSet, saveFile):\n",
        "        !fairseq-eval-lm $preprocFile --path $lmModel --batch-size $batchSize --max-tokens $maxTokens \\\n",
        "        --output-word-probs --sample-break-mode eos --gen-subset $dataSet > $saveFile\n",
        "\n",
        "    def deleteFolder(self, folder):\n",
        "        print(\"Deleting contents in folder: \" + str(folder))\n",
        "        for f in tqdm(glob.glob(folder)):\n",
        "            !rm $f\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fh8j0C1hIQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import translationUtils\n",
        "from translation import Translation\n",
        "import dataUtils\n",
        "import classification\n",
        "import thresholding\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import regression\n",
        "import transformerUtils \n",
        "\n",
        "trainTranslations = dataUtils.createObjectsFromFile(\"valid\")\n",
        "testTranslations = dataUtils.createObjectsFromFile(\"test\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maOAQ-qVnT-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainData, trainLabels, testData, testLabels = transformerUtils.createDataset(trainTranslations, testTranslations, 15)"
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}