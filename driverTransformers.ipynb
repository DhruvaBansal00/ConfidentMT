{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "driverTransformers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPNInfHQimotYOMsBLH+hLL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhruvaBansal00/ConfidentMT/blob/master/driverTransformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgXrhFN_g0aC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd drive/My Drive/ConfidentMachineTranslation/flores\n",
        "!pwd\n",
        "!ls\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/ConfidentMachineTranslation/flores/src/')\n",
        "!pip install fairseq sacrebleu sentencepiece fastBPE sacremoses xgboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvO2MafPg_l7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prints how much GPU RAM is available\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9Dw5oxhhHYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Methods for CLI with fairseq - WIP\n",
        "import os\n",
        "import glob\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "class FairseqWrapper:\n",
        "\n",
        "    def runFairseqGenerate(self, dataFolder, sourceLang, targetLang, fwModel, beam, lenpen, dataSet, removeBpe, saveFile):\n",
        "        !fairseq-generate $dataFolder --source-lang $sourceLang --target-lang $targetLang \\\n",
        "        --path $fwModel --beam $beam --lenpen $lenpen --gen-subset $dataSet --remove-bpe=$removeBpe --sacrebleu > $saveFile\n",
        "\n",
        "    def runFairseqScore(self, translations, groundTruth, saveFile, metric):\n",
        "        !fairseq-score --sys $translations --ref $groundTruth --$metric > $saveFile\n",
        "    \n",
        "    def runFairseqPreprocessLM(self, srcdict, preprocCommand, bpeTranslations, dest):\n",
        "        !fairseq-preprocess --only-source --srcdict $srcdict --$preprocCommand $bpeTranslations \\\n",
        "        --destdir $dest --workers 20\n",
        "    \n",
        "    def runFairseqPreprocessBinarize(self, srcLang, trgLang, srcdict, preprocCommand, bpeTranslations, destdir):\n",
        "        !fairseq-preprocess --source-lang $srcLang --target-lang $trgLang --srcdict $srcdict\\\n",
        "        --$preprocCommand $bpeTranslations --destdir $destdir --joined-dictionary --workers 20\n",
        "\n",
        "    def runFairseqEvalLM(self, preprocFile, lmModel, batchSize, maxTokens, dataSet, saveFile):\n",
        "        !fairseq-eval-lm $preprocFile --path $lmModel --batch-size $batchSize --max-tokens $maxTokens \\\n",
        "        --output-word-probs --sample-break-mode eos --gen-subset $dataSet > $saveFile\n",
        "\n",
        "    def deleteFolder(self, folder):\n",
        "        print(\"Deleting contents in folder: \" + str(folder))\n",
        "        for f in tqdm(glob.glob(folder)):\n",
        "            !rm $f\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fh8j0C1hIQb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "10720a93-86e8-49c4-a314-9059da2b9d00"
      },
      "source": [
        "import translationUtils\n",
        "from translation import Translation\n",
        "import dataUtils\n",
        "import classification\n",
        "import thresholding\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import regression\n",
        "import transformerUtils \n",
        "\n",
        "trainTranslations = dataUtils.createObjectsFromFile(\"valid\")\n",
        "testTranslations = dataUtils.createObjectsFromFile(\"test\")\n",
        "\n",
        "print(\"Train elements = \" + str(len(trainTranslations)))\n",
        "print(\"Test elements = \" + str(len(testTranslations)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train elements = 2559\n",
            "Test elements = 2835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maOAQ-qVnT-j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "11cc74d0-da59-4586-b1d0-be176621999b"
      },
      "source": [
        "# trainData, trainLabels, testData, testLabels = transformerUtils.createDataset(trainTranslations, testTranslations, 15)\n",
        "params = {\n",
        "    'hidden_dim': 128,\n",
        "    'num_heads': 2,\n",
        "    'feedforward_dim': 2048,\n",
        "    'dim_k': 96,\n",
        "    'dim_v': 96,\n",
        "    'dim_q': 96,\n",
        "    'max_length': 100,\n",
        "    'batch_size': 100,\n",
        "    'verbosity': 1,\n",
        "    'lr': 5e-3,\n",
        "    'eps': 1e-8,\n",
        "    'epochs': 25\n",
        "}\n",
        "model = getClassifierTransformer(trainTranslations, testTranslations, 15, params)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time = 0.6481467723846436, epoch 1, loss = 34.73843765258789, 38.888832330703735 seconds per 1 epochs\n",
            "time = 1.300710348288218, epoch 2, loss = 13.549247741699219, 39.15369486808777 seconds per 1 epochs\n",
            "time = 1.9477315147717793, epoch 3, loss = 13.515931129455566, 38.821170806884766 seconds per 1 epochs\n",
            "time = 2.5998766819636026, epoch 4, loss = 13.178577423095703, 39.12850093841553 seconds per 1 epochs\n",
            "time = 3.251638913154602, epoch 5, loss = 13.123237609863281, 39.10564565658569 seconds per 1 epochs\n",
            "time = 3.8979650775591534, epoch 6, loss = 12.826220512390137, 38.77893543243408 seconds per 1 epochs\n",
            "time = 4.540868882338206, epoch 7, loss = 12.177009582519531, 38.57411766052246 seconds per 1 epochs\n",
            "time = 5.185441148281098, epoch 8, loss = 11.250484466552734, 38.674113512039185 seconds per 1 epochs\n",
            "time = 5.834098366896312, epoch 9, loss = 10.085058212280273, 38.919265031814575 seconds per 1 epochs\n",
            "time = 6.485586508115133, epoch 10, loss = 6.109194278717041, 39.08917474746704 seconds per 1 epochs\n",
            "time = 7.138306987285614, epoch 11, loss = 3.8461012840270996, 39.1630961894989 seconds per 1 epochs\n",
            "time = 7.782161593437195, epoch 12, loss = 5.328978538513184, 38.631123065948486 seconds per 1 epochs\n",
            "time = 8.436665646235149, epoch 13, loss = 5.529305934906006, 39.2701313495636 seconds per 1 epochs\n",
            "time = 9.089281503359476, epoch 14, loss = 9.06325626373291, 39.15684914588928 seconds per 1 epochs\n",
            "time = 9.742530882358551, epoch 15, loss = 4.426951885223389, 39.194830656051636 seconds per 1 epochs\n",
            "time = 10.387870121002198, epoch 16, loss = 4.283048629760742, 38.720252990722656 seconds per 1 epochs\n",
            "time = 11.034452652931213, epoch 17, loss = 3.276850461959839, 38.79482460021973 seconds per 1 epochs\n",
            "time = 11.682388949394227, epoch 18, loss = 2.2566587924957275, 38.87601971626282 seconds per 1 epochs\n",
            "time = 12.333330500125886, epoch 19, loss = 2.204657793045044, 39.05637001991272 seconds per 1 epochs\n",
            "time = 12.977052330970764, epoch 20, loss = 2.1497273445129395, 38.62323760986328 seconds per 1 epochs\n",
            "time = 13.626046892007192, epoch 21, loss = 2.239152431488037, 38.939430952072144 seconds per 1 epochs\n",
            "time = 14.27428145011266, epoch 22, loss = 2.8798508644104004, 38.89400601387024 seconds per 1 epochs\n",
            "time = 14.925744823614757, epoch 23, loss = 3.3032472133636475, 39.087552547454834 seconds per 1 epochs\n",
            "time = 15.572565297285715, epoch 24, loss = 2.914846181869507, 38.8088743686676 seconds per 1 epochs\n",
            "time = 16.22083026965459, epoch 25, loss = 3.1462368965148926, 38.89568471908569 seconds per 1 epochs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsxTc9NeGolz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1aafdeb5-a06b-41f6-c890-6fcb36252d7e"
      },
      "source": [
        "params = {\n",
        "    'hidden_dim': 128,\n",
        "    'num_heads': 2,\n",
        "    'feedforward_dim': 2048,\n",
        "    'dim_k': 96,\n",
        "    'dim_v': 96,\n",
        "    'dim_q': 96,\n",
        "    'max_length': 100,\n",
        "    'batch_size': 100,\n",
        "    'verbosity': 1,\n",
        "    'lr': 5e-3,\n",
        "    'eps': 1e-8,\n",
        "    'epochs': 25\n",
        "}\n",
        "model = transformerUtils.getClassifierTransformer(trainTranslations, testTranslations, 15, params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time = 0.6627747535705566, epoch 1, loss = 34.73843765258789, 39.76651692390442 seconds per 1 epochs\n",
            "time = 1.3315394918123882, epoch 2, loss = 13.549247741699219, 40.12575650215149 seconds per 1 epochs\n",
            "time = 1.998296860853831, epoch 3, loss = 13.515931129455566, 40.005321979522705 seconds per 1 epochs\n",
            "time = 2.6677593986193338, epoch 4, loss = 13.178577423095703, 40.16760540008545 seconds per 1 epochs\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}