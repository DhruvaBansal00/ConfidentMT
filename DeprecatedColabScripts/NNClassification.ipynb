{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNClassification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNj/uPE92BjQBOPG+wp/Q2d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhruvaBansal00/ConfidentMT/blob/master/NNClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kJduL4qg0Wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install torch==1.5.0 torchvision>=0.5.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySc4MwyPhcAX",
        "colab_type": "code",
        "outputId": "d47d414b-236d-43a1-9135-dd65aa5067ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip3 install numpy\n",
        "!pip3 install Pillow\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transform"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qZch9Aw_fMK",
        "colab_type": "code",
        "outputId": "d42b08a8-2e5c-42df-e092-5c079dfbdc63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!ls\n",
        "%cd drive/My Drive/ConfidentMachineTranslation/flores\n",
        "!ls\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "'=0.5.0'   drive   sample_data\n",
            "/content/drive/.shortcut-targets-by-id/1viBwZM7BIiD8O4LeU-9UQXyV82oTWqh6/ConfidentMachineTranslation/flores\n",
            "'=0.5.0'\t\t\t configs\t\t  language_models\n",
            " analysis\t\t\t data\t\t\t  LM_Thresholding.ipynb\n",
            " Analysis\t\t\t data-bin\t\t  NCD_Analysis.ipynb\n",
            " backward_models\t\t Ensembles\t\t  noisychannel\n",
            " BoostedBinaryClassifers.ipynb\t Ensembling\t\t  NoisyChannel.ipynb\n",
            " checkpoints\t\t\t FLORES.ipynb\t\t  Resources\n",
            " ClassificationDataset\t\t LanguageAnalysis.ipynb   scripts\n",
            "/content/drive/.shortcut-targets-by-id/1viBwZM7BIiD8O4LeU-9UQXyV82oTWqh6/ConfidentMachineTranslation/flores\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRR3lp2LBTlH",
        "colab_type": "code",
        "outputId": "bd9b8779-4caf-457b-9e57-f4eecc1fe8e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# prints how much GPU RAM is available\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 11.6 GB  | Proc size: 1.8 GB\n",
            "GPU RAM Free: 11124MB | Used: 317MB | Util   3% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkwS5N9DBdsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import zip_longest\n",
        "\n",
        "def datasetReader(featureFile, labelFile):\n",
        "    files = [featureFile, labelFile]\n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    for lines in zip_longest(*files, fillvalue=''):\n",
        "        currX, currY = lines[0], float(lines[1].strip(\"\\n\"))\n",
        "        Xarr = []\n",
        "        features = currX.split()\n",
        "        for feature in features:\n",
        "            Xarr.append(float(feature.strip(\",\").strip(\"\\n\")))\n",
        "        X.append(Xarr)\n",
        "        Y.append(currY)\n",
        "    \n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "def printDatasetClassProp(Y): \n",
        "    classes = {}\n",
        "    total = len(Y)\n",
        "    for i in Y:\n",
        "        if i in classes:\n",
        "            classes[i] += 1\n",
        "        else:\n",
        "            classes[i] = 1\n",
        "    \n",
        "    for cls in classes:\n",
        "        print(\"Proportion in class \" + str(cls) + \" = \" + str(classes[cls]/total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diVWzdfBBoab",
        "colab_type": "code",
        "outputId": "1ee4b356-fc38-4d8c-f5fc-1d2e922beade",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!ls\n",
        "!pip3 install numpy\n",
        "!pip install numpy\n",
        "import numpy as np\n",
        "trainFeatures = open(\"ClassificationDataset/valid/features.txt\")\n",
        "testFeatures = open(\"ClassificationDataset/test/features.txt\")\n",
        "\n",
        "trainLabels = open(\"ClassificationDataset/valid/result.txt\")\n",
        "testLabels = open(\"ClassificationDataset/test/result.txt\")\n",
        "\n",
        "trainX, trainY = datasetReader(trainFeatures, trainLabels)\n",
        "testX, testY = datasetReader(testFeatures, testLabels)\n",
        "printDatasetClassProp(trainY)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'=0.5.0'\t\t\t configs\t\t  language_models\n",
            " analysis\t\t\t data\t\t\t  LM_Thresholding.ipynb\n",
            " Analysis\t\t\t data-bin\t\t  NCD_Analysis.ipynb\n",
            " backward_models\t\t Ensembles\t\t  noisychannel\n",
            " BoostedBinaryClassifers.ipynb\t Ensembling\t\t  NoisyChannel.ipynb\n",
            " checkpoints\t\t\t FLORES.ipynb\t\t  Resources\n",
            " ClassificationDataset\t\t LanguageAnalysis.ipynb   scripts\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.4)\n",
            "Proportion in class 0.0 = 0.8014849550605705\n",
            "Proportion in class 1.0 = 0.19851504493942945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogxQAQDGPB7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class DatasetLoad(Dataset):\n",
        "  def __init__(self, X, Y):\n",
        "    self.x_data = X\n",
        "    self.y_data = Y\n",
        "    self.len = len(self.x_data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.x_data[index], self.y_data[index]\n",
        "        \n",
        "  def __len__(self):\n",
        "    return self.len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq8JFPKZBUSC",
        "colab_type": "code",
        "outputId": "437e4fbf-edde-415b-ddbe-23ded86526c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(trainX.shape, trainY.shape)\n",
        "#trainConcat = np.concatenate((trainX, trainY.reshape(trainY.shape[0], 1)), axis=1).shape\n",
        "trainSet = DatasetLoad(X=torch.from_numpy(trainX), Y=torch.from_numpy(trainY))\n",
        "trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=32, shuffle=True)\n",
        "\n",
        "#testConcat = np.concatenate((testX, testY.reshape(testY.shape[0], 1)), axis=1).shape\n",
        "testSet = DatasetLoad(X=torch.from_numpy(testX), Y=torch.from_numpy(testY))\n",
        "testLoader = torch.utils.data.DataLoader(testSet, batch_size=32, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2559, 20) (2559,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoZvCPL3McIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class sentenceBLEUClassifierModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(sentenceBLEUClassifierModel, self).__init__()\n",
        "    self.linear1 = nn.Linear(20, 160)\n",
        "    self.linear2 = nn.Linear(160, 80)\n",
        "    self.linear3 = nn.Linear(80, 2)\n",
        "  def forward(self, x):\n",
        "    x = self.linear1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.linear2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.linear3(x)\n",
        "    x = F.relu(x)\n",
        "    return F.softmax(x, dim=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63P-gSn9N8Cj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.0005\n",
        "num_epochs = 250\n",
        "batch_size = 32\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "model = sentenceBLEUClassifierModel()\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "def get_accuracy(logit, target, batch_size):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    corrects = (torch.max(logits.data, 1)[1].view(target.size()).data == target).sum().item()\n",
        "    accuracy = 100.0 * corrects/batch_size\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plOQF2hEOUjD",
        "colab_type": "code",
        "outputId": "907f54e0-7ce6-4e21-969b-3998a9a4ffd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    train_running_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "\n",
        "    model = model.train()\n",
        "\n",
        "    for i, (batch, label) in enumerate(trainLoader):\n",
        "        \n",
        "        batch = batch.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        ## forward + backprop + loss\n",
        "        logits = model(batch.float())\n",
        "        loss = criterion(logits, label.long())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        ## update model params\n",
        "        optimizer.step()\n",
        "\n",
        "        train_running_loss += loss.detach().item()\n",
        "        train_acc += get_accuracy(logits, label.float(), batch_size)\n",
        "    \n",
        "    model.eval()\n",
        "    print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \\\n",
        "          %(epoch, train_running_loss / i, train_acc/i)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 1 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 2 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 3 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 4 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 5 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 6 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 7 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 8 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 9 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 10 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 11 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 12 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 13 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 14 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 15 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 16 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 17 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 18 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 19 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 20 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 21 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 22 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 23 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 24 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 25 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 26 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 27 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 28 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 29 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 30 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 31 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 32 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 33 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 34 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 35 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 36 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 37 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 38 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 39 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 40 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 41 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 42 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 43 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 44 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 45 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 46 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 47 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 48 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 49 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 50 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 51 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 52 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 53 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 54 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 55 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 56 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 57 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 58 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 59 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 60 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 61 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 62 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 63 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 64 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 65 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 66 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 67 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 68 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 69 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 70 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 71 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 72 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 73 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 74 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 75 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 76 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 77 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 78 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 79 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 80 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 81 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 82 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 83 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 84 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 85 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 86 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 87 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 88 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 89 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 90 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 91 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 92 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 93 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 94 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 95 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 96 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 97 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 98 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 99 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 100 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 101 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 102 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 103 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 104 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 105 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 106 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 107 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 108 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 109 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 110 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 111 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 112 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 113 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 114 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 115 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 116 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 117 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 118 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 119 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 120 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 121 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 122 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 123 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 124 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 125 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 126 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 127 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 128 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 129 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 130 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 131 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 132 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 133 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 134 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 135 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 136 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 137 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 138 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 139 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 140 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 141 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 142 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 143 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 144 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 145 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 146 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 147 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 148 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 149 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 150 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 151 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 152 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 153 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 154 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 155 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 156 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 157 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 158 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 159 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 160 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 161 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 162 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 163 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 164 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 165 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 166 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 167 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 168 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 169 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 170 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 171 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 172 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 173 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 174 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 175 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 176 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 177 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 178 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 179 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 180 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 181 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 182 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 183 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 184 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 185 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 186 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 187 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 188 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 189 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 190 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 191 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 192 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 193 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 194 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 195 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 196 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 197 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 198 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 199 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 200 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 201 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 202 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 203 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 204 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 205 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 206 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 207 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 208 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 209 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 210 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 211 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 212 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 213 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 214 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 215 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 216 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 217 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 218 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 219 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 220 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 221 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 222 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 223 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 224 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 225 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 226 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 227 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 228 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 229 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 230 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 231 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 232 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 233 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 234 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 235 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 236 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 237 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 238 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 239 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 240 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 241 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 242 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 243 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 244 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 245 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 246 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 247 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 248 | Loss: 0.7019 | Train Accuracy: 81.13\n",
            "Epoch: 249 | Loss: 0.7019 | Train Accuracy: 81.13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ck-fLsGTeuc",
        "colab_type": "code",
        "outputId": "a020b716-75ac-4848-e0e1-e69d229a8e07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_acc = 0.0\n",
        "for i, (batch, label) in enumerate(testLoader):\n",
        "    batch = batch.to(device)\n",
        "    label = label.to(device)\n",
        "    outputs = model(batch.float())\n",
        "    test_acc += 100*(torch.max(outputs.data, 1)[1].view(label.size()).data == label).sum().item()/batch_size\n",
        "print('Test Accuracy: %.2f'%( test_acc/i))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 75.14\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}