{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FeatureSubsetBinaryClassifers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhruvaBansal00/ConfidentMT/blob/master/FeatureSubsetBinaryClassifers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEk99K4f0Hw_",
        "colab_type": "code",
        "outputId": "a4de6a27-71bf-4502-9f5c-16c2b8abfcec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!ls\n",
        "%cd drive/My Drive/ConfidentMachineTranslation/flores\n",
        "!ls\n",
        "!pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "drive  sample_data\n",
            "/content/drive/My Drive/ConfidentMachineTranslation/flores\n",
            "'=0.5.0'\t\t\t FeatureSubsetBinaryClassifers.ipynb\n",
            " analysis\t\t\t FLORES.ipynb\n",
            " Analysis\t\t\t LanguageAnalysis.ipynb\n",
            " backward_models\t\t language_models\n",
            " BoostedBinaryClassifers.ipynb\t LM_Thresholding.ipynb\n",
            " checkpoints\t\t\t NCD_Analysis.ipynb\n",
            " ClassificationDataset\t\t NNClassification.ipynb\n",
            " configs\t\t\t noisychannel\n",
            " data\t\t\t\t NoisyChannel.ipynb\n",
            " data-bin\t\t\t Resources\n",
            " Ensembles\t\t\t scripts\n",
            " Ensembling\n",
            "/content/drive/My Drive/ConfidentMachineTranslation/flores\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0LVqC0npSH1",
        "colab_type": "code",
        "outputId": "ae99dab1-1344-4ee0-8d73-c856a736c44e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "pip install fairseq sacrebleu sentencepiece"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fairseq\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/bf/de299e082e7af010d35162cb9a185dc6c17db71624590f2f379aeb2519ff/fairseq-0.9.0.tar.gz (306kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 2.6MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/9d/9846507837ca50ae20917f59d83b79246b8313bd19d4f5bf575ecb98132b/sacrebleu-1.4.9-py3-none-any.whl (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.7MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.18)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.18.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2019.12.20)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.5.0+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.41.1)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (0.16.0)\n",
            "Building wheels for collected packages: fairseq\n",
            "  Building wheel for fairseq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.9.0-cp36-cp36m-linux_x86_64.whl size=2021137 sha256=eb8425286fd69e17206ea1cff95313d84cceac4278392dde78a6159d95be3e7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/3e/1b/0fa30695dcba41e4b0088067fa40f3328d1e8ee78c22cd4766\n",
            "Successfully built fairseq\n",
            "Installing collected packages: portalocker, sacrebleu, fairseq, sentencepiece\n",
            "Successfully installed fairseq-0.9.0 portalocker-1.7.0 sacrebleu-1.4.9 sentencepiece-0.1.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlcgFl162kdH",
        "colab_type": "code",
        "outputId": "e1e2ed13-3a94-483f-d339-378b149624fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# prints how much GPU RAM is available\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=7adfac5c19ac21ab7a591250457d54fcc699fb6523e01f23aa71b9619a8fa07c\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  | Proc size: 159.5 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xwd7lNk3EZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "import numpy as np\n",
        "from itertools import zip_longest\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "class CustomEnsembleClassifier:\n",
        "    def __init__(self, clfs):\n",
        "        self.classifiers = clfs\n",
        "    \n",
        "    def predict(self, X):\n",
        "        probabilities = None\n",
        "        for clf in self.classifiers:\n",
        "            if probabilities is None:\n",
        "                probabilities = clf.predict_proba(X)\n",
        "            else:\n",
        "                probabilities += clf.predict_proba(X)\n",
        "        return np.argmax(np.array(probabilities), axis=1)\n",
        "\n",
        "\n",
        "\n",
        "def printDatasetClassProp(Y): \n",
        "    classes = {}\n",
        "    total = len(Y)\n",
        "    for i in Y:\n",
        "        if i in classes:\n",
        "            classes[i] += 1\n",
        "        else:\n",
        "            classes[i] = 1\n",
        "    \n",
        "    for cls in classes:\n",
        "        print(\"Proportion in class \" + str(cls) + \" = \" + str(classes[cls]/total))\n",
        "\n",
        "def datasetReader(featureFile, labelFile):\n",
        "    files = [featureFile, labelFile]\n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    for lines in zip_longest(*files, fillvalue=''):\n",
        "        currX, currY = lines[0], float(lines[1].strip(\"\\n\"))\n",
        "        Xarr = []\n",
        "        features = currX.split()\n",
        "        for feature in features:\n",
        "            Xarr.append(float(feature.strip(\",\").strip(\"\\n\")))\n",
        "        X.append(Xarr)\n",
        "        Y.append(currY)    \n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "\n",
        "def computeSimilarity(o1, o2):\n",
        "    total = len(o1)\n",
        "    same = 0\n",
        "    for i in range(len(o1)):\n",
        "        if o1[i] == o2[i]:\n",
        "            same += 1\n",
        "    print(same/total)\n",
        "\n",
        "\n",
        "def trainMLPClassifier(X, Y, verbose=True):\n",
        "    if verbose:\n",
        "        print(\"Training MLP Classifier\")\n",
        "    clf = MLPClassifier(hidden_layer_sizes=(64, 256, 512, 256, 64), random_state=42,\n",
        "                        max_iter=200, learning_rate='adaptive', learning_rate_init=0.0005, activation='relu')\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainKNeighborsClassifier(X, Y, verbose=True):\n",
        "    if verbose:\n",
        "        print(\"Training KNeighbors Classifier\")\n",
        "    clf = KNeighborsClassifier(100)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainGaussianProcessClassifier(X, Y, verbose=True):\n",
        "    if verbose:\n",
        "        print(\"Training Gaussian Process Classifier\")\n",
        "    length_scale = [1 for i in range(len(X[0]))]\n",
        "    clf = GaussianProcessClassifier(1.0 * RBF(length_scale), warm_start=True, random_state=42, n_jobs=-1)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainCustomEnsemble(X, Y, maxDepth=8, estimators=100, verbose=True):\n",
        "    if verbose:\n",
        "        print(\"Training custom ensemble\")\n",
        "    rf = RandomForestClassifier(max_depth=maxDepth, random_state=42)\n",
        "    grad = GradientBoostingClassifier(random_state=42)\n",
        "    ada = AdaBoostClassifier(n_estimators=estimators, random_state=42)\n",
        "    # dl = MLPClassifier(hidden_layer_sizes=(100), random_state=1, max_iter=200)\n",
        "    # kn = KNeighborsClassifier(100)\n",
        "\n",
        "    classifiers = [rf, grad, ada]\n",
        "\n",
        "    for clf in classifiers:\n",
        "        clf.fit(X, Y)\n",
        "\n",
        "    return CustomEnsembleClassifier(classifiers)\n",
        "    \n",
        "\n",
        "def trainEnsembleClassifier(X, Y, maxDepth=8, estimators=100, verbose=True):\n",
        "    if verbose:\n",
        "        print(\"Training an ensemble of Random Forest and Gradient Boosting Classifiers\")\n",
        "\n",
        "    estimators = [\n",
        "     ('rf', RandomForestClassifier(max_depth=maxDepth, random_state=42)),\n",
        "     ('grad', GradientBoostingClassifier(random_state=42))]\n",
        "    clf = StackingClassifier(estimators=estimators, final_estimator=AdaBoostClassifier(n_estimators=50, random_state=42))\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "\n",
        "def trainRandomForestClassifier(X, Y, maxDepth=8, verbose=True):\n",
        "    if verbose:\n",
        "        print(\"Training Random Forest classifier\")\n",
        "    clf = RandomForestClassifier(max_depth=maxDepth, random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainAdaBoostClassifier(X, Y, estimators=100, verbose=True):\n",
        "    if verbose:\n",
        "        print(\"Training AdaBoosted Decision Tree classifier\")\n",
        "    clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=estimators, random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainGradientBoostingClassifier(X, Y, verbose=True):\n",
        "    if verbose:\n",
        "        print(\"Training Graident Boosted classifier\")\n",
        "    clf = GradientBoostingClassifier(random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainSVM(X, Y, verbose=True):\n",
        "    if verbose:\n",
        "        print(\"Training SVM classifier\")\n",
        "    clf = SVC(gamma='auto')\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def calculateAccuracy(predictedClasses, groundTruth):\n",
        "    correct_accepted = 0\n",
        "    total_accepted = 0\n",
        "\n",
        "    correct_rejected = 0\n",
        "    total_rejected = 0\n",
        "\n",
        "    for i in range(len(predictedClasses)):\n",
        "        if groundTruth[i] == 1:\n",
        "            total_accepted += 1\n",
        "            if predictedClasses[i] == groundTruth[i]:\n",
        "                correct_accepted += 1\n",
        "        else:\n",
        "            total_rejected += 1\n",
        "            if predictedClasses[i] == groundTruth[i]:\n",
        "                correct_rejected += 1\n",
        "\n",
        "\n",
        "    print(\"Correctly accepted = \" + str(correct_accepted/total_accepted))\n",
        "    print(\"Incorrectly rejected = \" + str(1 - correct_accepted/total_accepted))\n",
        "    print(\"Correctly rejected = \" + str(correct_rejected/total_rejected))\n",
        "    print(\"Incorrectly accepted = \" + str(1 - correct_rejected/total_rejected))\n",
        "\n",
        "    print(\"Total Accuracy = \" + str((correct_accepted + correct_rejected)/(total_accepted + total_rejected)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_4LpbZ6UBsX",
        "colab_type": "code",
        "outputId": "f7abd07d-2886-4ae4-e937-5b413f72863d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "##make precision graphs\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import auc\n",
        "import random\n",
        "\n",
        "class Translation:\n",
        "    def __init__(self, original, reference, translation, score, features):\n",
        "        self.original = original\n",
        "        self.reference = reference\n",
        "        self.translation = translation\n",
        "        self.score = score\n",
        "        self.features = features\n",
        "\n",
        "def compute_exclued_included_sentenceBleuScore(acceptedTranslations, rejectedTranslations):\n",
        "    acceptedScore = 0 if len(acceptedTranslations) == 0 else sum([translation.score for translation in acceptedTranslations])/len(acceptedTranslations)\n",
        "    \n",
        "    rejectedScore = 0 if len(rejectedTranslations) == 0 else sum([translation.score for translation in rejectedTranslations])/len(rejectedTranslations)\n",
        "\n",
        "    return rejectedScore, acceptedScore\n",
        "\n",
        "def compute_excluded_included_score (acceptedTranslations, rejectedTranslations):\n",
        "    if len(acceptedTranslations) != 0:\n",
        "        temporary_reference_inclusion = open(\"analysis/temporary_reference_inclusion.txt\", \"w\")\n",
        "        temporary_output_inclusion = open(\"analysis/temporary_output_inclusion.txt\", \"w\")\n",
        "\n",
        "    \n",
        "        for translation in acceptedTranslations:\n",
        "            temporary_reference_inclusion.write(translation.reference)\n",
        "            temporary_output_inclusion.write(translation.translation)\n",
        "\n",
        "        temporary_reference_inclusion.close()\n",
        "        temporary_output_inclusion.close()\n",
        "\n",
        "\n",
        "        !fairseq-score --sys analysis/temporary_output_inclusion.txt --ref analysis/temporary_reference_inclusion.txt --sacrebleu > analysis/inclusion_result.txt\n",
        "\n",
        "        temporary_inclusion_result = open(\"analysis/inclusion_result.txt\")\n",
        "        inclusion_result_string = [line for line in temporary_inclusion_result][1].split(\" \")[2]\n",
        "\n",
        "        temporary_reference_inclusion.close()\n",
        "        temporary_output_inclusion.close()\n",
        "        temporary_inclusion_result.close()\n",
        "\n",
        "    else:\n",
        "        inclusion_result_string = \"0\"\n",
        "\n",
        "    if len(rejectedTranslations) != 0:\n",
        "\n",
        "        temporary_reference_exclusion = open(\"analysis/temporary_reference_exclusion.txt\", \"w\")\n",
        "        temporary_output_exclusion = open(\"analysis/temporary_output_exclusion.txt\", \"w\")\n",
        "        \n",
        "        for translation in rejectedTranslations:\n",
        "            temporary_reference_exclusion.write(translation.reference)\n",
        "            temporary_output_exclusion.write(translation.translation)\n",
        "\n",
        "        \n",
        "        temporary_reference_exclusion.close()\n",
        "        temporary_output_exclusion.close()\n",
        "\n",
        "        !fairseq-score --sys analysis/temporary_output_exclusion.txt --ref analysis/temporary_reference_exclusion.txt --sacrebleu > analysis/exclusion_result.txt\n",
        "\n",
        "        temporary_exclusion_result = open(\"analysis/exclusion_result.txt\")\n",
        "        exclusion_result_string = \"0\" if len(rejectedTranslations) == 0 else [line for line in temporary_exclusion_result][1].split(\" \")[2]\n",
        "\n",
        "        temporary_reference_exclusion.close()\n",
        "        temporary_output_exclusion.close()\n",
        "        temporary_exclusion_result.close()\n",
        "    \n",
        "    else:\n",
        "        exclusion_result_string = \"0\"\n",
        "\n",
        "    return float(exclusion_result_string), float(inclusion_result_string)\n",
        "\n",
        "\n",
        "def readTranslations(sentenceFile, featureArray):\n",
        "    translations = []\n",
        "    temp = []\n",
        "    index = 0\n",
        "    for line in sentenceFile:\n",
        "        if len(temp) < 3:\n",
        "            temp.append(line)\n",
        "        else:\n",
        "            score = float(line.strip(\"\\n\"))\n",
        "            translations.append(Translation(temp[0], temp[1], temp[2], score, featureArray[index]))\n",
        "            index += 1\n",
        "            temp = []\n",
        "    \n",
        "    return translations\n",
        "\n",
        "def getTrainTestSets(trainTranslations, testTranslations, threshold_train, threshold_test, avgLogProb):\n",
        "    trainFeatures = []\n",
        "    trainY = []\n",
        "    testFeatures = []\n",
        "    testY = []\n",
        "\n",
        "    for translation in trainTranslations:\n",
        "        trainFeatures.append(translation.features)\n",
        "        if avgLogProb:\n",
        "            if translation.features[0] < threshold_train:\n",
        "                trainY.append(0)\n",
        "            else:\n",
        "                trainY.append(1)\n",
        "        else:\n",
        "            if translation.score < threshold_train:\n",
        "                trainY.append(0)\n",
        "            else:\n",
        "                trainY.append(1)\n",
        "    \n",
        "    for translation in testTranslations:\n",
        "        testFeatures.append(translation.features)\n",
        "        if translation.score < threshold_test:\n",
        "            testY.append(0)\n",
        "        else:\n",
        "            testY.append(1)\n",
        "\n",
        "    return trainFeatures, trainY, testFeatures, testY\n",
        "\n",
        "# featuresUsed = [0, 5, 6, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20]\n",
        "# featuresUsed = [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21] ##All\n",
        "avgLogProb = [False, False, False, False]\n",
        "featuresUsed = [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
        "# featuresUsed = [10, 11, 12]\n",
        "featureSubsets = [[10], #just baseline Forward Model score [P(T|S)]\n",
        "                  [10, 11, 12], #Similar to noisy channel decoding: P(y|x), p(x|y), p(y) \n",
        "                  [10, 11, 12, 19, 20], #Like above + sentence length features\n",
        "                  [0, 10, 11, 12, 19, 20], #Like above + average Logprob + sentence length features\n",
        "                  [0, 5, 6, 10, 11, 12, 19, 20], #Like above + average Logprob + sentence length features + Rare words\n",
        "                  [0, 10, 11, 12, 13, 14, 19, 20], #Like above + average Logprob + sentence length features + end of sentence identifiers\n",
        "                  [10, 11, 12, 16, 17, 18], #Like above + ngram features\n",
        "                  [0, 10, 11, 12, 16, 17, 18], #Like above + average Logprob + ngram features\n",
        "                  [0, 5, 6, 10, 11, 12, 13, 14, 19, 20] #Like above + average Logprob + sentence length features + Rare words + end of sentence identifiers\n",
        "                  ]\n",
        "featureSubsetDetails = [\"Just baseline Forward Model score [P(T|S)]\",\n",
        "                        \"Similar to noisy channel decoding: P(y|x), p(x|y), p(y)\",\n",
        "                        \"NCD features + sentence length features\",\n",
        "                        \"NCD features + average Logprob + sentence length features\",\n",
        "                        \"NCD features + average Logprob + sentence length features + Rare words\",\n",
        "                        \"NCD features + average Logprob + sentence length features + end of sentence identifiers\",\n",
        "                        \"NCD features + ngram features\",\n",
        "                        \"NCD features + average Logprob + ngram features\",\n",
        "                        \"NCD features + average Logprob + sentence length features + Rare words + end of sentence identifiers\"]\n",
        "\n",
        "trainThresholds = [np.linspace(1, 60, 25).tolist(), np.linspace(1, 60, 25).tolist(), np.linspace(1, 60, 25).tolist(), np.linspace(1, 60, 25).tolist()]\n",
        "testThresholds = [np.linspace(1, 60, 25).tolist(), np.linspace(1, 60, 25).tolist(), np.linspace(1, 60, 25).tolist(), np.linspace(1, 60, 25).tolist()]\n",
        "modelLabel = {0: \"Random Forest Classifier\", 1: \"Custom Ensemble\", 2: \"Gradient Boosting Classifier\", 3: \"MLP Classifier\"}\n",
        "trainset = \"valid\"\n",
        "testset = \"test\"\n",
        "bleuThresholdTrain = 15\n",
        "bleuThresholdTest = 15\n",
        "\n",
        "trainFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/features.txt\")\n",
        "testFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/features.txt\")\n",
        "\n",
        "trainLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/result.txt\")\n",
        "testLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/result.txt\")\n",
        "\n",
        "trainSentences = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/sentences.txt\")\n",
        "testSentences = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/sentences.txt\")\n",
        "fullTrainX, fullTrainY = datasetReader(trainFeatures, trainLabels)\n",
        "fullTestX, fullTestY = datasetReader(testFeatures, testLabels)\n",
        "featuresTrain = fullTrainX\n",
        "featuresTest = fullTestX\n",
        "print(featuresTrain.shape)\n",
        "# print(len(trainX[0]))\n",
        "# print(len(testX[0]))\n",
        "\n",
        "print(np.array(fullTrainX).shape)\n",
        "print(np.array(fullTestX).shape)\n",
        "print(\"TRAIN SET CLASS PROPORTIONS:\")\n",
        "printDatasetClassProp(fullTrainY)\n",
        "print(\"TEST SET CLASS PROPORTIONS\")\n",
        "printDatasetClassProp(fullTestY)\n",
        "print()\n",
        "for ind, subset in enumerate(featureSubsets):\n",
        "  trainX = [[row[i] for i in subset] for row in fullTrainX]\n",
        "  testX = [[row[i] for i in subset] for row in fullTestX]\n",
        "\n",
        "  print(np.array(trainX).shape)\n",
        "  print(np.array(testX).shape)\n",
        "  classifiers = [trainRandomForestClassifier, trainCustomEnsemble, trainGradientBoostingClassifier, trainMLPClassifier]\n",
        "  outputs = []\n",
        "  models = []\n",
        "  plt.xlabel('Fraction Above Threshold') \n",
        "  plt.ylabel('Corpus BLEU score') \n",
        "  plt.title('Comparing Methods using Corpus BLEU score')\n",
        "  for j, classifier in enumerate(classifiers):\n",
        "      print(\"#################################################\")\n",
        "      curr = classifier(trainX, fullTrainY)\n",
        "      print(\"TRAIN ACCURACY\")\n",
        "      predictions = np.array(curr.predict(trainX))\n",
        "      calculateAccuracy(predictions, fullTrainY)\n",
        "      print(\"TEST ACCURACY\")\n",
        "      predictions = np.array(curr.predict(testX))\n",
        "      calculateAccuracy(predictions, fullTestY)\n",
        "      outputs.append(predictions)\n",
        "      models.append(curr)\n",
        "      print(\"#################################################\")\n",
        "      currFeaturesTrain = [[row[i] for i in featureSubsets[ind]] for row in featuresTrain]\n",
        "      currFeaturesTest = [[row[i] for i in featureSubsets[ind]] for row in featuresTest]\n",
        "      trainSentences = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/sentences.txt\")\n",
        "      testSentences = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/sentences.txt\")\n",
        "\n",
        "      trainTranslations = readTranslations(trainSentences, currFeaturesTrain)\n",
        "      testTranslations = readTranslations(testSentences, currFeaturesTest)\n",
        "\n",
        "      acceptedScores = []\n",
        "      acceptedFraction = []\n",
        "      print(\"TRAIN SET\")\n",
        "      for index in range(len(testThresholds[j])):\n",
        "          trainFeatures, trainY, testFeatures, testY = getTrainTestSets(trainTranslations, testTranslations, trainThresholds[j][index], testThresholds[j][index], avgLogProb[j])\n",
        "          print(len(trainY))\n",
        "          clf = classifier(trainFeatures, trainY, verbose=False)\n",
        "          predictions = clf.predict(trainFeatures)\n",
        "          \n",
        "          acceptedTranslations = np.array(trainTranslations)[np.array(predictions) > 0]\n",
        "          rejectedTranslations = np.array(trainTranslations)[np.array(predictions) < 1]\n",
        "            \n",
        "          rejectedScore, acceptedScore = compute_excluded_included_score(acceptedTranslations, rejectedTranslations)\n",
        "          \n",
        "          acceptedScores.append(acceptedScore)\n",
        "          acceptedFraction.append(float(len(acceptedTranslations))/float(len(predictions)))\n",
        "      \n",
        "      r = random.random()\n",
        "      b = random.random()\n",
        "      g = random.random()\n",
        "      c = (r, g, b)\n",
        "      plt.plot(acceptedFraction, acceptedScores, label = modelLabel[j], color=c)\n",
        "      acceptedScores = [x for _,x in sorted(zip(acceptedFraction,acceptedScores))]\n",
        "      acceptedFraction.sort()\n",
        "\n",
        "      print(\"[\"+modelLabel[j]+\"] AUC for included fraction: {}\".format(auc(acceptedFraction, acceptedScores)))\n",
        "      print(\"TEST SET\")\n",
        "      for index in range(len(testThresholds[j])):\n",
        "          trainFeatures, trainY, testFeatures, testY = getTrainTestSets(trainTranslations, testTranslations, trainThresholds[j][index], testThresholds[j][index], avgLogProb[j])\n",
        "          print(len(trainY))\n",
        "          clf = classifier(trainFeatures, trainY, verbose=False)\n",
        "          predictions = clf.predict(testFeatures)\n",
        "          \n",
        "          acceptedTranslations = np.array(testTranslations)[np.array(predictions) > 0]\n",
        "          rejectedTranslations = np.array(testTranslations)[np.array(predictions) < 1]\n",
        "            \n",
        "          rejectedScore, acceptedScore = compute_excluded_included_score(acceptedTranslations, rejectedTranslations)\n",
        "          \n",
        "          acceptedScores.append(acceptedScore)\n",
        "          acceptedFraction.append(float(len(acceptedTranslations))/float(len(predictions)))\n",
        "      \n",
        "      r = random.random()\n",
        "      b = random.random()\n",
        "      g = random.random()\n",
        "      c = (r, g, b)\n",
        "      plt.plot(acceptedFraction, acceptedScores, label = modelLabel[j], color=c)\n",
        "      acceptedScores = [x for _,x in sorted(zip(acceptedFraction,acceptedScores))]\n",
        "      acceptedFraction.sort()\n",
        "\n",
        "      print(\"[\"+modelLabel[j]+\"] AUC for included fraction: {}\".format(auc(acceptedFraction, acceptedScores)))\n",
        "  plt.legend(loc=\"upper right\")\n",
        "  plt.show()\n",
        "  print(\"\\n\\n\")\n",
        "  \n",
        "'''for output_1 in outputs:\n",
        "    for output_2 in outputs:\n",
        "        computeSimilarity(output_1, output_2)'''\n",
        "\n",
        "\n",
        "trainFeatures.close()\n",
        "trainLabels.close()\n",
        "testFeatures.close()\n",
        "testLabels.close()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2559, 23)\n",
            "(2559, 23)\n",
            "(2835, 23)\n",
            "TRAIN SET CLASS PROPORTIONS:\n",
            "Proportion in class 0.0 = 0.8014849550605705\n",
            "Proportion in class 1.0 = 0.19851504493942945\n",
            "TEST SET CLASS PROPORTIONS\n",
            "Proportion in class 1.0 = 0.2536155202821869\n",
            "Proportion in class 0.0 = 0.7463844797178131\n",
            "\n",
            "(2559, 1)\n",
            "(2835, 1)\n",
            "#################################################\n",
            "Training Random Forest classifier\n",
            "TRAIN ACCURACY\n",
            "Correctly accepted = 0.34448818897637795\n",
            "Incorrectly rejected = 0.655511811023622\n",
            "Correctly rejected = 0.98488542174549\n",
            "Incorrectly accepted = 0.015114578254510014\n",
            "Total Accuracy = 0.8577569363032435\n",
            "TEST ACCURACY\n",
            "Correctly accepted = 0.2141863699582754\n",
            "Incorrectly rejected = 0.7858136300417247\n",
            "Correctly rejected = 0.9428166351606805\n",
            "Incorrectly accepted = 0.05718336483931952\n",
            "Total Accuracy = 0.7580246913580246\n",
            "#################################################\n",
            "TRAIN SET\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "[Random Forest Classifier] AUC for included fraction: 11.326617819460726\n",
            "TEST SET\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "[Random Forest Classifier] AUC for included fraction: 10.81237141657931\n",
            "#################################################\n",
            "Training custom ensemble\n",
            "TRAIN ACCURACY\n",
            "Correctly accepted = 0.2874015748031496\n",
            "Incorrectly rejected = 0.7125984251968505\n",
            "Correctly rejected = 0.9863481228668942\n",
            "Incorrectly accepted = 0.013651877133105783\n",
            "Total Accuracy = 0.8475967174677609\n",
            "TEST ACCURACY\n",
            "Correctly accepted = 0.18915159944367177\n",
            "Incorrectly rejected = 0.8108484005563282\n",
            "Correctly rejected = 0.9541587901701323\n",
            "Incorrectly accepted = 0.045841209829867724\n",
            "Total Accuracy = 0.7601410934744268\n",
            "#################################################\n",
            "#################################################\n",
            "Training Graident Boosted classifier\n",
            "TRAIN ACCURACY\n",
            "Correctly accepted = 0.2125984251968504\n",
            "Incorrectly rejected = 0.7874015748031495\n",
            "Correctly rejected = 0.9926864943929791\n",
            "Incorrectly accepted = 0.0073135056070209314\n",
            "Total Accuracy = 0.8378272762797968\n",
            "TEST ACCURACY\n",
            "Correctly accepted = 0.15438108484005564\n",
            "Incorrectly rejected = 0.8456189151599444\n",
            "Correctly rejected = 0.973062381852552\n",
            "Incorrectly accepted = 0.026937618147447995\n",
            "Total Accuracy = 0.7654320987654321\n",
            "#################################################\n",
            "TRAIN SET\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n",
            "2559\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0b13e8f58ee5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mrejectedTranslations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainTranslations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mrejectedScore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macceptedScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_excluded_included_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macceptedTranslations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrejectedTranslations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0macceptedScores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macceptedScore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-0b13e8f58ee5>\u001b[0m in \u001b[0;36mcompute_excluded_included_score\u001b[0;34m(acceptedTranslations, rejectedTranslations)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fairseq-score --sys analysis/temporary_output_inclusion.txt --ref analysis/temporary_reference_inclusion.txt --sacrebleu > analysis/inclusion_result.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mtemporary_inclusion_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"analysis/inclusion_result.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     with temporary_clearer(), _display_stdin_widget(\n\u001b[0;32m--> 181\u001b[0;31m         delay_millis=500) as update_stdin_widget:\n\u001b[0m\u001b[1;32m    182\u001b[0m       \u001b[0;31m# TODO(b/115531839): Ensure that subprocesses are terminated upon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m       \u001b[0;31m# interrupt.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    339\u001b[0m   \u001b[0mshell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ipython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m   \u001b[0mdisplay_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_display_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'delayMillis'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdelay_millis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdisplay_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mecho_updater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_echo_status\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccsFgQUiD656",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import time\n",
        "\n",
        "\n",
        "dataset = \"valid\"\n",
        "bleuThreshold = 15\n",
        "featureFile = open(\"ClassificationDataset/\"+str(bleuThreshold)+\"BLEU/\"+dataset+\"/features.txt\")\n",
        "labelFile = open(\"ClassificationDataset/\"+str(bleuThreshold)+\"BLEU/\"+dataset+\"/result.txt\")\n",
        "featuresUsed = [10]\n",
        "\n",
        "inputs, labels = datasetReader(featureFile, labelFile)\n",
        "for classifier in classifiers:\n",
        "  features = np.array([[row[i] for i in featuresUsed] for row in inputs])\n",
        "  kf = KFold(n_splits=len(features))\n",
        "\n",
        "  numCorrect = 0\n",
        "  currIter = 0\n",
        "  for train_index, test_index in kf.split(features):\n",
        "      print(\"Currently done with \" + str(currIter)+\"/\"+str(len(features)))\n",
        "      trainX, trainY = features[train_index], labels[train_index]\n",
        "      testX, testY = features[test_index], labels[test_index]\n",
        "      if currIter == 0:\n",
        "        curr = classifier(trainX, trainY, verbose=True)\n",
        "      else:\n",
        "        curr = classifier(trainX, trainY, verbose=False)\n",
        "      prediction = np.array(curr.predict(testX))\n",
        "\n",
        "      if prediction[0] == testY[0]:\n",
        "          numCorrect += 1\n",
        "      \n",
        "      currIter += 1\n",
        "      print(\"Current Accuracy = \" + str(float(numCorrect)/float(currIter)))\n",
        "\n",
        "  print(\"Total Accuracy = \" + str(numCorrect/len(features)))\n",
        "\n",
        "featureFile.close()\n",
        "labelFile.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an1uY1tRPfEV",
        "colab_type": "code",
        "outputId": "ded1df09-8b80-4bd9-c435-758aae17b4d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "##make precision graphs\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import auc\n",
        "import random\n",
        "\n",
        "class Translation:\n",
        "    def __init__(self, original, reference, translation, score, features):\n",
        "        self.original = original\n",
        "        self.reference = reference\n",
        "        self.translation = translation\n",
        "        self.score = score\n",
        "        self.features = features\n",
        "\n",
        "def compute_exclued_included_sentenceBleuScore(acceptedTranslations, rejectedTranslations):\n",
        "    acceptedScore = 0 if len(acceptedTranslations) == 0 else sum([translation.score for translation in acceptedTranslations])/len(acceptedTranslations)\n",
        "    \n",
        "    rejectedScore = 0 if len(rejectedTranslations) == 0 else sum([translation.score for translation in rejectedTranslations])/len(rejectedTranslations)\n",
        "\n",
        "    return rejectedScore, acceptedScore\n",
        "\n",
        "def compute_excluded_included_score (acceptedTranslations, rejectedTranslations):\n",
        "    temporary_reference_inclusion = open(\"analysis/temporary_reference_inclusion.txt\", \"w\")\n",
        "    temporary_output_inclusion = open(\"analysis/temporary_output_inclusion.txt\", \"w\")\n",
        "\n",
        "    temporary_reference_exclusion = open(\"analysis/temporary_reference_exclusion.txt\", \"w\")\n",
        "    temporary_output_exclusion = open(\"analysis/temporary_output_exclusion.txt\", \"w\")\n",
        "    \n",
        "    for translation in acceptedTranslations:\n",
        "        temporary_reference_inclusion.write(translation.reference)\n",
        "        temporary_output_inclusion.write(translation.translation)\n",
        "\n",
        "    for translation in rejectedTranslations:\n",
        "        temporary_reference_exclusion.write(translation.reference)\n",
        "        temporary_output_exclusion.write(translation.translation)\n",
        "\n",
        "    \n",
        "    temporary_reference_inclusion.close()\n",
        "    temporary_output_inclusion.close()\n",
        "    temporary_reference_exclusion.close()\n",
        "    temporary_output_exclusion.close()\n",
        "\n",
        "    !fairseq-score --sys analysis/temporary_output_inclusion.txt --ref analysis/temporary_reference_inclusion.txt --sacrebleu > analysis/inclusion_result.txt\n",
        "    !fairseq-score --sys analysis/temporary_output_exclusion.txt --ref analysis/temporary_reference_exclusion.txt --sacrebleu > analysis/exclusion_result.txt\n",
        "\n",
        "    temporary_inclusion_result = open(\"analysis/inclusion_result.txt\")\n",
        "    temporary_exclusion_result = open(\"analysis/exclusion_result.txt\")\n",
        "    inclusion_result_string = [line for line in temporary_inclusion_result][1].split(\" \")[2]\n",
        "    exclusion_result_string = [line for line in temporary_exclusion_result][1].split(\" \")[2]\n",
        "\n",
        "    return float(exclusion_result_string), float(inclusion_result_string)\n",
        "\n",
        "\n",
        "def readTranslations(sentenceFile, featureArray):\n",
        "    translations = []\n",
        "    temp = []\n",
        "    index = 0\n",
        "    for line in sentenceFile:\n",
        "        if len(temp) < 3:\n",
        "            temp.append(line)\n",
        "        else:\n",
        "            score = float(line.strip(\"\\n\"))\n",
        "            translations.append(Translation(temp[0], temp[1], temp[2], score, featureArray[index]))\n",
        "            index += 1\n",
        "            temp = []\n",
        "    \n",
        "    return translations\n",
        "\n",
        "def getTrainTestSets(trainTranslations, testTranslations, threshold_train, threshold_test, avgLogProb):\n",
        "    trainFeatures = []\n",
        "    trainY = []\n",
        "    testFeatures = []\n",
        "    testY = []\n",
        "\n",
        "    for translation in trainTranslations:\n",
        "        trainFeatures.append(translation.features)\n",
        "        if avgLogProb:\n",
        "            if translation.features[0] < threshold_train:\n",
        "                trainY.append(0)\n",
        "            else:\n",
        "                trainY.append(1)\n",
        "        else:\n",
        "            if translation.score < threshold_train:\n",
        "                trainY.append(0)\n",
        "            else:\n",
        "                trainY.append(1)\n",
        "    \n",
        "    for translation in testTranslations:\n",
        "        testFeatures.append(translation.features)\n",
        "        if translation.score < threshold_test:\n",
        "            testY.append(0)\n",
        "        else:\n",
        "            testY.append(1)\n",
        "\n",
        "    return trainFeatures, trainY, testFeatures, testY\n",
        "\n",
        "# featuresUsed = [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
        "# featuresUsed = [0]\n",
        "# featuresUsed = [0, 4]\n",
        "\n",
        "trainset = \"valid\"\n",
        "testset = \"test\"\n",
        "bleuThresholdTrain = 15\n",
        "bleuThresholdTest = 15\n",
        "\n",
        "trainFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/features.txt\")\n",
        "testFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/features.txt\")\n",
        "trainLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/result.txt\")\n",
        "testLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/result.txt\")\n",
        "\n",
        "trainSentences = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/sentences.txt\")\n",
        "testSentences = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/sentences.txt\")\n",
        "\n",
        "\n",
        "featuresTrain, _ = datasetReader(trainFeatures, trainLabels)\n",
        "featuresTest, _ = datasetReader(testFeatures, testLabels)\n",
        "\n",
        "featuresTrain = [[row[i] for i in featuresUsed] for row in featuresTrain]\n",
        "featuresTest = [[row[i] for i in featuresUsed] for row in featuresTest]\n",
        "\n",
        "trainTranslations = readTranslations(trainSentences, featuresTrain)\n",
        "testTranslations = readTranslations(testSentences, featuresTest)\n",
        "\n",
        "# Thresholds_train = np.linspace(-1.5, 0, 25).tolist()\n",
        "Thresholds_train = np.linspace(4, 28, 25).tolist()\n",
        "\n",
        "Thresholds_test = np.linspace(4, 28, 25).tolist()\n",
        "\n",
        "acceptedScores = []\n",
        "acceptedFraction = []\n",
        "\n",
        "useSentenceBLEUScore = True\n",
        "\n",
        "\n",
        "for index in range(len(Thresholds_test)):\n",
        "    trainFeatures, trainY, testFeatures, testY = getTrainTestSets(trainTranslations, testTranslations, Thresholds_train[index], Thresholds_test[index])\n",
        "\n",
        "    clf = trainSVM(trainFeatures, trainY)\n",
        "    # print(\"Using Average Logprob Decision Stump of \" + str(Thresholds_train[index]))\n",
        "    # print(\"BLEU score = \" + str(Thresholds_test[index]))\n",
        "    predictions = clf.predict(testFeatures)\n",
        "    # calculateAccuracy(predictions, testY)\n",
        "    # print(\"##########################################\")\n",
        "    acceptedTranslations = np.array(testTranslations)[np.array(predictions) > 0]\n",
        "    rejectedTranslations = np.array(testTranslations)[np.array(predictions) < 1]\n",
        "    if useSentenceBLEUScore:\n",
        "        rejectedScore, acceptedScore = compute_exclued_included_sentenceBleuScore(acceptedTranslations, rejectedTranslations)\n",
        "    else:\n",
        "        rejectedScore, acceptedScore = compute_excluded_included_score(acceptedTranslations, rejectedTranslations)\n",
        "    acceptedScores.append(acceptedScore)\n",
        "    acceptedFraction.append(float(len(acceptedTranslations))/float(len(predictions)))\n",
        "\n",
        "plt.xlabel('Fraction Above Threshold') \n",
        "plt.ylabel('BLEU score (average)') \n",
        "plt.title('Random Forest Thresholding') \n",
        "\n",
        "r = random.random()\n",
        "b = random.random()\n",
        "g = random.random()\n",
        "c = (r, g, b)\n",
        "plt.scatter(acceptedFraction, acceptedScores, label = \"Random Forest Analysis\", color=c)\n",
        "\n",
        "acceptedScores = [x for _,x in sorted(zip(acceptedFraction,acceptedScores))]\n",
        "acceptedFraction.sort()\n",
        "\n",
        "print('AUC for incuded fraction: {}'.format(auc(acceptedFraction, acceptedScores)))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-c72493789813>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mThresholds_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mtrainFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTrainTestSets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainTranslations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestTranslations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mThresholds_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mThresholds_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: getTrainTestSets() missing 1 required positional argument: 'avgLogProb'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utOMembzJXAc",
        "colab_type": "text"
      },
      "source": [
        "Experimenting with multiple parameters and plotting curves on the same graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJFjlR8sJtkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import auc\n",
        "import random\n",
        "\n",
        "class Translation:\n",
        "    def __init__(self, original, reference, translation, score, features):\n",
        "        self.original = original\n",
        "        self.reference = reference\n",
        "        self.translation = translation\n",
        "        self.score = score\n",
        "        self.features = features\n",
        "\n",
        "def compute_exclued_included_sentenceBleuScore(acceptedTranslations, rejectedTranslations):\n",
        "    acceptedScore = 0 if len(acceptedTranslations) == 0 else sum([translation.score for translation in acceptedTranslations])/len(acceptedTranslations)\n",
        "    \n",
        "    rejectedScore = 0 if len(rejectedTranslations) == 0 else sum([translation.score for translation in rejectedTranslations])/len(rejectedTranslations)\n",
        "\n",
        "    return rejectedScore, acceptedScore\n",
        "\n",
        "def compute_excluded_included_score (acceptedTranslations, rejectedTranslations):\n",
        "    if len(acceptedTranslations) != 0:\n",
        "        temporary_reference_inclusion = open(\"analysis/temporary_reference_inclusion.txt\", \"w\")\n",
        "        temporary_output_inclusion = open(\"analysis/temporary_output_inclusion.txt\", \"w\")\n",
        "\n",
        "    \n",
        "        for translation in acceptedTranslations:\n",
        "            temporary_reference_inclusion.write(translation.reference)\n",
        "            temporary_output_inclusion.write(translation.translation)\n",
        "\n",
        "        temporary_reference_inclusion.close()\n",
        "        temporary_output_inclusion.close()\n",
        "\n",
        "\n",
        "        !fairseq-score --sys analysis/temporary_output_inclusion.txt --ref analysis/temporary_reference_inclusion.txt --sacrebleu > analysis/inclusion_result.txt\n",
        "\n",
        "        temporary_inclusion_result = open(\"analysis/inclusion_result.txt\")\n",
        "        inclusion_result_string = [line for line in temporary_inclusion_result][1].split(\" \")[2]\n",
        "\n",
        "    else:\n",
        "        inclusion_result_string = \"0\"\n",
        "\n",
        "    if len(rejectedTranslations) != 0:\n",
        "\n",
        "        temporary_reference_exclusion = open(\"analysis/temporary_reference_exclusion.txt\", \"w\")\n",
        "        temporary_output_exclusion = open(\"analysis/temporary_output_exclusion.txt\", \"w\")\n",
        "        \n",
        "        for translation in rejectedTranslations:\n",
        "            temporary_reference_exclusion.write(translation.reference)\n",
        "            temporary_output_exclusion.write(translation.translation)\n",
        "\n",
        "        \n",
        "        temporary_reference_exclusion.close()\n",
        "        temporary_output_exclusion.close()\n",
        "\n",
        "        !fairseq-score --sys analysis/temporary_output_exclusion.txt --ref analysis/temporary_reference_exclusion.txt --sacrebleu > analysis/exclusion_result.txt\n",
        "\n",
        "        temporary_exclusion_result = open(\"analysis/exclusion_result.txt\")\n",
        "        exclusion_result_string = \"0\" if len(rejectedTranslations) == 0 else [line for line in temporary_exclusion_result][1].split(\" \")[2]\n",
        "    \n",
        "    else:\n",
        "        exclusion_result_string = \"0\"\n",
        "\n",
        "    return float(exclusion_result_string), float(inclusion_result_string)\n",
        "\n",
        "\n",
        "def readTranslations(sentenceFile, featureArray):\n",
        "    translations = []\n",
        "    temp = []\n",
        "    index = 0\n",
        "    for line in sentenceFile:\n",
        "        if len(temp) < 3:\n",
        "            temp.append(line)\n",
        "        else:\n",
        "            score = float(line.strip(\"\\n\"))\n",
        "            translations.append(Translation(temp[0], temp[1], temp[2], score, featureArray[index]))\n",
        "            index += 1\n",
        "            temp = []\n",
        "    \n",
        "    return translations\n",
        "\n",
        "def getTrainTestSets(trainTranslations, testTranslations, threshold_train, threshold_test, avgLogProb):\n",
        "    trainFeatures = []\n",
        "    trainY = []\n",
        "    testFeatures = []\n",
        "    testY = []\n",
        "\n",
        "    for translation in trainTranslations:\n",
        "        trainFeatures.append(translation.features)\n",
        "        if avgLogProb:\n",
        "            if translation.features[0] < threshold_train:\n",
        "                trainY.append(0)\n",
        "            else:\n",
        "                trainY.append(1)\n",
        "        else:\n",
        "            if translation.score < threshold_train:\n",
        "                trainY.append(0)\n",
        "            else:\n",
        "                trainY.append(1)\n",
        "    \n",
        "    for translation in testTranslations:\n",
        "        testFeatures.append(translation.features)\n",
        "        if translation.score < threshold_test:\n",
        "            testY.append(0)\n",
        "        else:\n",
        "            testY.append(1)\n",
        "\n",
        "    return trainFeatures, trainY, testFeatures, testY\n",
        "\n",
        "trainset = \"valid\"\n",
        "testset = \"test\"\n",
        "bleuThresholdTrain = 10\n",
        "bleuThresholdTest = 10\n",
        "\n",
        "trainFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/features.txt\")\n",
        "testFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/features.txt\")\n",
        "trainLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/result.txt\")\n",
        "testLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/result.txt\")\n",
        "\n",
        "\n",
        "featuresTrain, _ = datasetReader(trainFeatures, trainLabels)\n",
        "featuresTest, _ = datasetReader(testFeatures, testLabels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ItLAR-5J-ov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "featuresUsed = [[0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21], [0], [4]]\n",
        "trainThresholds = [np.linspace(4, 28, 25).tolist(), np.linspace(-1.5, -0.25, 25).tolist(), np.linspace(1, 60, 25).tolist()]\n",
        "testThresholds = [np.linspace(4, 28, 25).tolist(), np.linspace(4, 28, 25).tolist(), np.linspace(1, 60, 25).tolist()]\n",
        "\n",
        "evaluationMetrics = [compute_exclued_included_sentenceBleuScore, compute_excluded_included_score]\n",
        "evalLabel = {0: \"Average Sentence BLEU score\", 1: \"Corpus BLEU score\"}\n",
        "models = [trainRandomForestClassifier, trainRandomForestClassifier, trainRandomForestClassifier]\n",
        "modelLabel = {0: \"Random Forest Classifier (all features)\", 1: \"Average Logprob Thresholding\", 2: \"Sentence BLEU Thresholding\"}\n",
        "avgLogProb = [False, True, False]\n",
        "acceptedScores = []\n",
        "acceptedFraction = []\n",
        "\n",
        "\n",
        "for evalMetric in range(len(evaluationMetrics)):\n",
        "    plt.xlabel('Fraction Above Threshold') \n",
        "    plt.ylabel(evalLabel[evalMetric]) \n",
        "    plt.title('Comparing Methods using ' + evalLabel[evalMetric])\n",
        "\n",
        "    for model in range(len(models)):\n",
        "        currFeaturesTrain = [[row[i] for i in featuresUsed[model]] for row in featuresTrain]\n",
        "        currFeaturesTest = [[row[i] for i in featuresUsed[model]] for row in featuresTest]\n",
        "\n",
        "\n",
        "        trainSentences = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/sentences.txt\")\n",
        "        testSentences = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/sentences.txt\")\n",
        "\n",
        "        trainTranslations = readTranslations(trainSentences, currFeaturesTrain)\n",
        "        testTranslations = readTranslations(testSentences, currFeaturesTest)\n",
        "\n",
        "        acceptedScores = []\n",
        "        acceptedFraction = []\n",
        "\n",
        "        for index in range(len(testThresholds[model])):\n",
        "            trainFeatures, trainY, testFeatures, testY = getTrainTestSets(trainTranslations, testTranslations, trainThresholds[model][index], testThresholds[model][index], avgLogProb[model])\n",
        "            clf = models[model](trainFeatures, trainY, verbose=False)\n",
        "            predictions = clf.predict(testFeatures)\n",
        "            \n",
        "            acceptedTranslations = np.array(testTranslations)[np.array(predictions) > 0]\n",
        "            rejectedTranslations = np.array(testTranslations)[np.array(predictions) < 1]\n",
        "              \n",
        "            rejectedScore, acceptedScore = evaluationMetrics[evalMetric](acceptedTranslations, rejectedTranslations)\n",
        "            \n",
        "            acceptedScores.append(acceptedScore)\n",
        "            acceptedFraction.append(float(len(acceptedTranslations))/float(len(predictions)))\n",
        "        \n",
        "        r = random.random()\n",
        "        b = random.random()\n",
        "        g = random.random()\n",
        "        c = (r, g, b)\n",
        "        plt.plot(acceptedFraction, acceptedScores, label = modelLabel[model], color=c)\n",
        "        acceptedScores = [x for _,x in sorted(zip(acceptedFraction,acceptedScores))]\n",
        "        acceptedFraction.sort()\n",
        "\n",
        "        print(\"[\"+modelLabel[model]+\"] AUC for included fraction: {}\".format(auc(acceptedFraction, acceptedScores)))\n",
        "    plt.legend(loc=\"upper right\")\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}