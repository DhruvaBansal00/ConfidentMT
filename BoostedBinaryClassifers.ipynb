{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BoostedBinaryClassifers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhruvaBansal00/ConfidentMT/blob/master/BoostedBinaryClassifers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEk99K4f0Hw_",
        "colab_type": "code",
        "outputId": "87cc7554-3914-4920-a03f-55a196680452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!ls\n",
        "%cd drive/My Drive/ConfidentMachineTranslation/flores\n",
        "!ls\n",
        "!pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "drive  sample_data\n",
            "/content/drive/My Drive/ConfidentMachineTranslation/flores\n",
            "'=0.5.0'\t\t\t FeatureSubsetBinaryClassifers.ipynb\n",
            " analysis\t\t\t FLORES.ipynb\n",
            " Analysis\t\t\t LanguageAnalysis.ipynb\n",
            " backward_models\t\t language_models\n",
            " BoostedBinaryClassifers.ipynb\t LM_Thresholding.ipynb\n",
            " checkpoints\t\t\t NCD_Analysis.ipynb\n",
            " ClassificationDataset\t\t NNClassification.ipynb\n",
            " configs\t\t\t noisychannel\n",
            " data\t\t\t\t NoisyChannel.ipynb\n",
            " data-bin\t\t\t Resources\n",
            " Ensembles\t\t\t scripts\n",
            " Ensembling\n",
            "/content/drive/My Drive/ConfidentMachineTranslation/flores\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0LVqC0npSH1",
        "colab_type": "code",
        "outputId": "04d1da7b-0a98-4fbd-9ac2-777b640af89b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "pip install fairseq sacrebleu sentencepiece"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fairseq\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/bf/de299e082e7af010d35162cb9a185dc6c17db71624590f2f379aeb2519ff/fairseq-0.9.0.tar.gz (306kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 2.8MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/9d/9846507837ca50ae20917f59d83b79246b8313bd19d4f5bf575ecb98132b/sacrebleu-1.4.9-py3-none-any.whl (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.5MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.18)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.18.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2019.12.20)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.5.0+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.41.1)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (0.16.0)\n",
            "Building wheels for collected packages: fairseq\n",
            "  Building wheel for fairseq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.9.0-cp36-cp36m-linux_x86_64.whl size=2021171 sha256=446ea5f7e9fca7fb90334d62f98b75a7859bee44f2fde3240f8fdd907ce6afb8\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/3e/1b/0fa30695dcba41e4b0088067fa40f3328d1e8ee78c22cd4766\n",
            "Successfully built fairseq\n",
            "Installing collected packages: portalocker, sacrebleu, fairseq, sentencepiece\n",
            "Successfully installed fairseq-0.9.0 portalocker-1.7.0 sacrebleu-1.4.9 sentencepiece-0.1.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlcgFl162kdH",
        "colab_type": "code",
        "outputId": "1451e77c-762c-469d-ea14-a7fb567c46a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# prints how much GPU RAM is available\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=9d2ee7fb8f5fc0d50d83d14aa626349ece832b1d74e7e70009ea9c8ed54d8959\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  | Proc size: 159.0 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBb8hVU3Cj8g",
        "colab_type": "text"
      },
      "source": [
        "Define models and methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xwd7lNk3EZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "import numpy as np\n",
        "from itertools import zip_longest\n",
        "from sklearn.svm import SVC\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import auc\n",
        "import statistics\n",
        "random.seed(42)\n",
        "\n",
        "class CustomEnsembleClassifier:\n",
        "    def __init__(self, clfs):\n",
        "        self.classifiers = clfs\n",
        "    \n",
        "    def predict(self, X):\n",
        "        probabilities = None\n",
        "        for clf in self.classifiers:\n",
        "            if probabilities is None:\n",
        "                probabilities = clf.predict_proba(X)\n",
        "            else:\n",
        "                probabilities += clf.predict_proba(X)\n",
        "        return np.argmax(np.array(probabilities), axis=1)\n",
        "        \n",
        "class Translation:\n",
        "    def __init__(self, original, reference, translation, score, features):\n",
        "        self.original = original\n",
        "        self.reference = reference\n",
        "        self.translation = translation\n",
        "        self.score = score\n",
        "        self.features = features\n",
        "\n",
        "def compute_exclued_included_sentenceBleuScore(acceptedTranslations, rejectedTranslations):\n",
        "    acceptedScore = 0 if len(acceptedTranslations) == 0 else sum([translation.score for translation in acceptedTranslations])/len(acceptedTranslations)\n",
        "    \n",
        "    rejectedScore = 0 if len(rejectedTranslations) == 0 else sum([translation.score for translation in rejectedTranslations])/len(rejectedTranslations)\n",
        "\n",
        "    return rejectedScore, acceptedScore\n",
        "\n",
        "def compute_excluded_included_score (acceptedTranslations, rejectedTranslations):\n",
        "    if len(acceptedTranslations) != 0:\n",
        "        temporary_reference_inclusion = open(\"analysis/temporary_reference_inclusion.txt\", \"w\")\n",
        "        temporary_output_inclusion = open(\"analysis/temporary_output_inclusion.txt\", \"w\")\n",
        "\n",
        "    \n",
        "        for translation in acceptedTranslations:\n",
        "            temporary_reference_inclusion.write(translation.reference)\n",
        "            temporary_output_inclusion.write(translation.translation)\n",
        "\n",
        "        temporary_reference_inclusion.close()\n",
        "        temporary_output_inclusion.close()\n",
        "\n",
        "\n",
        "        !fairseq-score --sys analysis/temporary_output_inclusion.txt --ref analysis/temporary_reference_inclusion.txt --sacrebleu > analysis/inclusion_result.txt\n",
        "\n",
        "        temporary_inclusion_result = open(\"analysis/inclusion_result.txt\")\n",
        "        inclusion_result_string = [line for line in temporary_inclusion_result][1].split(\" \")[2]\n",
        "\n",
        "        temporary_reference_inclusion.close()\n",
        "        temporary_output_inclusion.close()\n",
        "        temporary_inclusion_result.close()\n",
        "\n",
        "    else:\n",
        "        inclusion_result_string = \"0\"\n",
        "\n",
        "    if len(rejectedTranslations) != 0:\n",
        "\n",
        "        temporary_reference_exclusion = open(\"analysis/temporary_reference_exclusion.txt\", \"w\")\n",
        "        temporary_output_exclusion = open(\"analysis/temporary_output_exclusion.txt\", \"w\")\n",
        "        \n",
        "        for translation in rejectedTranslations:\n",
        "            temporary_reference_exclusion.write(translation.reference)\n",
        "            temporary_output_exclusion.write(translation.translation)\n",
        "\n",
        "        \n",
        "        temporary_reference_exclusion.close()\n",
        "        temporary_output_exclusion.close()\n",
        "\n",
        "        !fairseq-score --sys analysis/temporary_output_exclusion.txt --ref analysis/temporary_reference_exclusion.txt --sacrebleu > analysis/exclusion_result.txt\n",
        "\n",
        "        temporary_exclusion_result = open(\"analysis/exclusion_result.txt\")\n",
        "        exclusion_result_string = \"0\" if len(rejectedTranslations) == 0 else [line for line in temporary_exclusion_result][1].split(\" \")[2]\n",
        "\n",
        "        temporary_reference_exclusion.close()\n",
        "        temporary_output_exclusion.close()\n",
        "        temporary_exclusion_result.close()\n",
        "    \n",
        "    else:\n",
        "        exclusion_result_string = \"0\"\n",
        "\n",
        "    return float(exclusion_result_string), float(inclusion_result_string)\n",
        "\n",
        "\n",
        "def readTranslations(sentenceFile, featureArray):\n",
        "    translations = []\n",
        "    temp = []\n",
        "    index = 0\n",
        "    for line in sentenceFile:\n",
        "        if len(temp) < 3:\n",
        "            temp.append(line)\n",
        "        else:\n",
        "            score = float(line.strip(\"\\n\"))\n",
        "            translations.append(Translation(temp[0], temp[1], temp[2], score, featureArray[index]))\n",
        "            index += 1\n",
        "            temp = []\n",
        "    \n",
        "    return translations\n",
        "\n",
        "def getTrainTestSets(trainTranslations, testTranslations, threshold_train, threshold_test, avgLogProb):\n",
        "    trainFeatures = []\n",
        "    trainY = []\n",
        "    testFeatures = []\n",
        "    testY = []\n",
        "\n",
        "    for translation in trainTranslations:\n",
        "        trainFeatures.append(translation.features)\n",
        "        if avgLogProb:\n",
        "            if translation.features[0] < threshold_train:\n",
        "                trainY.append(0)\n",
        "            else:\n",
        "                trainY.append(1)\n",
        "        else:\n",
        "            if translation.score < threshold_train:\n",
        "                trainY.append(0)\n",
        "            else:\n",
        "                trainY.append(1)\n",
        "    \n",
        "    for translation in testTranslations:\n",
        "        testFeatures.append(translation.features)\n",
        "        if translation.score < threshold_test:\n",
        "            testY.append(0)\n",
        "        else:\n",
        "            testY.append(1)\n",
        "\n",
        "    return trainFeatures, trainY, testFeatures, testY\n",
        "\n",
        "\n",
        "\n",
        "def printDatasetClassProp(Y): \n",
        "    classes = {}\n",
        "    total = len(Y)\n",
        "    for i in Y:\n",
        "        if i in classes:\n",
        "            classes[i] += 1\n",
        "        else:\n",
        "            classes[i] = 1\n",
        "    \n",
        "    for cls in classes:\n",
        "        print(\"Proportion in class \" + str(cls) + \" = \" + str(classes[cls]/total))\n",
        "\n",
        "def datasetReader(featureFile, labelFile):\n",
        "    files = [featureFile, labelFile]\n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    for lines in zip_longest(*files, fillvalue=''):\n",
        "        currX, currY = lines[0], float(lines[1].strip(\"\\n\"))\n",
        "        Xarr = []\n",
        "        features = currX.split()\n",
        "        for feature in features:\n",
        "            Xarr.append(float(feature.strip(\",\").strip(\"\\n\")))\n",
        "        X.append(Xarr)\n",
        "        Y.append(currY)\n",
        "    \n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "def normalizeFeatures(trainX, testX):\n",
        "    featureLists = [trainX[:, i] for i in range(trainX.shape[1])]\n",
        "\n",
        "    #means and stddv calculated using training features only. \n",
        "    means = [statistics.mean(feature) for feature in featureLists]\n",
        "    stdDv = [statistics.stdev(feature) for feature in featureLists]\n",
        "\n",
        "    trainX = np.array([[(row[i] - means[i]) / stdDv[i] for i in range(len(row))] for row in trainX])\n",
        "    testX = np.array([[(row[i] - means[i]) / stdDv[i] for i in range(len(row))] for row in testX])\n",
        "\n",
        "    return trainX, testX\n",
        "\n",
        "\n",
        "def computeSimilarity(o1, o2):\n",
        "    total = len(o1)\n",
        "    same = 0\n",
        "    for i in range(len(o1)):\n",
        "        if o1[i] == o2[i]:\n",
        "            same += 1\n",
        "    print(same/total)\n",
        "\n",
        "def trainLogisticRegressionClassifier(X, Y, verbose=True):\n",
        "    if verbose:\n",
        "        print(\"Traning Logistic Regression Classifier\")\n",
        "    clf = LogisticRegression(random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainMLPClassifier(X, Y, verbose=True):\n",
        "    if verbose:\n",
        "        print(\"Training MLP Classifier\")\n",
        "    clf = MLPClassifier(hidden_layer_sizes=(256, 512, 1024, 512, 256), random_state=42,\n",
        "                        max_iter=200, learning_rate='adaptive', learning_rate_init=0.0001, activation='relu')\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainKNeighborsClassifier(X, Y, verbose=True):\n",
        "    if verbose:\n",
        "        print(\"Training KNeighbors Classifier\")\n",
        "    clf = KNeighborsClassifier(100)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainGaussianProcessClassifier(X, Y, verbose=True):\n",
        "    if verbose:\n",
        "        print(\"Training Gaussian Process Classifier\")\n",
        "    length_scale = [1 for i in range(len(X[0]))]\n",
        "    clf = GaussianProcessClassifier(1.0 * RBF(length_scale), warm_start=True, random_state=42, n_jobs=-1)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainCustomEnsemble(X, Y, maxDepth=8, estimators=100, verbose=True, subsetTraining=False):\n",
        "    if verbose:\n",
        "        print(\"Training custom ensemble\")\n",
        "    rf = RandomForestClassifier(max_depth=maxDepth, random_state=42)\n",
        "    grad = GradientBoostingClassifier(random_state=42)\n",
        "    ada = AdaBoostClassifier(n_estimators=estimators, random_state=42)\n",
        "    dl = MLPClassifier(hidden_layer_sizes=(256,512,256), random_state=42, max_iter=100)\n",
        "    kn = KNeighborsClassifier(100)\n",
        "\n",
        "    classifiers = [rf, grad, ada, kn]\n",
        "\n",
        "    Xs = [X for i in range(len(classifiers))]\n",
        "    Ys = [Y for i in range(len(classifiers))]\n",
        "\n",
        "    if subsetTraining:\n",
        "        Xs = []\n",
        "        Ys = []\n",
        "        data = list(zip(X, Y))\n",
        "        random.shuffle(data)\n",
        "        X_all, Y_all = zip(*data)\n",
        "\n",
        "        start = 0\n",
        "        end = int(len(X)/len(classifiers))\n",
        "\n",
        "        for i in range(len(classifiers)):\n",
        "            Xs.append(X_all[start:end])\n",
        "            Ys.append(Y_all[start:end])\n",
        "            start = end\n",
        "            end = int((i+2) * len(X)/len(classifiers))\n",
        "\n",
        "    for index in range(len(classifiers)):\n",
        "        classifiers[index].fit(Xs[index], Ys[index])\n",
        "\n",
        "    return CustomEnsembleClassifier(classifiers)\n",
        "    \n",
        "\n",
        "def trainEnsembleClassifier(X, Y, maxDepth=8, estimators=100, verbose=True):\n",
        "    if verbose:\n",
        "        print(\"Training an ensemble of Random Forest and Gradient Boosting Classifiers\")\n",
        "\n",
        "    estimators = [\n",
        "     ('rf', RandomForestClassifier(max_depth=maxDepth, random_state=42)),\n",
        "     ('grad', GradientBoostingClassifier(random_state=42))]\n",
        "    clf = StackingClassifier(estimators=estimators, final_estimator=AdaBoostClassifier(n_estimators=50, random_state=42))\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "\n",
        "def trainRandomForestClassifier(X, Y, maxDepth=8, verbose=True):\n",
        "    if verbose:\n",
        "        print(\"Training Random Forest classifier\")\n",
        "    clf = RandomForestClassifier(max_depth=maxDepth, random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainAdaBoostClassifier(X, Y, estimators=100, verbose=True):\n",
        "    if verbose:\n",
        "        print(\"Training AdaBoosted Decision Tree classifier\")\n",
        "    clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=estimators, random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainGradientBoostingClassifier(X, Y, verbose=True):\n",
        "    if verbose:\n",
        "        print(\"Training Graident Boosted classifier\")\n",
        "    clf = GradientBoostingClassifier(random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainSVM(X, Y, verbose=True):\n",
        "    if verbose:\n",
        "        print(\"Training SVM classifier\")\n",
        "    clf = SVC(gamma='auto')\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def calculateAccuracy(predictedClasses, groundTruth):\n",
        "    correct_accepted = 0\n",
        "    total_accepted = 0\n",
        "\n",
        "    correct_rejected = 0\n",
        "    total_rejected = 0\n",
        "\n",
        "    for i in range(len(predictedClasses)):\n",
        "        if groundTruth[i] == 1:\n",
        "            total_accepted += 1\n",
        "            if predictedClasses[i] == groundTruth[i]:\n",
        "                correct_accepted += 1\n",
        "        else:\n",
        "            total_rejected += 1\n",
        "            if predictedClasses[i] == groundTruth[i]:\n",
        "                correct_rejected += 1\n",
        "\n",
        "\n",
        "    print(\"Correctly accepted = \" + str(correct_accepted/total_accepted))\n",
        "    print(\"Incorrectly rejected = \" + str(1 - correct_accepted/total_accepted))\n",
        "    print(\"Correctly rejected = \" + str(correct_rejected/total_rejected))\n",
        "    print(\"Incorrectly accepted = \" + str(1 - correct_rejected/total_rejected))\n",
        "\n",
        "    print(\"Total Accuracy = \" + str((correct_accepted + correct_rejected)/(total_accepted + total_rejected)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg8PAhsfCfJu",
        "colab_type": "text"
      },
      "source": [
        "Perform quick training of classifiers and get accuracies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_4LpbZ6UBsX",
        "colab_type": "code",
        "outputId": "03983482-c86d-4ae8-f525-12a6a54aedce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "# featuresUsed = [0, 5, 6, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20]\n",
        "# featuresUsed = [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22] ##All\n",
        "# featuresUsed = [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
        "featuresUsed = [0]\n",
        "\n",
        "\n",
        "trainset = \"valid\"\n",
        "testset = \"test\"\n",
        "bleuThresholdTrain = 15\n",
        "bleuThresholdTest = 15\n",
        "\n",
        "trainFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/features.txt\")\n",
        "testFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/features.txt\")\n",
        "\n",
        "trainLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/result.txt\")\n",
        "testLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/result.txt\")\n",
        "\n",
        "trainX, trainY = datasetReader(trainFeatures, trainLabels)\n",
        "testX, testY = datasetReader(testFeatures, testLabels)\n",
        "\n",
        "trainX, testX = normalizeFeatures(trainX, testX)\n",
        "\n",
        "trainX = [[row[i] for i in featuresUsed] for row in trainX]\n",
        "testX = [[row[i] for i in featuresUsed] for row in testX]\n",
        "\n",
        "printDatasetClassProp(trainY)\n",
        "\n",
        "\n",
        "classifiers = [trainRandomForestClassifier, trainCustomEnsemble, trainLogisticRegressionClassifier]\n",
        "outputs = []\n",
        "models = []\n",
        "for classifier in classifiers:\n",
        "    print(\"#################################################\")\n",
        "    curr = classifier(trainX, trainY)\n",
        "    predictions = np.array(curr.predict(testX))\n",
        "    calculateAccuracy(predictions, testY)\n",
        "    outputs.append(predictions)\n",
        "    models.append(curr)\n",
        "    print(\"#################################################\")\n",
        "\n",
        "for output_1 in outputs:\n",
        "    for output_2 in outputs:\n",
        "        computeSimilarity(output_1, output_2)\n",
        "\n",
        "\n",
        "trainFeatures.close()\n",
        "trainLabels.close()\n",
        "testFeatures.close()\n",
        "testLabels.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Proportion in class 0.0 = 0.8014849550605705\n",
            "Proportion in class 1.0 = 0.19851504493942945\n",
            "#################################################\n",
            "Training Random Forest classifier\n",
            "Correctly accepted = 0.1349095966620306\n",
            "Incorrectly rejected = 0.8650904033379694\n",
            "Correctly rejected = 0.9617202268431002\n",
            "Incorrectly accepted = 0.03827977315689979\n",
            "Total Accuracy = 0.7520282186948853\n",
            "#################################################\n",
            "#################################################\n",
            "Training custom ensemble\n",
            "Correctly accepted = 0.10848400556328233\n",
            "Incorrectly rejected = 0.8915159944367177\n",
            "Correctly rejected = 0.9768431001890359\n",
            "Incorrectly accepted = 0.023156899810964138\n",
            "Total Accuracy = 0.7566137566137566\n",
            "#################################################\n",
            "#################################################\n",
            "Traning Logistic Regression Classifier\n",
            "Correctly accepted = 0.11961057023643949\n",
            "Incorrectly rejected = 0.8803894297635605\n",
            "Correctly rejected = 0.9825141776937618\n",
            "Incorrectly accepted = 0.017485822306238186\n",
            "Total Accuracy = 0.763668430335097\n",
            "#################################################\n",
            "1.0\n",
            "0.982010582010582\n",
            "0.963668430335097\n",
            "0.982010582010582\n",
            "1.0\n",
            "0.981657848324515\n",
            "0.963668430335097\n",
            "0.981657848324515\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDDs8MEmUD0N",
        "colab_type": "text"
      },
      "source": [
        "Run LOOCV\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_FRXMQlUFVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import time\n",
        "\n",
        "\n",
        "dataset = \"valid\"\n",
        "bleuThreshold = 15\n",
        "featureFile = open(\"ClassificationDataset/\"+str(bleuThreshold)+\"BLEU/\"+dataset+\"/features.txt\")\n",
        "labelFile = open(\"ClassificationDataset/\"+str(bleuThreshold)+\"BLEU/\"+dataset+\"/result.txt\")\n",
        "featuresUsed = [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
        "\n",
        "inputs, labels = datasetReader(featureFile, labelFile)\n",
        "features = np.array([[row[i] for i in featuresUsed] for row in inputs])\n",
        "\n",
        "classifier = trainRandomForestClassifier\n",
        "\n",
        "kf = KFold(n_splits=len(features))\n",
        "\n",
        "numCorrect = 0\n",
        "currIter = 0\n",
        "\n",
        "for train_index, test_index in kf.split(features):\n",
        "    print(\"Currently done with \" + str(currIter)+\"/\"+str(len(features)))\n",
        "    trainX, trainY = features[train_index], labels[train_index]\n",
        "    testX, testY = features[test_index], labels[test_index]\n",
        "\n",
        "    curr = classifier(trainX, trainY, verbose=False)\n",
        "    prediction = np.array(curr.predict(testX))\n",
        "\n",
        "    if prediction[0] == testY[0]:\n",
        "        numCorrect += 1\n",
        "    \n",
        "    currIter += 1\n",
        "\n",
        "    print(\"Current Accuracy = \" + str(float(numCorrect)/float(currIter)))\n",
        "\n",
        "print(\"Total Accuracy = \" + str(numCorrect/len(features)))\n",
        "\n",
        "featureFile.close()\n",
        "labelFile.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utOMembzJXAc",
        "colab_type": "text"
      },
      "source": [
        "Experimenting with multiple parameters and plotting curves on the same graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJFjlR8sJtkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = \"valid\"\n",
        "testset = \"test\"\n",
        "bleuThresholdTrain = 10\n",
        "bleuThresholdTest = 10\n",
        "\n",
        "trainFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/features.txt\")\n",
        "testFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/features.txt\")\n",
        "trainLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/result.txt\")\n",
        "testLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/result.txt\")\n",
        "\n",
        "\n",
        "featuresTrain, _ = datasetReader(trainFeatures, trainLabels)\n",
        "featuresTest, _ = datasetReader(testFeatures, testLabels)\n",
        "\n",
        "trainFeatures.close()\n",
        "testFeatures.close()\n",
        "trainLabels.close()\n",
        "testLabels.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaCi5beVhTeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "featuresUsed = [[0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21], [0], [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21], [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]]\n",
        "trainThresholds = [np.linspace(4, 28, 25).tolist(), np.linspace(-1.5, -0.25, 25).tolist(), np.linspace(4, 28, 25).tolist(), np.linspace(4, 28, 25).tolist()]\n",
        "testThresholds = [np.linspace(4, 28, 25).tolist(), np.linspace(4, 28, 25).tolist(),  np.linspace(4, 28, 25).tolist(), np.linspace(4, 28, 25).tolist()]\n",
        "\n",
        "evaluationMetrics = [compute_exclued_included_sentenceBleuScore, compute_excluded_included_score]\n",
        "evalLabel = {0: \"Average Sentence BLEU score\", 1: \"Corpus BLEU score\"}\n",
        "models = [trainRandomForestClassifier, trainRandomForestClassifier, trainCustomEnsemble, trainCustomEnsemble]\n",
        "modelLabel = {0: \"Random Forest Classifier (all features)\", 1: \"Average Logprob Thresholding\", 2: \"Ensemble of models trained on complete set\", 3: \"Ensemble of models trained on disjoint sets\"}\n",
        "avgLogProb = [False, True, False, False]\n",
        "subsetTraining = [False, False, False, True]\n",
        "acceptedScores = []\n",
        "acceptedFraction = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B6sFNq0hT-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "featuresUsed = [[10], [0]]\n",
        "trainThresholds = [np.linspace(4, 28, 25).tolist(), np.linspace(-1.5, -0.25, 25).tolist()]\n",
        "testThresholds = [np.linspace(4, 28, 25).tolist(), np.linspace(4, 28, 25).tolist()]\n",
        "\n",
        "evaluationMetrics = [compute_exclued_included_sentenceBleuScore, compute_excluded_included_score]\n",
        "evalLabel = {0: \"Average Sentence BLEU score\", 1: \"Corpus BLEU score\"}\n",
        "models = [trainRandomForestClassifier, trainRandomForestClassifier]\n",
        "modelLabel = {0: \"Random Forest Classifier with P(y|x) only\", 1: \"Average Logpob thresholding score\"}\n",
        "avgLogProb = [False, True]\n",
        "subsetTraining = [False, False]\n",
        "acceptedScores = []\n",
        "acceptedFraction = []\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS3jUanu8pBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "featuresUsed = [[0], [0], [0], [10]]\n",
        "trainThresholds = [np.linspace(4, 28, 25).tolist(), np.linspace(-1.5, -0.25, 25).tolist(), np.linspace(4, 28, 25).tolist(), np.linspace(4, 28, 25).tolist()]\n",
        "testThresholds = [np.linspace(4, 28, 25).tolist(), np.linspace(4, 28, 25).tolist(), np.linspace(4, 28, 25).tolist(), np.linspace(4, 28, 25).tolist()]\n",
        "\n",
        "evaluationMetrics = [compute_excluded_included_score]\n",
        "evalLabel = {0: \"Corpus BLEU score\"}\n",
        "models = [trainLogisticRegressionClassifier, trainRandomForestClassifier, trainLogisticRegressionClassifier, trainLogisticRegressionClassifier]\n",
        "modelLabel = {0: \"Logistic Regression classifier (not normalized)\", 1: \"Average Logpob thresholding score\", 2: \"Logistic Regression Classifier (normalized)\", 3: \"Logistic Regression Classifier (normalized)\"}\n",
        "avgLogProb = [False, True, False, False]\n",
        "subsetTraining = [False, False, False, False]\n",
        "normalizeScore = [False, False, True, True]\n",
        "acceptedScores = []\n",
        "acceptedFraction = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFwoNvxVeh9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "featuresUsed = [[0], [0, 5, 6, 8, 9, 12, 16, 17, 18, 19, 20], [0, 1, 2, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22]]\n",
        "trainThresholds = [np.linspace(-1.5, -0.25, 25).tolist(), np.linspace(4, 28, 25).tolist(), np.linspace(4, 28, 25).tolist()]\n",
        "testThresholds = [np.linspace(4, 28, 25).tolist(), np.linspace(4, 28, 25).tolist(), np.linspace(4, 28, 25).tolist()]\n",
        "\n",
        "evaluationMetrics = [compute_excluded_included_score]\n",
        "evalLabel = {0: \"Corpus BLEU score\"}\n",
        "models = [trainRandomForestClassifier, trainLogisticRegressionClassifier, trainLogisticRegressionClassifier]\n",
        "modelLabel = {0: \"Average Logpob thresholding score\", 1: \"Logistic Regression Classifier (normalized)\", 2: \"Logistic Regression Classifier (normalized)\"}\n",
        "avgLogProb = [True, False, False]\n",
        "subsetTraining = [False, False, False]\n",
        "normalizeScore = [False, True, True]\n",
        "acceptedScores = []\n",
        "acceptedFraction = []\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ItLAR-5J-ov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for evalMetric in range(len(evaluationMetrics)):\n",
        "    plt.xlabel('Fraction Above Threshold') \n",
        "    plt.ylabel(evalLabel[evalMetric]) \n",
        "    plt.title('Comparing Methods using ' + evalLabel[evalMetric])\n",
        "\n",
        "    for model in range(len(models)):\n",
        "        if normalizeScore[model]:\n",
        "            trainFeatures, testFeatures = normalizeFeatures(featuresTrain, featuresTest)\n",
        "        else:\n",
        "            trainFeatures, testFeatures = featuresTrain, featuresTest\n",
        "        currFeaturesTrain = [[row[i] for i in featuresUsed[model]] for row in trainFeatures]\n",
        "        currFeaturesTest = [[row[i] for i in featuresUsed[model]] for row in testFeatures]\n",
        "\n",
        "\n",
        "        trainSentences = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/sentences.txt\")\n",
        "        testSentences = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/sentences.txt\")\n",
        "\n",
        "        trainTranslations = readTranslations(trainSentences, currFeaturesTrain)\n",
        "        testTranslations = readTranslations(testSentences, currFeaturesTest)\n",
        "\n",
        "        trainSentences.close()\n",
        "        testSentences.close()\n",
        "\n",
        "        acceptedScores = []\n",
        "        acceptedFraction = []\n",
        "\n",
        "        for index in range(len(testThresholds[model])):\n",
        "            trainFeatures, trainY, testFeatures, testY = getTrainTestSets(trainTranslations, testTranslations, trainThresholds[model][index], testThresholds[model][index], avgLogProb[model])\n",
        "            if subsetTraining[model]:\n",
        "                clf = models[model](trainFeatures, trainY, verbose=False, subsetTraining=True)\n",
        "            else:\n",
        "                clf = models[model](trainFeatures, trainY, verbose=False)\n",
        "            predictions = clf.predict(testFeatures)\n",
        "            \n",
        "            acceptedTranslations = np.array(testTranslations)[np.array(predictions) > 0]\n",
        "            rejectedTranslations = np.array(testTranslations)[np.array(predictions) < 1]\n",
        "              \n",
        "            rejectedScore, acceptedScore = evaluationMetrics[evalMetric](acceptedTranslations, rejectedTranslations)\n",
        "            \n",
        "            acceptedScores.append(acceptedScore)\n",
        "            acceptedFraction.append(float(len(acceptedTranslations))/float(len(predictions)))\n",
        "        \n",
        "        r = random.random()\n",
        "        b = random.random()\n",
        "        g = random.random()\n",
        "        c = (r, g, b)\n",
        "        plt.plot(acceptedFraction, acceptedScores, label = modelLabel[model], color=c)\n",
        "        acceptedScores = [x for _,x in sorted(zip(acceptedFraction,acceptedScores))]\n",
        "        acceptedFraction.sort()\n",
        "\n",
        "        print(\"[\"+modelLabel[model]+\"] AUC for included fraction: {}\".format(auc(acceptedFraction, acceptedScores)))\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfazeaZXCYEO",
        "colab_type": "text"
      },
      "source": [
        "Analyze Average logprob vs Normalized fw score discrepancy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LWCoCjXm9yn",
        "colab_type": "code",
        "outputId": "5e56a9bc-2384-445e-f3d4-3aba72479c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "featuresUsed = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
        "sentences = open(\"ClassificationDataset/\"+str(15)+\"BLEU/\"+\"valid\"+\"/sentences.txt\")\n",
        "currFeaturesTrain = [[row[i] for i in featuresUsed] for row in featuresTrain]\n",
        "translations = readTranslations(sentences, currFeaturesTrain)\n",
        "\n",
        "\n",
        "avg_logprob_scores = [translation.features[0] for translation in translations]\n",
        "fw_scores_normalized = [translation.features[10]/translation.features[22] for translation in translations]\n",
        "\n",
        "plt.xlabel('forward score/number of tokens') \n",
        "plt.ylabel('Average logprob score') \n",
        "plt.title('Average logprob vs forward score/number of tokens')\n",
        "\n",
        "plt.scatter(fw_scores_normalized, avg_logprob_scores, c=\"blue\")\n",
        "\n",
        "sentences.close()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}