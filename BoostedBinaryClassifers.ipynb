{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BoostedBinaryClassifers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhruvaBansal00/ConfidentMT/blob/master/BoostedBinaryClassifers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEk99K4f0Hw_",
        "colab_type": "code",
        "outputId": "8bc5ab62-1646-49c5-a96d-7699517564b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!ls\n",
        "%cd drive/My Drive/ConfidentMachineTranslation/flores\n",
        "!ls\n",
        "!pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "drive  sample_data\n",
            "/content/drive/My Drive/ConfidentMachineTranslation/flores\n",
            "'=0.5.0'\t\t\t Ensembling\n",
            " analysis\t\t\t FLORES.ipynb\n",
            " Analysis\t\t\t LanguageAnalysis.ipynb\n",
            " backward_models\t\t language_models\n",
            " BoostedBinaryClassifers.ipynb\t LM_Thresholding.ipynb\n",
            " checkpoints\t\t\t NCD_Analysis.ipynb\n",
            " ClassificationDataset\t\t NNClassification.ipynb\n",
            " configs\t\t\t noisychannel\n",
            " data\t\t\t\t NoisyChannel.ipynb\n",
            " data-bin\t\t\t Resources\n",
            " Ensembles\t\t\t scripts\n",
            "/content/drive/My Drive/ConfidentMachineTranslation/flores\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0LVqC0npSH1",
        "colab_type": "code",
        "outputId": "3ece8f0d-0aa4-4cd2-b6f5-5cce04022013",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "pip install fairseq sacrebleu sentencepiece"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fairseq\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/bf/de299e082e7af010d35162cb9a185dc6c17db71624590f2f379aeb2519ff/fairseq-0.9.0.tar.gz (306kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 2.8MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/9d/9846507837ca50ae20917f59d83b79246b8313bd19d4f5bf575ecb98132b/sacrebleu-1.4.9-py3-none-any.whl (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.3MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/88/49e772d686088e1278766ad68a463513642a2a877487decbd691dec02955/sentencepiece-0.1.90-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.17)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.18.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2019.12.20)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.5.0+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.41.1)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (0.16.0)\n",
            "Building wheels for collected packages: fairseq\n",
            "  Building wheel for fairseq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.9.0-cp36-cp36m-linux_x86_64.whl size=2035346 sha256=5e2ad55192ce6d106a3a753ca17f2460b2388d2b71f6e67cc8bd5e805b8f1ecc\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/3e/1b/0fa30695dcba41e4b0088067fa40f3328d1e8ee78c22cd4766\n",
            "Successfully built fairseq\n",
            "Installing collected packages: portalocker, sacrebleu, fairseq, sentencepiece\n",
            "Successfully installed fairseq-0.9.0 portalocker-1.7.0 sacrebleu-1.4.9 sentencepiece-0.1.90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlcgFl162kdH",
        "colab_type": "code",
        "outputId": "9646abb0-5f01-48ec-e61e-2d46b2361690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# prints how much GPU RAM is available\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=996e5bf2320df8cd03bfb0f06ecb44bd61b133ccebf0889503660095003eec1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  | Proc size: 160.2 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xwd7lNk3EZn",
        "colab_type": "code",
        "outputId": "8292ca31-a079-47d8-fb14-ba36238d7828",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "import numpy as np\n",
        "from itertools import zip_longest\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "class CustomEnsembleClassifier:\n",
        "    def __init__(self, clfs):\n",
        "        self.classifiers = clfs\n",
        "    \n",
        "    def predict(self, X):\n",
        "        probabilities = None\n",
        "        for clf in self.classifiers:\n",
        "            if probabilities is None:\n",
        "                probabilities = clf.predict_proba(X)\n",
        "            else:\n",
        "                probabilities += clf.predict_proba(X)\n",
        "        return np.argmax(np.array(probabilities), axis=1)\n",
        "\n",
        "\n",
        "\n",
        "def printDatasetClassProp(Y): \n",
        "    classes = {}\n",
        "    total = len(Y)\n",
        "    for i in Y:\n",
        "        if i in classes:\n",
        "            classes[i] += 1\n",
        "        else:\n",
        "            classes[i] = 1\n",
        "    \n",
        "    for cls in classes:\n",
        "        print(\"Proportion in class \" + str(cls) + \" = \" + str(classes[cls]/total))\n",
        "\n",
        "def datasetReader(featureFile, labelFile):\n",
        "    files = [featureFile, labelFile]\n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    for lines in zip_longest(*files, fillvalue=''):\n",
        "        currX, currY = lines[0], float(lines[1].strip(\"\\n\"))\n",
        "        Xarr = []\n",
        "        features = currX.split()\n",
        "        for feature in features:\n",
        "            Xarr.append(float(feature.strip(\",\").strip(\"\\n\")))\n",
        "        X.append(Xarr)\n",
        "        Y.append(currY)\n",
        "    \n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "\n",
        "def computeSimilarity(o1, o2):\n",
        "    total = len(o1)\n",
        "    same = 0\n",
        "    for i in range(len(o1)):\n",
        "        if o1[i] == o2[i]:\n",
        "            same += 1\n",
        "    print(same/total)\n",
        "\n",
        "\n",
        "def trainMLPClassifier(X, Y):\n",
        "    print(\"Training MLP Classifier\")\n",
        "    clf = MLPClassifier(hidden_layer_sizes=(30,30), random_state=1, max_iter=100)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainKNeighborsClassifier(X, Y):\n",
        "    print(\"Training KNeighbors Classifier\")\n",
        "    clf = KNeighborsClassifier(100)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainGaussianProcessClassifier(X, Y):\n",
        "    print(\"Training Gaussian Process Classifier\")\n",
        "    length_scale = [1 for i in range(len(X[0]))]\n",
        "    clf = GaussianProcessClassifier(1.0 * RBF(length_scale), warm_start=True, random_state=42, n_jobs=-1)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainCustomEnsemble(X, Y, maxDepth=8, estimators=100):\n",
        "    print(\"Training custom ensemble\")\n",
        "    rf = RandomForestClassifier(max_depth=maxDepth, random_state=42)\n",
        "    grad = GradientBoostingClassifier(random_state=42)\n",
        "    ada = AdaBoostClassifier(n_estimators=estimators, random_state=42)\n",
        "    # dl = MLPClassifier(hidden_layer_sizes=(100), random_state=1, max_iter=200)\n",
        "    # kn = KNeighborsClassifier(100)\n",
        "\n",
        "    classifiers = [rf, grad, ada]\n",
        "\n",
        "    for clf in classifiers:\n",
        "        clf.fit(X, Y)\n",
        "\n",
        "    return CustomEnsembleClassifier(classifiers)\n",
        "    \n",
        "\n",
        "def trainEnsembleClassifier(X, Y, maxDepth=8, estimators=100):\n",
        "    print(\"Training an ensemble of Random Forest and Gradient Boosting Classifiers\")\n",
        "\n",
        "    estimators = [\n",
        "     ('rf', RandomForestClassifier(max_depth=maxDepth, random_state=42)),\n",
        "     ('grad', GradientBoostingClassifier(random_state=42))]\n",
        "    clf = StackingClassifier(estimators=estimators, final_estimator=AdaBoostClassifier(n_estimators=50, random_state=42))\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "\n",
        "def trainRandomForestClassifier(X, Y, maxDepth=8):\n",
        "    print(\"Training Random Forest classifier\")\n",
        "    clf = RandomForestClassifier(max_depth=maxDepth, random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainAdaBoostClassifier(X, Y, estimators=100):\n",
        "    print(\"Training AdaBoosted Decision Tree classifier\")\n",
        "    clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=estimators, random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainGradientBoostingClassifier(X, Y):\n",
        "    print(\"Training Graident Boosted classifier\")\n",
        "    clf = GradientBoostingClassifier(random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainSVM(X, Y):\n",
        "    print(\"Training SVM classifier\")\n",
        "    clf = SVC(gamma='auto')\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def calculateAccuracy(predictedClasses, groundTruth):\n",
        "    correct_accepted = 0\n",
        "    total_accepted = 0\n",
        "\n",
        "    correct_rejected = 0\n",
        "    total_rejected = 0\n",
        "\n",
        "    for i in range(len(predictedClasses)):\n",
        "        if groundTruth[i] == 1:\n",
        "            total_accepted += 1\n",
        "            if predictedClasses[i] == groundTruth[i]:\n",
        "                correct_accepted += 1\n",
        "        else:\n",
        "            total_rejected += 1\n",
        "            if predictedClasses[i] == groundTruth[i]:\n",
        "                correct_rejected += 1\n",
        "\n",
        "\n",
        "    print(\"Correctly accepted = \" + str(correct_accepted/total_accepted))\n",
        "    print(\"Incorrectly rejected = \" + str(1 - correct_accepted/total_accepted))\n",
        "    print(\"Correctly rejected = \" + str(correct_rejected/total_rejected))\n",
        "    print(\"Incorrectly accepted = \" + str(1 - correct_rejected/total_rejected))\n",
        "\n",
        "    print(\"Total Accuracy = \" + str((correct_accepted + correct_rejected)/(total_accepted + total_rejected)))\n",
        "\n",
        "# featuresUsed = [0, 5, 6, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20]\n",
        "# featuresUsed = [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21] ##All\n",
        "featuresUsed = [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
        "# featuresUsed = [10, 11, 12]\n",
        "\n",
        "\n",
        "trainset = \"valid\"\n",
        "testset = \"test\"\n",
        "bleuThresholdTrain = 10\n",
        "bleuThresholdTest = 10\n",
        "\n",
        "trainFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/features.txt\")\n",
        "testFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/features.txt\")\n",
        "\n",
        "trainLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/result.txt\")\n",
        "testLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/result.txt\")\n",
        "\n",
        "trainX, trainY = datasetReader(trainFeatures, trainLabels)\n",
        "testX, testY = datasetReader(testFeatures, testLabels)\n",
        "# print(len(trainX[0]))\n",
        "# print(len(testX[0]))\n",
        "\n",
        "print(np.array(trainX).shape)\n",
        "print(np.array(testX).shape)\n",
        "\n",
        "trainX = [[row[i] for i in featuresUsed] for row in trainX]\n",
        "testX = [[row[i] for i in featuresUsed] for row in testX]\n",
        "\n",
        "print(np.array(trainX).shape)\n",
        "print(np.array(testX).shape)\n",
        "\n",
        "printDatasetClassProp(trainY)\n",
        "\n",
        "\n",
        "classifiers = [trainRandomForestClassifier, trainAdaBoostClassifier, trainGradientBoostingClassifier, trainCustomEnsemble]\n",
        "outputs = []\n",
        "models = []\n",
        "for classifier in classifiers:\n",
        "    print(\"#################################################\")\n",
        "    curr = classifier(trainX, trainY)\n",
        "    predictions = np.array(curr.predict(testX))\n",
        "    calculateAccuracy(predictions, testY)\n",
        "    outputs.append(predictions)\n",
        "    models.append(curr)\n",
        "    print(\"#################################################\")\n",
        "\n",
        "for output_1 in outputs:\n",
        "    for output_2 in outputs:\n",
        "        computeSimilarity(output_1, output_2)\n",
        "\n",
        "\n",
        "trainFeatures.close()\n",
        "trainLabels.close()\n",
        "testFeatures.close()\n",
        "testLabels.close()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2559, 22)\n",
            "(2835, 22)\n",
            "(2559, 19)\n",
            "(2835, 19)\n",
            "Proportion in class 1.0 = 0.5287221570926143\n",
            "Proportion in class 0.0 = 0.4712778429073857\n",
            "#################################################\n",
            "Training Random Forest classifier\n",
            "Correctly accepted = 0.7030965391621129\n",
            "Incorrectly rejected = 0.2969034608378871\n",
            "Correctly rejected = 0.7138047138047138\n",
            "Incorrectly accepted = 0.2861952861952862\n",
            "Total Accuracy = 0.7075837742504409\n",
            "#################################################\n",
            "#################################################\n",
            "Training AdaBoosted Decision Tree classifier\n",
            "Correctly accepted = 0.6964177292046144\n",
            "Incorrectly rejected = 0.3035822707953856\n",
            "Correctly rejected = 0.6759259259259259\n",
            "Incorrectly accepted = 0.32407407407407407\n",
            "Total Accuracy = 0.6878306878306878\n",
            "#################################################\n",
            "#################################################\n",
            "Training Graident Boosted classifier\n",
            "Correctly accepted = 0.7061323618700668\n",
            "Incorrectly rejected = 0.2938676381299332\n",
            "Correctly rejected = 0.7053872053872053\n",
            "Incorrectly accepted = 0.29461279461279466\n",
            "Total Accuracy = 0.7058201058201058\n",
            "#################################################\n",
            "#################################################\n",
            "Training custom ensemble\n",
            "Correctly accepted = 0.7128111718275653\n",
            "Incorrectly rejected = 0.28718882817243474\n",
            "Correctly rejected = 0.7121212121212122\n",
            "Incorrectly accepted = 0.28787878787878785\n",
            "Total Accuracy = 0.7125220458553791\n",
            "#################################################\n",
            "1.0\n",
            "0.8567901234567902\n",
            "0.9192239858906526\n",
            "0.9569664902998236\n",
            "0.8567901234567902\n",
            "1.0\n",
            "0.8754850088183421\n",
            "0.873015873015873\n",
            "0.9192239858906526\n",
            "0.8754850088183421\n",
            "1.0\n",
            "0.962257495590829\n",
            "0.9569664902998236\n",
            "0.873015873015873\n",
            "0.962257495590829\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuJiK-mALbhy",
        "colab_type": "code",
        "outputId": "2c4a7613-3298-4a33-9a42-95596c0cb467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class Translation:\n",
        "    def __init__(self, original, reference, translation, score, category):\n",
        "        self.original = original\n",
        "        self.reference = reference\n",
        "        self.translation = translation\n",
        "        self.score = score\n",
        "        self.category = category #0 - accepted correctly, 1 - incorrectly rejected, 2 - correctly rejected, 3 - incorrectly accepted\n",
        "        self.features = []\n",
        "\n",
        "currModel = models[0] ##Random Forest Clf\n",
        "currResult = outputs[0]\n",
        "groundTruth = testY\n",
        "sentences = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/sentences.txt\")\n",
        "translations = []\n",
        "temp = []\n",
        "index = 0\n",
        "for line in sentences:\n",
        "    if len(temp) < 3:\n",
        "        temp.append(line)\n",
        "    else:\n",
        "        score = float(line.strip(\"\\n\"))\n",
        "        category = 0\n",
        "        if currResult[index] != groundTruth[index]:\n",
        "            category = 1 if currResult[index] == 0 else 3\n",
        "        else:\n",
        "            category = 0 if currResult[index] == 1 else 2\n",
        "\n",
        "        translations.append(Translation(temp[0], temp[1], temp[2], score, category))\n",
        "        index += 1\n",
        "        temp = []\n",
        "###############verification#####################\n",
        "# temp = [0 for i in range(4)]\n",
        "# total = 0\n",
        "# for translation in translations:\n",
        "#     total += 1\n",
        "#     temp[translation.category] += 1\n",
        "# for i in temp:\n",
        "#     print(str(float(i)/float(total)) + \"\\n\")\n",
        "###############verification#####################\n",
        "labels = {0 : \"Accepted Correctly\", 1: \"Incorrectly Rejected\", 2: \"Correctly Rejected\", 3: \"Incorrectly Accepted\"}\n",
        "indices = [2]\n",
        "\n",
        "# for i in indices:\n",
        "#     # print(labels[i])\n",
        "#     for translation in translations:\n",
        "#         if translation.category == i:\n",
        "#             print(translation.reference)\n",
        "#             print(translation.translation)\n",
        "#             print(str(translation.score) + \"\\n\")\n",
        "\n",
        "\n",
        "totalScore = [0 for i in range(4)]\n",
        "totalNum = [0 for i in range(4)]\n",
        "\n",
        "for translation in translations:\n",
        "    totalScore[translation.category] += translation.score\n",
        "    totalNum[translation.category] += 1\n",
        "\n",
        "print(np.array(totalScore)/np.array(totalNum))\n",
        "sentences.close()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[22.17986025 19.1385625   8.54718777 10.39010539]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ_gNXTbla-G",
        "colab_type": "code",
        "outputId": "3482af67-0f98-499d-f36b-6351bf27a87b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "set1 = \"valid\"\n",
        "set2 = \"test\"\n",
        "\n",
        "\n",
        "set1Features = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+set1+\"/features.txt\")\n",
        "set2Features = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+set2+\"/features.txt\")\n",
        "\n",
        "set1Labels = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+set1+\"/result.txt\")\n",
        "set2Labels = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+set2+\"/result.txt\")\n",
        "\n",
        "\n",
        "_,set1Labels = datasetReader(set1Features, set1Labels)\n",
        "_,set2Labels = datasetReader(set2Features, set2Labels)\n",
        "\n",
        "\n",
        "num_reject = 0\n",
        "for label in set1Labels:\n",
        "    if label == 0:\n",
        "        num_reject += 1\n",
        "\n",
        "num_accept = 0\n",
        "for label in set2Labels:\n",
        "    if label == 1:\n",
        "        num_accept += 1\n",
        "\n",
        "print(\"Num rejected in set 1 = \" + str(num_reject))\n",
        "print(\"Num accept in set 2 = \" + str(num_accept))\n",
        "set1Features.close()\n",
        "set2Features.close()\n",
        "set1Labels.close()\n",
        "set2Labels.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num rejected in set 1 = 2051\n",
            "Num accept in set 2 = 719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an1uY1tRPfEV",
        "colab_type": "code",
        "outputId": "1f49d17c-cf76-4e53-80f7-ea4ae7ce50d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "##make precision graphs\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import auc\n",
        "import random\n",
        "\n",
        "class Translation:\n",
        "    def __init__(self, original, reference, translation, score, features):\n",
        "        self.original = original\n",
        "        self.reference = reference\n",
        "        self.translation = translation\n",
        "        self.score = score\n",
        "        self.features = features\n",
        "\n",
        "def compute_exclued_included_sentenceBleuScore(acceptedTranslations, rejectedTranslations):\n",
        "    acceptedScore = 0 if len(acceptedTranslations) == 0 else sum([translation.score for translation in acceptedTranslations])/len(acceptedTranslations)\n",
        "    \n",
        "    rejectedScore = 0 if len(rejectedTranslations) == 0 else sum([translation.score for translation in rejectedTranslations])/len(rejectedTranslations)\n",
        "\n",
        "    return rejectedScore, acceptedScore\n",
        "\n",
        "def compute_excluded_included_score (acceptedTranslations, rejectedTranslations):\n",
        "    temporary_reference_inclusion = open(\"analysis/temporary_reference_inclusion.txt\", \"w\")\n",
        "    temporary_output_inclusion = open(\"analysis/temporary_output_inclusion.txt\", \"w\")\n",
        "\n",
        "    temporary_reference_exclusion = open(\"analysis/temporary_reference_exclusion.txt\", \"w\")\n",
        "    temporary_output_exclusion = open(\"analysis/temporary_output_exclusion.txt\", \"w\")\n",
        "    \n",
        "    for translation in acceptedTranslations:\n",
        "        temporary_reference_inclusion.write(translation.reference)\n",
        "        temporary_output_inclusion.write(translation.translation)\n",
        "\n",
        "    for translation in rejectedTranslations:\n",
        "        temporary_reference_exclusion.write(translation.reference)\n",
        "        temporary_output_exclusion.write(translation.translation)\n",
        "\n",
        "    \n",
        "    temporary_reference_inclusion.close()\n",
        "    temporary_output_inclusion.close()\n",
        "    temporary_reference_exclusion.close()\n",
        "    temporary_output_exclusion.close()\n",
        "\n",
        "    !fairseq-score --sys analysis/temporary_output_inclusion.txt --ref analysis/temporary_reference_inclusion.txt --sacrebleu > analysis/inclusion_result.txt\n",
        "    !fairseq-score --sys analysis/temporary_output_exclusion.txt --ref analysis/temporary_reference_exclusion.txt --sacrebleu > analysis/exclusion_result.txt\n",
        "\n",
        "    temporary_inclusion_result = open(\"analysis/inclusion_result.txt\")\n",
        "    temporary_exclusion_result = open(\"analysis/exclusion_result.txt\")\n",
        "    inclusion_result_string = [line for line in temporary_inclusion_result][1].split(\" \")[2]\n",
        "    exclusion_result_string = [line for line in temporary_exclusion_result][1].split(\" \")[2]\n",
        "\n",
        "    return float(exclusion_result_string), float(inclusion_result_string)\n",
        "\n",
        "\n",
        "def readTranslations(sentenceFile, featureArray):\n",
        "    translations = []\n",
        "    temp = []\n",
        "    index = 0\n",
        "    for line in sentenceFile:\n",
        "        if len(temp) < 3:\n",
        "            temp.append(line)\n",
        "        else:\n",
        "            score = float(line.strip(\"\\n\"))\n",
        "            translations.append(Translation(temp[0], temp[1], temp[2], score, featureArray[index]))\n",
        "            index += 1\n",
        "            temp = []\n",
        "    \n",
        "    return translations\n",
        "\n",
        "def getTrainTestSets(trainTranslations, testTranslations, threshold_train, threshold_test):\n",
        "    trainFeatures = []\n",
        "    trainY = []\n",
        "    testFeatures = []\n",
        "    testY = []\n",
        "\n",
        "    for translation in trainTranslations:\n",
        "        trainFeatures.append(translation.features)\n",
        "        # if translation.features[0] < threshold_train:\n",
        "        if translation.score < threshold_train:\n",
        "            trainY.append(0)\n",
        "        else:\n",
        "            trainY.append(1)\n",
        "    \n",
        "    for translation in testTranslations:\n",
        "        testFeatures.append(translation.features)\n",
        "        # if translation.features[0] < threshold_train:\n",
        "        if translation.score < threshold_test:\n",
        "            testY.append(0)\n",
        "        else:\n",
        "            testY.append(1)\n",
        "\n",
        "    return trainFeatures, trainY, testFeatures, testY\n",
        "\n",
        "featuresUsed = [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
        "# featuresUsed = [0]\n",
        "# featuresUsed = [0, 4]\n",
        "\n",
        "trainset = \"valid\"\n",
        "testset = \"test\"\n",
        "bleuThresholdTrain = 10\n",
        "bleuThresholdTest = 10\n",
        "\n",
        "trainFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/features.txt\")\n",
        "testFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/features.txt\")\n",
        "trainLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/result.txt\")\n",
        "testLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/result.txt\")\n",
        "\n",
        "trainSentences = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/sentences.txt\")\n",
        "testSentences = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/sentences.txt\")\n",
        "\n",
        "\n",
        "featuresTrain, _ = datasetReader(trainFeatures, trainLabels)\n",
        "featuresTest, _ = datasetReader(testFeatures, testLabels)\n",
        "\n",
        "featuresTrain = [[row[i] for i in featuresUsed] for row in featuresTrain]\n",
        "featuresTest = [[row[i] for i in featuresUsed] for row in featuresTest]\n",
        "\n",
        "trainTranslations = readTranslations(trainSentences, featuresTrain)\n",
        "testTranslations = readTranslations(testSentences, featuresTest)\n",
        "\n",
        "# Thresholds_train = np.linspace(-1.5, 0, 25).tolist()\n",
        "Thresholds_train = np.linspace(4, 28, 25).tolist()\n",
        "\n",
        "Thresholds_test = np.linspace(4, 28, 25).tolist()\n",
        "\n",
        "acceptedScores = []\n",
        "acceptedFraction = []\n",
        "\n",
        "useSentenceBLEUScore = True\n",
        "\n",
        "\n",
        "for index in range(len(Thresholds_test)):\n",
        "    trainFeatures, trainY, testFeatures, testY = getTrainTestSets(trainTranslations, testTranslations, Thresholds_train[index], Thresholds_test[index])\n",
        "\n",
        "    clf = trainRandomForestClassifier(trainFeatures, trainY)\n",
        "    # print(\"Using Average Logprob Decision Stump of \" + str(Thresholds_train[index]))\n",
        "    print(\"BLEU score = \" + str(Thresholds_test[index]))\n",
        "    predictions = clf.predict(testFeatures)\n",
        "    calculateAccuracy(predictions, testY)\n",
        "    print(\"##########################################\")\n",
        "    acceptedTranslations = np.array(testTranslations)[np.array(predictions) > 0]\n",
        "    rejectedTranslations = np.array(testTranslations)[np.array(predictions) < 1]\n",
        "    if useSentenceBLEUScore:\n",
        "        rejectedScore, acceptedScore = compute_exclued_included_sentenceBleuScore(acceptedTranslations, rejectedTranslations)\n",
        "    else:\n",
        "        rejectedScore, acceptedScore = compute_excluded_included_score(acceptedTranslations, rejectedTranslations)\n",
        "    acceptedScores.append(acceptedScore)\n",
        "    acceptedFraction.append(float(len(acceptedTranslations))/float(len(predictions)))\n",
        "\n",
        "plt.xlabel('Fraction Above Threshold') \n",
        "plt.ylabel('BLEU score (average)') \n",
        "plt.title('Random Forest Thresholding') \n",
        "\n",
        "r = random.random()\n",
        "b = random.random()\n",
        "g = random.random()\n",
        "c = (r, g, b)\n",
        "plt.scatter(acceptedFraction, acceptedScores, label = \"Random Forest Analysis\", color=c)\n",
        "\n",
        "acceptedScores = [x for _,x in sorted(zip(acceptedFraction,acceptedScores))]\n",
        "acceptedFraction.sort()\n",
        "\n",
        "print('AUC for incuded fraction: {}'.format(auc(acceptedFraction, acceptedScores)))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Random Forest classifier\n",
            "BLEU score = 4.0\n",
            "Correctly accepted = 0.9992784992784993\n",
            "Incorrectly rejected = 0.0007215007215006786\n",
            "Correctly rejected = 0.06349206349206349\n",
            "Incorrectly accepted = 0.9365079365079365\n",
            "Total Accuracy = 0.9784832451499118\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 5.0\n",
            "Correctly accepted = 0.9996349032493611\n",
            "Incorrectly rejected = 0.0003650967506388936\n",
            "Correctly rejected = 0.052083333333333336\n",
            "Incorrectly accepted = 0.9479166666666666\n",
            "Total Accuracy = 0.9675485008818342\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 6.0\n",
            "Correctly accepted = 0.9965792474344356\n",
            "Incorrectly rejected = 0.0034207525655644\n",
            "Correctly rejected = 0.0392156862745098\n",
            "Incorrectly accepted = 0.9607843137254902\n",
            "Total Accuracy = 0.927689594356261\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 7.0\n",
            "Correctly accepted = 0.982995951417004\n",
            "Incorrectly rejected = 0.01700404858299598\n",
            "Correctly rejected = 0.1178082191780822\n",
            "Incorrectly accepted = 0.8821917808219178\n",
            "Total Accuracy = 0.8716049382716049\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 8.0\n",
            "Correctly accepted = 0.9629133154602324\n",
            "Incorrectly rejected = 0.0370866845397676\n",
            "Correctly rejected = 0.2562814070351759\n",
            "Incorrectly accepted = 0.7437185929648241\n",
            "Total Accuracy = 0.8141093474426808\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 9.0\n",
            "Correctly accepted = 0.8890030832476875\n",
            "Incorrectly rejected = 0.11099691675231249\n",
            "Correctly rejected = 0.4465691788526434\n",
            "Incorrectly accepted = 0.5534308211473566\n",
            "Total Accuracy = 0.7502645502645503\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 10.0\n",
            "Correctly accepted = 0.7134183363691561\n",
            "Incorrectly rejected = 0.2865816636308439\n",
            "Correctly rejected = 0.7011784511784511\n",
            "Incorrectly accepted = 0.2988215488215489\n",
            "Total Accuracy = 0.708289241622575\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 11.0\n",
            "Correctly accepted = 0.5392934390771449\n",
            "Incorrectly rejected = 0.4607065609228551\n",
            "Correctly rejected = 0.8287292817679558\n",
            "Incorrectly accepted = 0.1712707182320442\n",
            "Total Accuracy = 0.6871252204585538\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 12.0\n",
            "Correctly accepted = 0.41578947368421054\n",
            "Incorrectly rejected = 0.5842105263157895\n",
            "Correctly rejected = 0.8997050147492626\n",
            "Incorrectly accepted = 0.10029498525073743\n",
            "Total Accuracy = 0.7051146384479717\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 13.0\n",
            "Correctly accepted = 0.3522012578616352\n",
            "Incorrectly rejected = 0.6477987421383649\n",
            "Correctly rejected = 0.935672514619883\n",
            "Incorrectly accepted = 0.06432748538011701\n",
            "Total Accuracy = 0.7393298059964727\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 14.0\n",
            "Correctly accepted = 0.2717391304347826\n",
            "Incorrectly rejected = 0.7282608695652174\n",
            "Correctly rejected = 0.9541604384653712\n",
            "Incorrectly accepted = 0.04583956153462876\n",
            "Total Accuracy = 0.7548500881834215\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 15.0\n",
            "Correctly accepted = 0.24061196105702365\n",
            "Incorrectly rejected = 0.7593880389429764\n",
            "Correctly rejected = 0.967391304347826\n",
            "Incorrectly accepted = 0.03260869565217395\n",
            "Total Accuracy = 0.783068783068783\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 16.0\n",
            "Correctly accepted = 0.17128874388254486\n",
            "Incorrectly rejected = 0.8287112561174551\n",
            "Correctly rejected = 0.9765976597659766\n",
            "Incorrectly accepted = 0.023402340234023433\n",
            "Total Accuracy = 0.8024691358024691\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 17.0\n",
            "Correctly accepted = 0.11044176706827309\n",
            "Incorrectly rejected = 0.8895582329317269\n",
            "Correctly rejected = 0.9905862216516902\n",
            "Incorrectly accepted = 0.00941377834830981\n",
            "Total Accuracy = 0.8359788359788359\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 18.0\n",
            "Correctly accepted = 0.14123006833712984\n",
            "Incorrectly rejected = 0.8587699316628702\n",
            "Correctly rejected = 0.9929048414023373\n",
            "Incorrectly accepted = 0.007095158597662743\n",
            "Total Accuracy = 0.8610229276895943\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 19.0\n",
            "Correctly accepted = 0.1099476439790576\n",
            "Incorrectly rejected = 0.8900523560209423\n",
            "Correctly rejected = 0.9922543823889115\n",
            "Incorrectly accepted = 0.0077456176110884956\n",
            "Total Accuracy = 0.87336860670194\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 20.0\n",
            "Correctly accepted = 0.08074534161490683\n",
            "Incorrectly rejected = 0.9192546583850931\n",
            "Correctly rejected = 0.9944289693593314\n",
            "Incorrectly accepted = 0.005571030640668551\n",
            "Total Accuracy = 0.890652557319224\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 21.0\n",
            "Correctly accepted = 0.0859106529209622\n",
            "Incorrectly rejected = 0.9140893470790378\n",
            "Correctly rejected = 0.9964622641509434\n",
            "Incorrectly accepted = 0.003537735849056589\n",
            "Total Accuracy = 0.9029982363315696\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 22.0\n",
            "Correctly accepted = 0.08979591836734693\n",
            "Incorrectly rejected = 0.9102040816326531\n",
            "Correctly rejected = 0.9953667953667954\n",
            "Incorrectly accepted = 0.004633204633204602\n",
            "Total Accuracy = 0.9171075837742504\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 23.0\n",
            "Correctly accepted = 0.08636363636363636\n",
            "Incorrectly rejected = 0.9136363636363636\n",
            "Correctly rejected = 0.9927342256214149\n",
            "Incorrectly accepted = 0.00726577437858511\n",
            "Total Accuracy = 0.9223985890652557\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 24.0\n",
            "Correctly accepted = 0.07\n",
            "Incorrectly rejected = 0.9299999999999999\n",
            "Correctly rejected = 0.9958254269449716\n",
            "Incorrectly accepted = 0.004174573055028441\n",
            "Total Accuracy = 0.9305114638447972\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 25.0\n",
            "Correctly accepted = 0.08620689655172414\n",
            "Incorrectly rejected = 0.9137931034482758\n",
            "Correctly rejected = 0.9962420142803458\n",
            "Incorrectly accepted = 0.0037579857196542443\n",
            "Total Accuracy = 0.9403880070546737\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 26.0\n",
            "Correctly accepted = 0.10067114093959731\n",
            "Incorrectly rejected = 0.8993288590604027\n",
            "Correctly rejected = 0.9959046909903202\n",
            "Incorrectly accepted = 0.004095309009679804\n",
            "Total Accuracy = 0.9488536155202821\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 27.0\n",
            "Correctly accepted = 0.03787878787878788\n",
            "Incorrectly rejected = 0.9621212121212122\n",
            "Correctly rejected = 0.9992600813910469\n",
            "Incorrectly accepted = 0.0007399186089530607\n",
            "Total Accuracy = 0.9544973544973545\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 28.0\n",
            "Correctly accepted = 0.03418803418803419\n",
            "Incorrectly rejected = 0.9658119658119658\n",
            "Correctly rejected = 0.9977924944812362\n",
            "Incorrectly accepted = 0.002207505518763808\n",
            "Total Accuracy = 0.9580246913580247\n",
            "##########################################\n",
            "AUC for incuded fraction: 16.610049304594067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de7gdZXn38e8vO8FsCcgpQCAJQY0QiiWWQLFaTAEt+kqAgkiqnPSVWlqrFSwSD0BtU70KaitVxKIBRA4Ska2CBpTDCwIhwYQQgso5IQEiEo6b0879/jHPCpOdvfaefZi19l7z+1zXuvasmVkz97NWcq9nPTNzjyICMzOrjlHNDsDMzBrLid/MrGKc+M3MKsaJ38ysYpz4zcwqxonfzKxinPitFJLOkPT9Zscx3EmaIikkjW7AvkLSmwfwul5jzH/WkiZLek5S22DjtfI48VeIpIckdab/mI9JmidpXLPjGgxJMyWtT22qPX7SwP33lRTPzcX1sqRXcs+vaVScjRIRj0TEuIjoanYsVp8Tf/UcEhHjgOnA24DTmhzPUFidkk3tcUh/N1BWDzUiPl6LC5gLXJaL87393V4jfhlY63Pir6iIeAz4BdkXAACSPivpfknPSrpH0uG5ZcdLulnSWZKekvSgpPfmlu8q6cb02muB7fL7kzRL0nJJ6yTdIGlabtlDkj4j6S5Jz0s6X9IOkq5J27tO0tb9baOkaWlf69K+Z+WWzZP0LUlXS3oe+CtJO0maL2ltat8/5dbfV9IiSc9IelzSV9Oim9LfdakX//b+xpl8SNIjkv4g6XO5/Z4h6QpJ35f0DHC8pDek92iNpEcl/Vvti0vSm9Pn8HTa1mXd9nOQpN+n9+R/JCm9bpSkz0t6WNITki6U9IY672vdz7r7L6D0/n9J0i1p/QWS8usfm/b5pKQvpH8LBw3wPbSiIsKPijyAh4CD0vREYBnwX7nlHwB2IusQfBB4HpiQlh0PvAJ8DGgD/h5YDSgtvxX4KvA6YH/gWeD7adlb0rbeDYwB/gW4D9gsF9dtwA7AzsATwJ1kv0jGAr8CTq/TppnAqh7mj0n7mANsBhyQYtotLZ8HPA28I7X39cBi4Itp/TcCDwB/nWvfMWl6HLBfmp4CBDC6wPt/Ru09yc2rvf47QDuwF/ASMC33mleAw1Kc7cCVwLeBzYHtgYXA36X1LwE+l9YdC7wzt68AfgpsBUwG1gIHp2UfSe/XG1P7fgRc1FMb+/isu697A3B/+jfQnp5/OS3bA3gOeGd6z89KbT2o2f9XWv3R9AD8aOCHnSXY59J/1AB+CWzVy/pLgEPT9PHAfbllr0/b2DElkVeBzXPLf5BLBl8ALs8tGwU8CszMxfWh3PL5wLdyzz8B/LhOjDOB9cC63OMo4C+Bx4BRuXUvAc5I0/OAC3PL/hx4pNu2TwO+l6ZvAs4Etuu2zkaJro/3/wzqJ/6JuXkLgaNzr7kpt2wHsi+G9ty82cD1afpC4Lz89nLrBRt/EVwOfDZN/xI4Kbdst5SER+fbWOCz3uj9IEv0n8+texLw8zT9ReCSbv+mXsaJv/SHh3qq57CI2IIsYe7Oxj/Tj5W0JA0DrAP2ZOMhm8dqExHxQpocR/Yr4amIeD637sO56Z3yzyNiPbCSrHdf83huurOH570dhF4dEVvlHpenfa5M+8rHlN/nytz0LsBOtban9s8hS7QAHyXrtd4r6Q5J7+8lnoF4LDf9Ahu3t3ucY4A1uTi/Tdbzh+zXlICFaXjrIwX3s9FnlKZH81r7ya3X22fdk972uaFt6d/Uk31sy4aADxRVVETcKGke2c/rwyTtQjbccCBwa0R0SVpClkT6sgbYWtLmuYQwmaznB9mQ0FtrK6dx5Ulkvf6yrAYmSRqVS/6Tgd/l1smXpl0JPBgRU3vaWET8HpgtaRTwN8AVkrbtto2ydI/zJbJfHq/2EOdjZMNxSHoncJ2kmyLivj72sZrsS6Wm1rN/nGxYsKavz7o/1pD9siDF2w5sO4DtWD+5x19tXwfeLWkvsvHiIBv3RdIJZD3+PkXEw8Ai4ExJm6WEkz+z5nLg/0g6UNIY4GSy5PXrIWvJpm4n613+i6QxkmammC6ts/5C4FlJp0pql9QmaU9J+wBI+rCk8elLZF16zXqy92s92dh46SJiDbAAOFvSlumg7JskvSvF+QFJtUT9FNlnur7O5vIuAf45HbjNn4G00ZdLgc+6P64ADpH0F5I2IxvWKtLRsEFy4q+wiFhLNib8xYi4Bzib7MDd42Q99Fv6sbm/JRsn/yNwetpubT+/BT4MfAP4A1miOCQiXh6CZvQobfsQ4L1pn98Ejo2Ie+us3wW8n+wspwfTa/4XqJ3ZcjCwXNJzwH+RjcF3puGJfwduSUMv+5XVppxjyQ6G3kOW3K8AJqRl+wC3pzg7gE9GxAMFtvld4CKyYxkPAi+SHVvpSd3Puj8iYnnax6Vkvf/nyA7svzSQ7VlxtTMyzMyaKv3SWAdMjYgHmx1PK3OP38yaRtIhkl4vaXOy403LyM7yshI58ZtZMx1KdmB5NTCVbAjNwxAl81CPmVnFuMdvZlYxI+I8/u222y6mTJnS7DDMzEaUxYsX/yEixnefPyIS/5QpU1i0aFGzwzAzG1Ek9XhVtYd6zMwqxonfzKxinPjNzCrGid/MrGKc+M3MKqZlE//Kjvks2H9vrpq6Iwv235uVHfObHZKZ2bAwIk7n7K+VHfNZOudkul7sBKBz9SqWzjkZgEmzjmhmaGZmTdeSPf4VZ83dkPRrul7sZMVZc5sUkZnZ8NGSib9zTc83dqo338ysSloy8bdP2Llf883MqqQlE/+0U+bQNrZ9o3ltY9uZdsqcJkVkZjZ8tOTB3doB3BVnzaVzzaO0T9iZaafM8YFdMzNaNPFDlvyd6M3MNtWSQz1mZlafE7+ZWcU48ZuZVYwTv5lZxTjxm5lVTGmJX9JYSQslLZW0XNKZaf48SQ9KWpIe08uKwczMNlXm6ZwvAQdExHOSxgA3S7omLftMRFxR4r7NzKyO0hJ/RATwXHo6Jj2irP2ZmVkxpY7xS2qTtAR4Arg2Im5Pi/5d0l2SvibpdXVee6KkRZIWrV27tswwzcwqpdTEHxFdETEdmAjsK2lP4DRgd2AfYBvg1DqvPS8iZkTEjPHjx5cZpplZpTTkrJ6IWAdcDxwcEWsi8xLwPWDfRsRgZmaZMs/qGS9pqzTdDrwbuFfShDRPwGHA3WXFYGZmmyrzrJ4JwAWS2si+YC6PiJ9K+pWk8YCAJcDHS4zBzMy6KfOsnruAt/Uw/4Cy9mlmZn3zlbtmZhXjxG9mVjFO/GZmFePEb2ZWMU78ZmYV48RvZlYxTvxmZhXjxG9mVjFO/GZmFePEb2ZWMU78ZmYV48RvZlYxTvxmZhXjxG9mVjFO/GZmFePEb2ZWMU78ZmYV48RvZlYxLZ/4V3bMZ8H+e3PV1B1ZsP/erOyY3+yQzMyaqsybrTfdyo75LJ1zMl0vdgLQuXoVS+ecDMCkWUc0MzQzs6Zp6R7/irPmbkj6NV0vdrLirLlNisjMrPlaOvF3rnm0X/PNzKqgpRN/+4Sd+zXfzKwKWjrxb/9XB/VrvplZFbR04n/i+uv6Nd/MrApaOvF7jN/MbFMtnfg9xm9mtqmWTvzTTplD29j2jea1jW1n2ilzmhSRmVnztfQFXLWLtFacNZfONY/SPmFnpp0yxxdvmVml9Zr4JU0Ejgb+EtgJ6ATuBn4GXBMR60uPcJAmzTrCid7MLKfuUI+k7wHfBV4GvgLMBk4CrgMOBm6WtH8jghwM1+oxM9tYbz3+syPi7h7m3w38SNJmwORywhoartVjZrapuj3+fNKX1C5pt27LX46I+8oMbrBcq8fMbFN9ntUjaRawBPh5ej5dUkeB142VtFDSUknLJZ2Z5u8q6XZJ90m6LP1yKIXP4zcz21SR0zlPB/YF1gFExBJg1wKvewk4ICL2AqYDB0vaj+x4wdci4s3AU8BHBxJ4ET6P38xsU0US/ysR8XS3edHXiyLzXHo6Jj0COAC4Is2/ADisYKz95vP4zcw2VSTxL5f0t0CbpKmSvgH8usjGJbVJWgI8AVwL3A+si4hX0yqrgB6735JOlLRI0qK1a9cW2d0mJs06gr3mnk37ThNBon2niew192wf2DWzSlNE7513Sa8HPge8BxDwC+BLEfFi4Z1IWwFXAl8A5qVhHiRNIrseYM/eXj9jxoxYtGhR0d2ZmRkgaXFEzOg+v88rdyPiBbLE/7mB7jwi1km6Hng7sJWk0anXPxHwkVYzswbqM/FL+gmbjuk/DSwCvl2v5y9pPNnxgXWS2oF3kx3YvR44ErgUOA64auDhF7Pk9FN55NKLiK4u1NbG5KOPYfqZXyl7t2Zmw1KRMf4HgOeA76THM8CzwFvS83omANdLugu4A7g2In4KnAp8WtJ9wLbA+QMPv29LTj+Vhy+eR3R1ARBdXTx88TyWnH5qmbs1Mxu2iozx3xER+/Q0T9LyiPiTUiNkcGP8HbvttCHp56mtjVm/XT3Y0MzMhq16Y/xFevzjJG0ozZCmx6WnLw9RfKXpKen3Nt/MrNUVKct8MllBtvvJzurZFThJ0uZk5+EPa2prq9vjNzOroiJn9VwtaSqwe5r129wB3a+XFtkQmXz0MTx88bwe55uZVVHRG7FMBXYDxgJ7SSIiLiwvrMFb2TF/ww1Y2l6/OV2dL0CEz+oxs8orcjrn6cBMYA/gauC9wM3AsE383csxd73wPG1j233VrpkZxQ7uHgkcCDwWEScAewFvKDWqQXI5ZjOz+ook/s50i8VXJW1JVndnUrlhDY7LMZuZ1Vck8S9KtXa+AywG7gRuLTWqQXI5ZjOz+npN/JIE/EdErIuIc8nKLhyXhnyGLZdjNjOrr9fEH9llvVfnnj8UEXeVHtUg9VSOeeIRH2TFWXN903Uzq7wip3PeKWmfiLij9GiG0KRZR2w4g2dlx3x+c+qniFeyC407V6/iN6d+asN6ZmZVUmSM/8+BWyXdL+kuSctS4bURY9mXPr8h6dfEKy+z7Eufb1JEZmbNU6TH/9elR1GyV576Y935V03dkfYJOzPtlDnu/ZtZJfTZ44+Ih8lO3zwgTb9Q5HUjRgSdq1exdM7JHvc3s0roM4GnK3dPBU5Ls8YA3y8zqKE2Zqut+1zHF3iZWVUU6bkfDswCngeIiNXAFmUGNdTe+sV/R6PH9LmeL/AysyooMsb/ckSEpABI5ZhHlNrY/Z2fPqnX9XyBl5lVQZEe/+WSvk12k/SPAdfR+y0Xh6VJs47Izuuvwxd4mVlVFDm4exZwBTCfrDTzFyPiG2UHVoaeruiF7BiAK3eaWVUUKcv8aeCyiLi2AfGUqpbYa3X6fRqnmVVRkTH+LYAFkv4IXAb8MCIeLzes8uSv6DUzq6IiQz1nRsSfAP8ATABulHRd6ZGZmVkp+nMh1hPAY8CTwPblhGNmZmUrcgHXSZJuAH4JbAt8LCL+tOzAzMysHEXG+CcBn4qIJWUHY2Zm5esz8UfEaQCStgfG5uY/UmJcZmZWkiJDPYdI+j3wIHAj8BBwTclxmZlZSYoc3P03YD/gdxGxK3AgcFupUZmZWWmKJP5XIuJJYJSkURFxPTCj5LjMzKwkRQ7urpM0DrgJuFjSE6RKnWZmNvIU6fEfSnbzlX8Gfg7cDxxSZlBmZlaeuolfkgAi4vmIWB8Rr0bEBRHx32noZ8M6I9HKjvks2H9vrpq6Iwv239t33zKzyuitx3+9pE9ImpyfKWkzSQdIugA4rt6LJU2SdL2keyQtl/TJNP8MSY9KWpIe7xuaphS3smM+S+ecTOfqVb71oplVTm+J/2CgC7hE0uqUwB8Efg/MBr4eEfN6ef2rwMkRsQfZWUH/IGmPtOxrETE9Pa4efDP6Z8VZc+l6sXOjeb71oplVRd2DuxHxIvBN4JuSxgDbAZ0Rsa7IhiNiDbAmTT8raQUwLG5xVe8Wi771oplVQaEibRHxSkSsKZr0u5M0BXgbcHua9Y+S7pL0XUl93wl9iNW7xaJvvWhmVdCf6pwDkk4FnU9W7+cZ4FvAm4DpZL8Izq7zuhMlLZK0aO3atUMaU0934vKtF82sKkpN/GmIaD5wcUT8CCAiHo+IrohYT3bv3n17em1EnBcRMyJixvjx44c0rkmzjmCvuWdn9+CVaN9pom+9aGaVUeQCLiTtAkyNiOsktQOjI+LZPl4j4HxgRUR8NTd/Qhr/BzgcuHtgoQ+O78RlZlVV5J67HwNOBLYhG6KZCJxLVrOnN+8AjgGWSaqVdJ4DzJY0HQiygm9/N6DIzcxsQIr0+P+BbDjmdoCI+H0q0dyriLgZ6OkCr4afvmlmZq8pMsb/UkS8XHsiaTRZb93MzEagIon/RklzgHZJ7wZ+CPyk3LDMzKwsRRL/qcBaYBnZePzVwOfLDMrMzMrT6xi/pDZgeUTsTnbqZWWs7JjPirPm0rnmUdon7My0U+b4LCAzawm9Jv6I6JL0W0mTq3SP3VoRt1o9n1oRN8DJ38xGvCJDPVsDyyX9UlJH7VF2YM3kIm5m1sqKnM75hdKjGGZcxM3MWlmfPf6IuBG4F9giPVakeS3LRdzMrJX1mfglHQUsBD4AHAXcLunIsgNrJhdxM7NWVmSo53PAPhHxBICk8cB1wBVlBtZMtQO4PqvHzFpRkcQ/qpb0kydpQDnnZnMRNzNrVUUS/88l/QK4JD3/IHBNeSGZmVmZ+kz8EfEZSX8DvDPNOi8iriw3LDMzK0uRssy7AlfXbqQiqV3SlIh4qOzgzMxs6BUZq/8hsD73vCvNMzOzEahI4h+dL8ucpjcrLyQzMytTkcS/VtKs2hNJhwJ/KC+kkWVlx3wW7L83V03dkQX7783KjvnNDsnMrFdFzur5OHCxpHPI7qi1Eji21KhGCBdzM7ORqEjJhvsjYj9gD2BaRPxFRNxXfmjDn4u5mdlIVKRkwyclbQk8D3xd0p2S3lN+aMOfi7mZ2UhUZIz/IxHxDPAeYFvgGODLpUY1QriYm5mNREUSv9Lf9wEXRsTy3LxKczE3MxuJihzcXSxpAbArcJqkLdj4vP7KcjE3MxuJFBG9ryCNAqYDD0TEOknbAjtHxF2NCBBgxowZsWjRokbtzsysJUhaHBEzus8vUqtnPXBn7vmTZBU6zcxsBGr58spmZrYxJ34zs4qpm/glbdPtsbUkn83TTy7pYGbDTW9j/IuBYONTN8dJWgr8X5dl7ptLOpjZcFS3xx8Ru0bEG9Pf2mM88E3g3MaFOHK5pIOZDUf9HuNPN2TZvoRYWo5LOpjZcNTvxC9p3EBeV0Uu6WBmw1HdMX5Jn+5h9tbALOCc0iJqIdNOmbPRGD+4pIOZNV9vB3e36PY8gMeAD0fEsr42LGkScCGwQ3rteRHxX5K2AS4DpgAPAUdFxFP9D334c0kHMxuO+izZ0OOLpNER8Wof60wAJkTEnam+z2LgMOB44I8R8WVJnwW2johTe9uWSzaYmfVfvZINvZ3Hf3Nu+qJuixf2tcOIWBMRd6bpZ4EVwM7AocAFabULyL4MzMysQXo7SLt5bnrPbsv6dSGXpCnA24DbgR0iYk1a9BjZUFBPrzlR0iJJi9auXduf3ZmZWS96S/xRZ7qn53Wls4DmA59KN3R5bSPZOFOP24qI8yJiRkTMGD9+fNHdtRRf9WtmZejt4O5Wkg4n+3LYStLfpPkC3lBk45LGkCX9i9P5/wCPS5oQEWvScYAnBhh7S/NVv2ZWlt56/DeSnbr5/jR9SHq8H7iprw2nuj7nAysi4qu5RR3AcWn6OOCq/ofd+nzVr5mVpW6PPyJOqLdMUpEu5zvI7s+7TNKSNG8O2f16L5f0UeBh4Kji4VaHr/o1s7IUufViT75GNoRTV0TcTP2DwAcOcL+V0T5hZzpXr+pxvpnZYAy09ILLM5fMN3I3s7IMtMff/6u+rF981a+ZlaW3Wj3L6DnBizrn3tvQmjTrCCd6MxtyvfX439+wKMzMrGF6uxHLw90fwPPAI2naRhhfEGZm0Hutnv0k3SDpR5LeJulu4G6yC7AOblyINhRqF4R1rl4FERsuCHPyN6ue3s7qOQeYC1wC/IrsPrs7AvsD/9GA2GwI+YIwM6vpLfGPjogFEfFD4LGIuA0gIu5tTGg2lHxBmJnV9Jb41+emO7st8+mcI4xvA2lmNb0l/r0kPSPpWeBP03Tt+VsbFJ8NEV8QZmY1vdXqaWtkIFYuXxBmZjUDvXLXRiBfEGZmMPBaPWZmNkI58ZuZVYwTv5lZxTjxm5lVjBO/mVnFOPFb07l4nFlj+XROa6pa8bhaHaFa8TjAp56alcQ9fmsqF48zazwnfmsqF48zazwnfmsqF48zazwnfmsqF48zazwf3LWmcvE4s8Zz4remc/E4s8byUI+ZWcU48ZuZVYwTv5lZxTjxm5lVjBO/WQO4HpENJz6rx6xkrkdkw417/GYlcz0iG26c+M1K5npENtyUlvglfVfSE5Luzs07Q9Kjkpakx/vK2r/ZcOF6RDbclNnjnwcc3MP8r0XE9PS4usT9mw0Lrkdkw01piT8ibgL+WNb2zUaKSbOOYK+5Z9O+00SQaN9pInvNPdsHdq1pmnFWzz9KOhZYBJwcEU/1tJKkE4ETASZPntzA8MyGnusR2XDS6IO73wLeBEwH1gBn11sxIs6LiBkRMWP8+PGNis/MrOU1NPFHxOMR0RUR64HvAPs2cv9mZtbgxC9pQu7p4cDd9dY1M7NylDbGL+kSYCawnaRVwOnATEnTgQAeAv6urP2bmVnPSkv8ETG7h9nnl7U/M2sNKzvm+45sJXOtHjMbNlzXqDFcssHMhg3XNWoMJ34zGzZc16gxnPjNbNhwXaPGcOI3s2HDdY0aw4nfzIaNkVLXaKTfUc1n9ZjZsDLc6xq1wplH7vGbmfVDK5x55MRvZtYPQ3HmUbOHijzUY2bWD+0TdqZz9aoe5xfR11DRhiuXc/tQWxuTjz6G6Wd+ZQha4B6/mVm/DPbMo96GimpfCt2/WKKri4cvnseS008dVOw1TvxmZv0w2DOPehsq6ulLIe+RSy8aUMzdeajHzKyfBnPmUW9DRX0dJ4iurgHtszv3+M3MGqi3oaK+jhOorW1IYnCP38ysgWq/FOqVns4f+O1u8tHHDEkMTvxmZg1Wb6hooy+FEs/qceI3MxtGGnHlssf4zcwqxonfzKxinPjNzCrGid/MrGKc+M3MKkYR0ewY+iRpLfDwAF66HfCHIQ5nJKhiu93manCb+2eXiBjffeaISPwDJWlRRMxodhyNVsV2u83V4DYPDQ/1mJlVjBO/mVnFtHriP6/ZATRJFdvtNleD2zwEWnqM38zMNtXqPX4zM+vGid/MrGJaIvFLOljSbyXdJ+mzPSx/naTL0vLbJU1pfJRDq0CbPy3pHkl3SfqlpF2aEedQ6qvNufWOkBSSWuK0vyLtlnRU+ryXS/pBo2McagX+fU+WdL2k36R/4+9rRpxDRdJ3JT0h6e46yyXpv9P7cZekPxvUDiNiRD+ANuB+4I3AZsBSYI9u65wEnJumjwYua3bcDWjzXwGvT9N/X4U2p/W2AG4CbgNmNDvuBn3WU4HfAFun59s3O+4GtPk84O/T9B7AQ82Oe5Bt3h/4M+DuOsvfB1wDCNgPuH0w+2uFHv++wH0R8UBEvAxcChzabZ1DgQvS9BXAgZLUwBiHWp9tjojrI+KF9PQ2YGKDYxxqRT5ngC8BXwFebGRwJSrS7o8B/xMRTwFExBMNjnGoFWlzAFum6TcAqxsY35CLiJuAP/ayyqHAhZG5DdhK0oSB7q8VEv/OwMrc81VpXo/rRMSrwNPAtg2JrhxF2pz3UbLewkjWZ5vTz99JEfGzRgZWsiKf9VuAt0i6RdJtkg5uWHTlKNLmM4APS1oFXA18ojGhNU1//8/3ynfganGSPgzMAN7V7FjKJGkU8FXg+CaH0gyjyYZ7ZpL9srtJ0lsjYl1ToyrXbGBeRJwt6e3ARZL2jIj1zQ5sJGiFHv+jwKTc84lpXo/rSBpN9tPwyYZEV44ibUbSQcDngFkR8VKDYitLX23eAtgTuEHSQ2TjoB0tcIC3yGe9CuiIiFci4kHgd2RfBCNVkTZ/FLgcICJuBcaSFTNrVYX+zxfVCon/DmCqpF0lbUZ28Laj2zodwHFp+kjgV5GOmIxQfbZZ0tuAb5Ml/ZE+5gt9tDkino6I7SJiSkRMITuuMSsiFjUn3CFT5N/3j8l6+0jajmzo54FGBjnEirT5EeBAAEnTyBL/2oZG2VgdwLHp7J79gKcjYs1ANzbih3oi4lVJ/wj8guxsgO9GxHJJ/wosiogO4Hyyn4L3kR1AObp5EQ9ewTb/JzAO+GE6jv1IRMxqWtCDVLDNLadgu38BvEfSPUAX8JmIGLG/aAu2+WTgO5L+mexA7/EjuTMn6RKyL+/t0nGL04ExABFxLtlxjPcB9wEvACcMan8j+L0yM7MBaIWhHjMz6wcnfjOzinHiNzOrGCd+M7OKceI3M6sYJ34bEpK6JC3JPaYMcnvT8xUXJc3qrSLnALZ/WKrguXtu3kxJPx2qffSx/yvT+3SfpKdz79tfSHoonY8/lPvrd9sk3dDTBXCSjpd0ztBFZ4024s/jt2GjMyKm97QgFcRTPy+nn05WauJqgHTu9lCeqz8buDn9PX0It1tIRBwOWUIGTomI99eWFakfKGl0qjtl1m/u8VspJE1J9dQvBO4GJkn6lqRFqWb8mbl195H0a0lLJS2U9AbgX4EPpl7wB/O9zLTtX+m1ew1MTvPnpZrlv5b0gKQj68Q2Dngn2WX/3S/m21LSz1Ls56YaQEiaLWmZpLslfSXN+7ik/8xtNx/jh1Nblkj6tqS2fr6Fn5B0Z9rn7mmbZ0i6SNItZBckjpc0X9Id6fGOtN67cr8gfiNpi7TNcZKukHSvpIvTFzKSDkzrLVNWF/51PbxnJ0j6naSFwDv62RYbbppdh9qP1niQXTG6JD2uBKYA64H9cutsk/62ATcAf0pWb/0BYJ+0bEuyX6LHA+fkXrvhOfAT4Lg0/RHgx2l6HvBDsg7NHmSlfXuK9UPA+Wn618DeaXomWTnnN/J39sMAAAMNSURBVKYYryUr8bETWYmA8Sm2XwGHpef35bZ7DdkXyrQU45g0/5vAsXVimQn8tNu8h4BPpOmTgP9N02cAi4H29PwHwDvT9GRgRe79eUeaHpdinklWlXZien9uTbGOJav6+Ja0/oXAp9L0DWS/uibk2r8ZcEv+s/Fj5D3c47eh0hkR09Pj8DTv4chqh9ccJelOspuG/AlZct4NWBMRdwBExDPR9xDG28mSHsBFZAms5scRsT4i7gF2qPP62WQ13kl/Z+eWLYysDnwXcEna9j7ADRGxNsV2MbB/RKwFHpC0n6Rtgd3JkuKBwN7AHZKWpOdv7KNN3f0o/V1M9iVa0xERnWn6IOCctI8Osl8r41IMX5X0T8BWufdzYUSsimzIbUna7m7AgxHxu7TOBWQ3Bcn781z7XwYu62dbbJjxGL+V6fnahKRdgVPIevZPSZpH1tscavkqpJsMlkvaBjgAeKukIOvZh6TPpFW61zDpq6bJpcBRwL3AlRERaQjlgog4bSANSGrt6GLj/6fP56ZHkf2i6n7TmS9L+hlZbZdbJP11t232tF2rEPf4rVG2JEtaT0vaAXhvmv9bYIKkfQAkbaGsdPazZKWWe/JrXhub/xDw//oRx5HARRGxS2SVPCcBDwJ/mZbvq6wq5Cjgg2QHgBcC75K0XRqrnw3cmNa/kuzuSPlfEb8EjpS0fWrTNirnnscLyN2ARNL09PdNEbEsIr5CVuly9zqvh+z9nyLpzen5MbzWtprbydq/raQxwAeGqgHWHE781hARsZRsiOdesmGaW9L8l8kS7DckLSUbVx8LXA/sUTu4221znwBOkHQXWaL6ZD9CmU2WrPPm89pwzx3AOcAKsi+EKyMrf/vZFNNSYHFEXJXifyqtu0tELEzz7gE+DyxIMV5LNk4+1P4JmJEOct8DfDzN/1Q6CH0X8Aq93H0t/Vo4gayK6zKy4zLndltnDdnxhVvJPrcVQ90QayxX5zQzqxj3+M3MKsaJ38ysYpz4zcwqxonfzKxinPjNzCrGid/MrGKc+M3MKub/AwMEcbGYByXnAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}