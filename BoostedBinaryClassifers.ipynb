{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BoostedBinaryClassifers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhruvaBansal00/ConfidentMT/blob/master/BoostedBinaryClassifers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEk99K4f0Hw_",
        "colab_type": "code",
        "outputId": "e806cd1a-01a7-4242-8863-e7c9ec7d3fe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!ls\n",
        "%cd drive/My Drive/ConfidentMachineTranslation/flores\n",
        "!ls\n",
        "!pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "drive  sample_data\n",
            "/content/drive/My Drive/ConfidentMachineTranslation/flores\n",
            "'=0.5.0'\t\t\t Ensembling\n",
            " analysis\t\t\t FLORES.ipynb\n",
            " Analysis\t\t\t LanguageAnalysis.ipynb\n",
            " backward_models\t\t language_models\n",
            " BoostedBinaryClassifers.ipynb\t LM_Thresholding.ipynb\n",
            " checkpoints\t\t\t NCD_Analysis.ipynb\n",
            " ClassificationDataset\t\t NNClassification.ipynb\n",
            " configs\t\t\t noisychannel\n",
            " data\t\t\t\t NoisyChannel.ipynb\n",
            " data-bin\t\t\t Resources\n",
            " Ensembles\t\t\t scripts\n",
            "/content/drive/My Drive/ConfidentMachineTranslation/flores\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlcgFl162kdH",
        "colab_type": "code",
        "outputId": "d95850c6-2d66-488e-ce3e-41b4c83dffc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# prints how much GPU RAM is available\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=8d617771c9b0b2aad6c9b84c6f42d015bc9341b147b53cc57d4d5236b2f5f9f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  | Proc size: 159.7 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xwd7lNk3EZn",
        "colab_type": "code",
        "outputId": "2af3b240-ee8a-45d2-a2ba-bb8a44954b0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "import numpy as np\n",
        "from itertools import zip_longest\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "def printDatasetClassProp(Y): \n",
        "    classes = {}\n",
        "    total = len(Y)\n",
        "    for i in Y:\n",
        "        if i in classes:\n",
        "            classes[i] += 1\n",
        "        else:\n",
        "            classes[i] = 1\n",
        "    \n",
        "    for cls in classes:\n",
        "        print(\"Proportion in class \" + str(cls) + \" = \" + str(classes[cls]/total))\n",
        "\n",
        "def datasetReader(featureFile, labelFile):\n",
        "    files = [featureFile, labelFile]\n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    for lines in zip_longest(*files, fillvalue=''):\n",
        "        currX, currY = lines[0], float(lines[1].strip(\"\\n\"))\n",
        "        Xarr = []\n",
        "        features = currX.split()\n",
        "        for feature in features:\n",
        "            Xarr.append(float(feature.strip(\",\").strip(\"\\n\")))\n",
        "        X.append(Xarr)\n",
        "        Y.append(currY)\n",
        "    \n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "\n",
        "def computeSimilarity(o1, o2):\n",
        "    total = len(o1)\n",
        "    same = 0\n",
        "    for i in range(len(o1)):\n",
        "        if o1[i] == o2[i]:\n",
        "            same += 1\n",
        "    print(same/total)\n",
        "\n",
        "def trainGaussianProcessClassifier(X, Y):\n",
        "    print(\"Training Gaussian Process Classifier\")\n",
        "    length_scale = [1 for i in range(len(X[0]))]\n",
        "    clf = GaussianProcessClassifier(1.0 * RBF(length_scale), warm_start=True, random_state=42, n_jobs=-1)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainEnsembleClassifier(X, Y, maxDepth=8, estimators=100):\n",
        "    print(\"Training an ensemble of Random Forest, AdaBoosting and Gradient Boosting Classifiers\")\n",
        "\n",
        "    estimators = [\n",
        "     ('rf', RandomForestClassifier(max_depth=maxDepth, random_state=42)),\n",
        "     ('ada', AdaBoostClassifier(n_estimators=estimators, random_state=42)),\n",
        "     ('grad', GradientBoostingClassifier(random_state=42))]\n",
        "    clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "\n",
        "def trainRandomForestClassifier(X, Y, maxDepth=8):\n",
        "    print(\"Training Random Forest classifier\")\n",
        "    clf = RandomForestClassifier(max_depth=maxDepth, random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainAdaBoostClassifier(X, Y, estimators=100):\n",
        "    print(\"Training AdaBoosted Decision Tree classifier\")\n",
        "    clf = AdaBoostClassifier(n_estimators=estimators, random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainGradientBoostingClassifier(X, Y):\n",
        "    print(\"Training Graident Boosted classifier\")\n",
        "    clf = GradientBoostingClassifier(random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainSVM(X, Y):\n",
        "    print(\"Training SVM classifier\")\n",
        "    clf = SVC(gamma='auto')\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def calculateAccuracy(predictedClasses, groundTruth):\n",
        "    correct_accepted = 0\n",
        "    total_accepted = 0\n",
        "\n",
        "    correct_rejected = 0\n",
        "    total_rejected = 0\n",
        "\n",
        "    for i in range(len(predictedClasses)):\n",
        "        if groundTruth[i] == 1:\n",
        "            total_accepted += 1\n",
        "            if predictedClasses[i] == groundTruth[i]:\n",
        "                correct_accepted += 1\n",
        "        else:\n",
        "            total_rejected += 1\n",
        "            if predictedClasses[i] == groundTruth[i]:\n",
        "                correct_rejected += 1\n",
        "\n",
        "\n",
        "    print(\"Correctly accepted = \" + str(correct_accepted/total_accepted))\n",
        "    print(\"Incorrectly accepted = \" + str(1 - correct_rejected/total_rejected))\n",
        "    print(\"Correctly rejected = \" + str(correct_rejected/total_rejected))\n",
        "    print(\"Incorrectly rejected = \" + str(1 - correct_accepted/total_accepted))\n",
        "\n",
        "    print(\"Total Accuracy = \" + str((correct_accepted + correct_rejected)/(total_accepted + total_rejected)))\n",
        "\n",
        "\n",
        "trainset = \"valid\"\n",
        "testset = \"test\"\n",
        "bleuThresholdTrain = 10\n",
        "bleuThresholdTest = 10\n",
        "\n",
        "trainFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/features.txt\")\n",
        "testFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/features.txt\")\n",
        "\n",
        "trainLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/result.txt\")\n",
        "testLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/result.txt\")\n",
        "\n",
        "trainX, trainY = datasetReader(trainFeatures, trainLabels)\n",
        "testX, testY = datasetReader(testFeatures, testLabels)\n",
        "\n",
        "printDatasetClassProp(trainY)\n",
        "\n",
        "\n",
        "classifiers = [trainRandomForestClassifier, trainAdaBoostClassifier, trainGradientBoostingClassifier, trainSVM, trainGaussianProcessClassifier]\n",
        "outputs = []\n",
        "\n",
        "for classifier in classifiers:\n",
        "    print(\"#################################################\")\n",
        "    curr = classifier(trainX, trainY)\n",
        "    predictions = np.array(curr.predict(testX))\n",
        "    calculateAccuracy(predictions, testY)\n",
        "    outputs.append(predictions)\n",
        "    print(\"#################################################\")\n",
        "\n",
        "for output_1 in outputs:\n",
        "    for output_2 in outputs:\n",
        "        computeSimilarity(output_1, output_2)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Proportion in class 1.0 = 0.5287221570926143\n",
            "Proportion in class 0.0 = 0.4712778429073857\n",
            "#################################################\n",
            "Training Random Forest classifier\n",
            "Correctly accepted = 0.7030965391621129\n",
            "Incorrectly accepted = 0.2861952861952862\n",
            "Correctly rejected = 0.7138047138047138\n",
            "Incorrectly rejected = 0.2969034608378871\n",
            "Total Accuracy = 0.7075837742504409\n",
            "#################################################\n",
            "#################################################\n",
            "Training AdaBoosted Decision Tree classifier\n",
            "Correctly accepted = 0.6964177292046144\n",
            "Incorrectly accepted = 0.32407407407407407\n",
            "Correctly rejected = 0.6759259259259259\n",
            "Incorrectly rejected = 0.3035822707953856\n",
            "Total Accuracy = 0.6878306878306878\n",
            "#################################################\n",
            "#################################################\n",
            "Training Graident Boosted classifier\n",
            "Correctly accepted = 0.7061323618700668\n",
            "Incorrectly accepted = 0.29461279461279466\n",
            "Correctly rejected = 0.7053872053872053\n",
            "Incorrectly rejected = 0.2938676381299332\n",
            "Total Accuracy = 0.7058201058201058\n",
            "#################################################\n",
            "#################################################\n",
            "Training SVM classifier\n",
            "Correctly accepted = 0.9890710382513661\n",
            "Incorrectly accepted = 0.9907407407407407\n",
            "Correctly rejected = 0.009259259259259259\n",
            "Incorrectly rejected = 0.010928961748633892\n",
            "Total Accuracy = 0.5784832451499118\n",
            "#################################################\n",
            "#################################################\n",
            "Training Gaussian Process Classifier\n",
            "Correctly accepted = 0.6988463873709775\n",
            "Incorrectly accepted = 0.2912457912457912\n",
            "Correctly rejected = 0.7087542087542088\n",
            "Incorrectly rejected = 0.3011536126290225\n",
            "Total Accuracy = 0.7029982363315697\n",
            "#################################################\n",
            "1.0\n",
            "0.8567901234567902\n",
            "0.9192239858906526\n",
            "0.5238095238095238\n",
            "0.9008818342151675\n",
            "0.8567901234567902\n",
            "1.0\n",
            "0.8754850088183421\n",
            "0.5393298059964726\n",
            "0.8634920634920635\n",
            "0.9192239858906526\n",
            "0.8754850088183421\n",
            "1.0\n",
            "0.5305114638447972\n",
            "0.8899470899470899\n",
            "0.5238095238095238\n",
            "0.5393298059964726\n",
            "0.5305114638447972\n",
            "1.0\n",
            "0.5227513227513227\n",
            "0.9008818342151675\n",
            "0.8634920634920635\n",
            "0.8899470899470899\n",
            "0.5227513227513227\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ_gNXTbla-G",
        "colab_type": "code",
        "outputId": "66aa5351-d82d-4022-8cbb-25211ffa0712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "set1 = \"train\"\n",
        "set2 = \"valid\"\n",
        "\n",
        "\n",
        "set1Features = open(\"ClassificationDataset/\"+set1+\"/features.txt\")\n",
        "set2Features = open(\"ClassificationDataset/\"+set2+\"/features.txt\")\n",
        "\n",
        "set1Labels = open(\"ClassificationDataset/\"+set1+\"/result.txt\")\n",
        "set2Labels = open(\"ClassificationDataset/\"+set2+\"/result.txt\")\n",
        "\n",
        "\n",
        "_,set1Labels = datasetReader(set1Features, set1Labels)\n",
        "_,set2Labels = datasetReader(set2Features, set2Labels)\n",
        "\n",
        "\n",
        "num_reject = 0\n",
        "for label in set1Labels:\n",
        "    if label == 0:\n",
        "        num_reject += 1\n",
        "\n",
        "num_accept = 0\n",
        "for label in set2Labels:\n",
        "    if label == 1:\n",
        "        num_accept += 1\n",
        "\n",
        "print(\"Num rejected in set 1 = \" + str(num_reject))\n",
        "print(\"Num accept in set 2 = \" + str(num_accept))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6514058b3607>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mset1Features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ClassificationDataset/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mset1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/features.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mset2Features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ClassificationDataset/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mset2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/features.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ClassificationDataset/train/features.txt'"
          ]
        }
      ]
    }
  ]
}