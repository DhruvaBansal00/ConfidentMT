{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BoostedBinaryClassifers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhruvaBansal00/ConfidentMT/blob/master/BoostedBinaryClassifers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEk99K4f0Hw_",
        "colab_type": "code",
        "outputId": "f29cc741-1f39-40ef-accb-df9cd9cd7355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!ls\n",
        "%cd drive/My Drive/ConfidentMachineTranslation/flores\n",
        "!ls\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "drive  sample_data\n",
            "/content/drive/My Drive/ConfidentMachineTranslation/flores\n",
            "'=0.5.0'\t\t\t Ensembling\n",
            " analysis\t\t\t FLORES.ipynb\n",
            " Analysis\t\t\t LanguageAnalysis.ipynb\n",
            " backward_models\t\t language_models\n",
            " BoostedBinaryClassifers.ipynb\t LM_Thresholding.ipynb\n",
            " checkpoints\t\t\t NCD_Analysis.ipynb\n",
            " ClassificationDataset\t\t NNClassification.ipynb\n",
            " configs\t\t\t noisychannel\n",
            " data\t\t\t\t NoisyChannel.ipynb\n",
            " data-bin\t\t\t Resources\n",
            " Ensembles\t\t\t scripts\n",
            "/content/drive/My Drive/ConfidentMachineTranslation/flores\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlcgFl162kdH",
        "colab_type": "code",
        "outputId": "404733ab-9b59-402c-abc0-2f4e4a854914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# prints how much GPU RAM is available\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=129d324cd80b9274738ee449d4d135d4d5055be2ceee15df0d2d04583ce244df\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  | Proc size: 160.1 MB\n",
            "GPU RAM Free: 15079MB | Used: 0MB | Util   0% | Total 15079MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xwd7lNk3EZn",
        "colab_type": "code",
        "outputId": "2f7ee6a5-a041-497f-cdd0-070b88eb3491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "from itertools import zip_longest\n",
        "\n",
        "def printDatasetClassProp(Y): \n",
        "    classes = {}\n",
        "    total = len(Y)\n",
        "    for i in Y:\n",
        "        if i in classes:\n",
        "            classes[i] += 1\n",
        "        else:\n",
        "            classes[i] = 1\n",
        "    \n",
        "    for cls in classes:\n",
        "        print(\"Proportion in class \" + str(cls) + \" = \" + str(classes[cls]/total))\n",
        "\n",
        "def datasetReader(featureFile, labelFile):\n",
        "    files = [featureFile, labelFile]\n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    for lines in zip_longest(*files, fillvalue=''):\n",
        "        currX, currY = lines[0], float(lines[1].strip(\"\\n\"))\n",
        "        Xarr = []\n",
        "        features = currX.split()\n",
        "        for feature in features:\n",
        "            Xarr.append(float(feature.strip(\",\").strip(\"\\n\")))\n",
        "        X.append(Xarr)\n",
        "        Y.append(currY)\n",
        "    \n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "\n",
        "def computeSimilarity(o1, o2):\n",
        "    total = len(o1)\n",
        "    same = 0\n",
        "    for i in range(len(o1)):\n",
        "        if o1[i] == o2[i]:\n",
        "            same += 1\n",
        "    print(same/total)\n",
        "\n",
        "def trainEnsembleClassifier(X, Y, maxDepth=8, estimators=100):\n",
        "    print(\"Training an ensemble of Random Forest, AdaBoosting and Gradient Boosting Classifiers\")\n",
        "\n",
        "    estimators = [\n",
        "     ('rf', RandomForestClassifier(max_depth=maxDepth, random_state=42)),\n",
        "     ('ada', AdaBoostClassifier(n_estimators=estimators, random_state=42)),\n",
        "     ('grad', GradientBoostingClassifier(random_state=42))]\n",
        "    clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "\n",
        "def trainRandomForestClassifier(X, Y, maxDepth=8):\n",
        "    print(\"Training Random Forest classifier\")\n",
        "    clf = RandomForestClassifier(max_depth=maxDepth, random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainAdaBoostClassifier(X, Y, estimators=100):\n",
        "    print(\"Training AdaBoosted Decision Tree classifier\")\n",
        "    clf = AdaBoostClassifier(n_estimators=estimators, random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainGradientBoostingClassifier(X, Y):\n",
        "    print(\"Training Graident Boosted classifier\")\n",
        "    clf = GradientBoostingClassifier(random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def calculateAccuracy(predictedClasses, groundTruth):\n",
        "    correct_accepted = 0\n",
        "    total_accepted = 0\n",
        "\n",
        "    correct_rejected = 0\n",
        "    total_rejected = 0\n",
        "\n",
        "    for i in range(len(predictedClasses)):\n",
        "        if groundTruth[i] == 1:\n",
        "            total_accepted += 1\n",
        "            if predictedClasses[i] == groundTruth[i]:\n",
        "                correct_accepted += 1\n",
        "        else:\n",
        "            total_rejected += 1\n",
        "            if predictedClasses[i] == groundTruth[i]:\n",
        "                correct_rejected += 1\n",
        "\n",
        "\n",
        "    print(\"Correctly accepted = \" + str(correct_accepted/total_accepted))\n",
        "    print(\"Incorrectly accepted = \" + str(1 - correct_rejected/total_rejected))\n",
        "    print(\"Correctly rejected = \" + str(correct_rejected/total_rejected))\n",
        "    print(\"Incorrectly rejected = \" + str(1 - correct_accepted/total_accepted))\n",
        "\n",
        "    print(\"Total Accuracy = \" + str((correct_accepted + correct_rejected)/(total_accepted + total_rejected)))\n",
        "\n",
        "\n",
        "trainset = \"valid\"\n",
        "testset = \"test\"\n",
        "bleuThreshold = 10\n",
        "\n",
        "trainFeatures = open(\"ClassificationDataset/\"+str(bleuThreshold)+\"BLEU/\"+trainset+\"/features.txt\")\n",
        "testFeatures = open(\"ClassificationDataset/\"+str(bleuThreshold)+\"BLEU/\"+testset+\"/features.txt\")\n",
        "\n",
        "trainLabels = open(\"ClassificationDataset/\"+str(bleuThreshold)+\"BLEU/\"+trainset+\"/result.txt\")\n",
        "testLabels = open(\"ClassificationDataset/\"+str(bleuThreshold)+\"BLEU/\"+testset+\"/result.txt\")\n",
        "\n",
        "trainX, trainY = datasetReader(trainFeatures, trainLabels)\n",
        "testX, testY = datasetReader(testFeatures, testLabels)\n",
        "\n",
        "printDatasetClassProp(trainY)\n",
        "\n",
        "\n",
        "classifiers = [trainRandomForestClassifier, trainAdaBoostClassifier, trainGradientBoostingClassifier, trainEnsembleClassifier]\n",
        "outputs = []\n",
        "\n",
        "for classifier in classifiers:\n",
        "    print(\"#################################################\")\n",
        "    curr = classifier(trainX, trainY)\n",
        "    predictions = np.array(curr.predict(testX))\n",
        "    calculateAccuracy(predictions, testY)\n",
        "    outputs.append(predictions)\n",
        "    print(\"#################################################\")\n",
        "\n",
        "for output_1 in outputs:\n",
        "    for output_2 in outputs:\n",
        "        computeSimilarity(output_1, output_2)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Proportion in class 1.0 = 0.5287221570926143\n",
            "Proportion in class 0.0 = 0.4712778429073857\n",
            "#################################################\n",
            "Training Random Forest classifier\n",
            "Correctly accepted = 0.7030965391621129\n",
            "Incorrectly accepted = 0.2861952861952862\n",
            "Correctly rejected = 0.7138047138047138\n",
            "Incorrectly rejected = 0.2969034608378871\n",
            "Total Accuracy = 0.7075837742504409\n",
            "#################################################\n",
            "#################################################\n",
            "Training AdaBoosted Decision Tree classifier\n",
            "Correctly accepted = 0.6964177292046144\n",
            "Incorrectly accepted = 0.32407407407407407\n",
            "Correctly rejected = 0.6759259259259259\n",
            "Incorrectly rejected = 0.3035822707953856\n",
            "Total Accuracy = 0.6878306878306878\n",
            "#################################################\n",
            "#################################################\n",
            "Training Graident Boosted classifier\n",
            "Correctly accepted = 0.7061323618700668\n",
            "Incorrectly accepted = 0.29461279461279466\n",
            "Correctly rejected = 0.7053872053872053\n",
            "Incorrectly rejected = 0.2938676381299332\n",
            "Total Accuracy = 0.7058201058201058\n",
            "#################################################\n",
            "#################################################\n",
            "Training an ensemble of Random Forest, AdaBoosting and Gradient Boosting Classifiers\n",
            "Correctly accepted = 0.7820279295689132\n",
            "Incorrectly accepted = 0.3939393939393939\n",
            "Correctly rejected = 0.6060606060606061\n",
            "Incorrectly rejected = 0.2179720704310868\n",
            "Total Accuracy = 0.708289241622575\n",
            "#################################################\n",
            "1.0\n",
            "0.8567901234567902\n",
            "0.9192239858906526\n",
            "0.9075837742504409\n",
            "0.8567901234567902\n",
            "1.0\n",
            "0.8754850088183421\n",
            "0.8462081128747796\n",
            "0.9192239858906526\n",
            "0.8754850088183421\n",
            "1.0\n",
            "0.8994708994708994\n",
            "0.9075837742504409\n",
            "0.8462081128747796\n",
            "0.8994708994708994\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ_gNXTbla-G",
        "colab_type": "code",
        "outputId": "bae7e918-3920-4b3e-dbfe-16a8ebd33b50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "set1 = \"train\"\n",
        "set2 = \"valid\"\n",
        "\n",
        "\n",
        "set1Features = open(\"ClassificationDataset/\"+set1+\"/features.txt\")\n",
        "set2Features = open(\"ClassificationDataset/\"+set2+\"/features.txt\")\n",
        "\n",
        "set1Labels = open(\"ClassificationDataset/\"+set1+\"/result.txt\")\n",
        "set2Labels = open(\"ClassificationDataset/\"+set2+\"/result.txt\")\n",
        "\n",
        "\n",
        "_,set1Labels = datasetReader(set1Features, set1Labels)\n",
        "_,set2Labels = datasetReader(set2Features, set2Labels)\n",
        "\n",
        "\n",
        "num_reject = 0\n",
        "for label in set1Labels:\n",
        "    if label == 0:\n",
        "        num_reject += 1\n",
        "\n",
        "num_accept = 0\n",
        "for label in set2Labels:\n",
        "    if label == 1:\n",
        "        num_accept += 1\n",
        "\n",
        "print(\"Num rejected in set 1 = \" + str(num_reject))\n",
        "print(\"Num accept in set 2 = \" + str(num_accept))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num rejected in set 1 = 118329\n",
            "Num accept in set 2 = 508\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}