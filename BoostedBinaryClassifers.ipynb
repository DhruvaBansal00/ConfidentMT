{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BoostedBinaryClassifers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhruvaBansal00/ConfidentMT/blob/master/BoostedBinaryClassifers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEk99K4f0Hw_",
        "colab_type": "code",
        "outputId": "8f84e66b-5db8-4999-dae2-6e9a399246c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!ls\n",
        "%cd drive/My Drive/ConfidentMachineTranslation/flores\n",
        "!ls\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "drive  sample_data\n",
            "/content/drive/My Drive/ConfidentMachineTranslation/flores\n",
            "'=0.5.0'\t\t\t Ensembling\n",
            " analysis\t\t\t FLORES.ipynb\n",
            " Analysis\t\t\t LanguageAnalysis.ipynb\n",
            " backward_models\t\t language_models\n",
            " BoostedBinaryClassifers.ipynb\t LM_Thresholding.ipynb\n",
            " checkpoints\t\t\t NCD_Analysis.ipynb\n",
            " ClassificationDataset\t\t NNClassification.ipynb\n",
            " configs\t\t\t noisychannel\n",
            " data\t\t\t\t NoisyChannel.ipynb\n",
            " data-bin\t\t\t Resources\n",
            " Ensembles\t\t\t scripts\n",
            "/content/drive/My Drive/ConfidentMachineTranslation/flores\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0LVqC0npSH1",
        "colab_type": "code",
        "outputId": "7aab10c5-0277-4347-c181-d7ef2e555349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "pip install fairseq sacrebleu sentencepiece"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fairseq\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/bf/de299e082e7af010d35162cb9a185dc6c17db71624590f2f379aeb2519ff/fairseq-0.9.0.tar.gz (306kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 4.7MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/9d/9846507837ca50ae20917f59d83b79246b8313bd19d4f5bf575ecb98132b/sacrebleu-1.4.9-py3-none-any.whl (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.0MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/88/49e772d686088e1278766ad68a463513642a2a877487decbd691dec02955/sentencepiece-0.1.90-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.17)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.18.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2019.12.20)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.5.0+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.41.1)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (0.16.0)\n",
            "Building wheels for collected packages: fairseq\n",
            "  Building wheel for fairseq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.9.0-cp36-cp36m-linux_x86_64.whl size=2035373 sha256=9ab0bc41070af7f2fc64476e4ba9137ff30e444a375c6b68010bb382837caf05\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/3e/1b/0fa30695dcba41e4b0088067fa40f3328d1e8ee78c22cd4766\n",
            "Successfully built fairseq\n",
            "Installing collected packages: portalocker, sacrebleu, fairseq, sentencepiece\n",
            "Successfully installed fairseq-0.9.0 portalocker-1.7.0 sacrebleu-1.4.9 sentencepiece-0.1.90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlcgFl162kdH",
        "colab_type": "code",
        "outputId": "5bce87c2-b269-4cbc-8ad7-a67dbe8edb9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# prints how much GPU RAM is available\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=e1cf63ccdfee4ddae9c966b81c0ad2535b5106e0ca42fca008f17ddd827c1ad0\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  | Proc size: 158.5 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xwd7lNk3EZn",
        "colab_type": "code",
        "outputId": "a96e67f9-588d-4cdd-d7bc-5381fe21e4fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "import numpy as np\n",
        "from itertools import zip_longest\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "class CustomEnsembleClassifier:\n",
        "    def __init__(self, clfs):\n",
        "        self.classifiers = clfs\n",
        "    \n",
        "    def predict(self, X):\n",
        "        probabilities = None\n",
        "        for clf in self.classifiers:\n",
        "            if probabilities is None:\n",
        "                probabilities = clf.predict_proba(X)\n",
        "            else:\n",
        "                probabilities += clf.predict_proba(X)\n",
        "        return np.argmax(np.array(probabilities), axis=1)\n",
        "\n",
        "\n",
        "\n",
        "def printDatasetClassProp(Y): \n",
        "    classes = {}\n",
        "    total = len(Y)\n",
        "    for i in Y:\n",
        "        if i in classes:\n",
        "            classes[i] += 1\n",
        "        else:\n",
        "            classes[i] = 1\n",
        "    \n",
        "    for cls in classes:\n",
        "        print(\"Proportion in class \" + str(cls) + \" = \" + str(classes[cls]/total))\n",
        "\n",
        "def datasetReader(featureFile, labelFile):\n",
        "    files = [featureFile, labelFile]\n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    for lines in zip_longest(*files, fillvalue=''):\n",
        "        currX, currY = lines[0], float(lines[1].strip(\"\\n\"))\n",
        "        Xarr = []\n",
        "        features = currX.split()\n",
        "        for feature in features:\n",
        "            Xarr.append(float(feature.strip(\",\").strip(\"\\n\")))\n",
        "        X.append(Xarr)\n",
        "        Y.append(currY)\n",
        "    \n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "\n",
        "def computeSimilarity(o1, o2):\n",
        "    total = len(o1)\n",
        "    same = 0\n",
        "    for i in range(len(o1)):\n",
        "        if o1[i] == o2[i]:\n",
        "            same += 1\n",
        "    print(same/total)\n",
        "\n",
        "\n",
        "def trainMLPClassifier(X, Y):\n",
        "    print(\"Training MLP Classifier\")\n",
        "    clf = MLPClassifier(hidden_layer_sizes=(30,30), random_state=1, max_iter=100)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainKNeighborsClassifier(X, Y):\n",
        "    print(\"Training KNeighbors Classifier\")\n",
        "    clf = KNeighborsClassifier(100)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainGaussianProcessClassifier(X, Y):\n",
        "    print(\"Training Gaussian Process Classifier\")\n",
        "    length_scale = [1 for i in range(len(X[0]))]\n",
        "    clf = GaussianProcessClassifier(1.0 * RBF(length_scale), warm_start=True, random_state=42, n_jobs=-1)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainCustomEnsemble(X, Y, maxDepth=8, estimators=100):\n",
        "    print(\"Training custom ensemble\")\n",
        "    rf = RandomForestClassifier(max_depth=maxDepth, random_state=42)\n",
        "    grad = GradientBoostingClassifier(random_state=42)\n",
        "    ada = AdaBoostClassifier(n_estimators=estimators, random_state=42)\n",
        "    # dl = MLPClassifier(hidden_layer_sizes=(100), random_state=1, max_iter=200)\n",
        "    # kn = KNeighborsClassifier(100)\n",
        "\n",
        "    classifiers = [rf, grad, ada]\n",
        "\n",
        "    for clf in classifiers:\n",
        "        clf.fit(X, Y)\n",
        "\n",
        "    return CustomEnsembleClassifier(classifiers)\n",
        "    \n",
        "\n",
        "def trainEnsembleClassifier(X, Y, maxDepth=8, estimators=100):\n",
        "    print(\"Training an ensemble of Random Forest and Gradient Boosting Classifiers\")\n",
        "\n",
        "    estimators = [\n",
        "     ('rf', RandomForestClassifier(max_depth=maxDepth, random_state=42)),\n",
        "     ('grad', GradientBoostingClassifier(random_state=42))]\n",
        "    clf = StackingClassifier(estimators=estimators, final_estimator=AdaBoostClassifier(n_estimators=50, random_state=42))\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "\n",
        "def trainRandomForestClassifier(X, Y, maxDepth=8):\n",
        "    print(\"Training Random Forest classifier\")\n",
        "    clf = RandomForestClassifier(max_depth=maxDepth, random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainAdaBoostClassifier(X, Y, estimators=100):\n",
        "    print(\"Training AdaBoosted Decision Tree classifier\")\n",
        "    clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=estimators, random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainGradientBoostingClassifier(X, Y):\n",
        "    print(\"Training Graident Boosted classifier\")\n",
        "    clf = GradientBoostingClassifier(random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainSVM(X, Y):\n",
        "    print(\"Training SVM classifier\")\n",
        "    clf = SVC(gamma='auto')\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def calculateAccuracy(predictedClasses, groundTruth):\n",
        "    correct_accepted = 0\n",
        "    total_accepted = 0\n",
        "\n",
        "    correct_rejected = 0\n",
        "    total_rejected = 0\n",
        "\n",
        "    for i in range(len(predictedClasses)):\n",
        "        if groundTruth[i] == 1:\n",
        "            total_accepted += 1\n",
        "            if predictedClasses[i] == groundTruth[i]:\n",
        "                correct_accepted += 1\n",
        "        else:\n",
        "            total_rejected += 1\n",
        "            if predictedClasses[i] == groundTruth[i]:\n",
        "                correct_rejected += 1\n",
        "\n",
        "\n",
        "    print(\"Correctly accepted = \" + str(correct_accepted/total_accepted))\n",
        "    print(\"Incorrectly rejected = \" + str(1 - correct_accepted/total_accepted))\n",
        "    print(\"Correctly rejected = \" + str(correct_rejected/total_rejected))\n",
        "    print(\"Incorrectly accepted = \" + str(1 - correct_rejected/total_rejected))\n",
        "\n",
        "    print(\"Total Accuracy = \" + str((correct_accepted + correct_rejected)/(total_accepted + total_rejected)))\n",
        "\n",
        "# featuresUsed = [0, 5, 6, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20]\n",
        "# featuresUsed = [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21] ##All\n",
        "featuresUsed = [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
        "# featuresUsed = [10, 11, 12]\n",
        "\n",
        "\n",
        "trainset = \"valid\"\n",
        "testset = \"test\"\n",
        "bleuThresholdTrain = 10\n",
        "bleuThresholdTest = 10\n",
        "\n",
        "trainFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/features.txt\")\n",
        "testFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/features.txt\")\n",
        "\n",
        "trainLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/result.txt\")\n",
        "testLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/result.txt\")\n",
        "\n",
        "trainX, trainY = datasetReader(trainFeatures, trainLabels)\n",
        "testX, testY = datasetReader(testFeatures, testLabels)\n",
        "# print(len(trainX[0]))\n",
        "# print(len(testX[0]))\n",
        "\n",
        "print(np.array(trainX).shape)\n",
        "print(np.array(testX).shape)\n",
        "\n",
        "trainX = [[row[i] for i in featuresUsed] for row in trainX]\n",
        "testX = [[row[i] for i in featuresUsed] for row in testX]\n",
        "\n",
        "print(np.array(trainX).shape)\n",
        "print(np.array(testX).shape)\n",
        "\n",
        "printDatasetClassProp(trainY)\n",
        "\n",
        "\n",
        "classifiers = [trainRandomForestClassifier, trainAdaBoostClassifier, trainGradientBoostingClassifier, trainCustomEnsemble]\n",
        "outputs = []\n",
        "models = []\n",
        "for classifier in classifiers:\n",
        "    print(\"#################################################\")\n",
        "    curr = classifier(trainX, trainY)\n",
        "    predictions = np.array(curr.predict(testX))\n",
        "    calculateAccuracy(predictions, testY)\n",
        "    outputs.append(predictions)\n",
        "    models.append(curr)\n",
        "    print(\"#################################################\")\n",
        "\n",
        "for output_1 in outputs:\n",
        "    for output_2 in outputs:\n",
        "        computeSimilarity(output_1, output_2)\n",
        "\n",
        "\n",
        "trainFeatures.close()\n",
        "trainLabels.close()\n",
        "testFeatures.close()\n",
        "testLabels.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2559, 22)\n",
            "(2835, 22)\n",
            "(2559, 19)\n",
            "(2835, 19)\n",
            "Proportion in class 1.0 = 0.5287221570926143\n",
            "Proportion in class 0.0 = 0.4712778429073857\n",
            "#################################################\n",
            "Training Random Forest classifier\n",
            "Correctly accepted = 0.7030965391621129\n",
            "Incorrectly rejected = 0.2969034608378871\n",
            "Correctly rejected = 0.7138047138047138\n",
            "Incorrectly accepted = 0.2861952861952862\n",
            "Total Accuracy = 0.7075837742504409\n",
            "#################################################\n",
            "#################################################\n",
            "Training AdaBoosted Decision Tree classifier\n",
            "Correctly accepted = 0.6964177292046144\n",
            "Incorrectly rejected = 0.3035822707953856\n",
            "Correctly rejected = 0.6759259259259259\n",
            "Incorrectly accepted = 0.32407407407407407\n",
            "Total Accuracy = 0.6878306878306878\n",
            "#################################################\n",
            "#################################################\n",
            "Training Graident Boosted classifier\n",
            "Correctly accepted = 0.7061323618700668\n",
            "Incorrectly rejected = 0.2938676381299332\n",
            "Correctly rejected = 0.7053872053872053\n",
            "Incorrectly accepted = 0.29461279461279466\n",
            "Total Accuracy = 0.7058201058201058\n",
            "#################################################\n",
            "#################################################\n",
            "Training custom ensemble\n",
            "Correctly accepted = 0.7128111718275653\n",
            "Incorrectly rejected = 0.28718882817243474\n",
            "Correctly rejected = 0.7121212121212122\n",
            "Incorrectly accepted = 0.28787878787878785\n",
            "Total Accuracy = 0.7125220458553791\n",
            "#################################################\n",
            "1.0\n",
            "0.8567901234567902\n",
            "0.9192239858906526\n",
            "0.9569664902998236\n",
            "0.8567901234567902\n",
            "1.0\n",
            "0.8754850088183421\n",
            "0.873015873015873\n",
            "0.9192239858906526\n",
            "0.8754850088183421\n",
            "1.0\n",
            "0.962257495590829\n",
            "0.9569664902998236\n",
            "0.873015873015873\n",
            "0.962257495590829\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuJiK-mALbhy",
        "colab_type": "code",
        "outputId": "2c4a7613-3298-4a33-9a42-95596c0cb467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class Translation:\n",
        "    def __init__(self, original, reference, translation, score, category):\n",
        "        self.original = original\n",
        "        self.reference = reference\n",
        "        self.translation = translation\n",
        "        self.score = score\n",
        "        self.category = category #0 - accepted correctly, 1 - incorrectly rejected, 2 - correctly rejected, 3 - incorrectly accepted\n",
        "        self.features = []\n",
        "\n",
        "currModel = models[0] ##Random Forest Clf\n",
        "currResult = outputs[0]\n",
        "groundTruth = testY\n",
        "sentences = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/sentences.txt\")\n",
        "translations = []\n",
        "temp = []\n",
        "index = 0\n",
        "for line in sentences:\n",
        "    if len(temp) < 3:\n",
        "        temp.append(line)\n",
        "    else:\n",
        "        score = float(line.strip(\"\\n\"))\n",
        "        category = 0\n",
        "        if currResult[index] != groundTruth[index]:\n",
        "            category = 1 if currResult[index] == 0 else 3\n",
        "        else:\n",
        "            category = 0 if currResult[index] == 1 else 2\n",
        "\n",
        "        translations.append(Translation(temp[0], temp[1], temp[2], score, category))\n",
        "        index += 1\n",
        "        temp = []\n",
        "###############verification#####################\n",
        "# temp = [0 for i in range(4)]\n",
        "# total = 0\n",
        "# for translation in translations:\n",
        "#     total += 1\n",
        "#     temp[translation.category] += 1\n",
        "# for i in temp:\n",
        "#     print(str(float(i)/float(total)) + \"\\n\")\n",
        "###############verification#####################\n",
        "labels = {0 : \"Accepted Correctly\", 1: \"Incorrectly Rejected\", 2: \"Correctly Rejected\", 3: \"Incorrectly Accepted\"}\n",
        "indices = [2]\n",
        "\n",
        "# for i in indices:\n",
        "#     # print(labels[i])\n",
        "#     for translation in translations:\n",
        "#         if translation.category == i:\n",
        "#             print(translation.reference)\n",
        "#             print(translation.translation)\n",
        "#             print(str(translation.score) + \"\\n\")\n",
        "\n",
        "\n",
        "totalScore = [0 for i in range(4)]\n",
        "totalNum = [0 for i in range(4)]\n",
        "\n",
        "for translation in translations:\n",
        "    totalScore[translation.category] += translation.score\n",
        "    totalNum[translation.category] += 1\n",
        "\n",
        "print(np.array(totalScore)/np.array(totalNum))\n",
        "sentences.close()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[22.17986025 19.1385625   8.54718777 10.39010539]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ_gNXTbla-G",
        "colab_type": "code",
        "outputId": "3482af67-0f98-499d-f36b-6351bf27a87b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "set1 = \"valid\"\n",
        "set2 = \"test\"\n",
        "\n",
        "\n",
        "set1Features = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+set1+\"/features.txt\")\n",
        "set2Features = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+set2+\"/features.txt\")\n",
        "\n",
        "set1Labels = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+set1+\"/result.txt\")\n",
        "set2Labels = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+set2+\"/result.txt\")\n",
        "\n",
        "\n",
        "_,set1Labels = datasetReader(set1Features, set1Labels)\n",
        "_,set2Labels = datasetReader(set2Features, set2Labels)\n",
        "\n",
        "\n",
        "num_reject = 0\n",
        "for label in set1Labels:\n",
        "    if label == 0:\n",
        "        num_reject += 1\n",
        "\n",
        "num_accept = 0\n",
        "for label in set2Labels:\n",
        "    if label == 1:\n",
        "        num_accept += 1\n",
        "\n",
        "print(\"Num rejected in set 1 = \" + str(num_reject))\n",
        "print(\"Num accept in set 2 = \" + str(num_accept))\n",
        "set1Features.close()\n",
        "set2Features.close()\n",
        "set1Labels.close()\n",
        "set2Labels.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num rejected in set 1 = 2051\n",
            "Num accept in set 2 = 719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an1uY1tRPfEV",
        "colab_type": "code",
        "outputId": "733ee225-d791-4d4c-ef13-3bd6d1e88f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "##make precision graphs\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import auc\n",
        "import random\n",
        "\n",
        "class Translation:\n",
        "    def __init__(self, original, reference, translation, score, features):\n",
        "        self.original = original\n",
        "        self.reference = reference\n",
        "        self.translation = translation\n",
        "        self.score = score\n",
        "        self.features = features\n",
        "\n",
        "def compute_excluded_included_score (acceptedTranslations, rejectedTranslations):\n",
        "    temporary_reference_inclusion = open(\"analysis/temporary_reference_inclusion.txt\", \"w\")\n",
        "    temporary_output_inclusion = open(\"analysis/temporary_output_inclusion.txt\", \"w\")\n",
        "\n",
        "    temporary_reference_exclusion = open(\"analysis/temporary_reference_exclusion.txt\", \"w\")\n",
        "    temporary_output_exclusion = open(\"analysis/temporary_output_exclusion.txt\", \"w\")\n",
        "    \n",
        "    for translation in acceptedTranslations:\n",
        "        temporary_reference_inclusion.write(translation.reference)\n",
        "        temporary_output_inclusion.write(translation.translation)\n",
        "\n",
        "    for translation in rejectedTranslations:\n",
        "        temporary_reference_exclusion.write(translation.reference)\n",
        "        temporary_output_exclusion.write(translation.translation)\n",
        "\n",
        "    \n",
        "    temporary_reference_inclusion.close()\n",
        "    temporary_output_inclusion.close()\n",
        "    temporary_reference_exclusion.close()\n",
        "    temporary_output_exclusion.close()\n",
        "\n",
        "    !fairseq-score --sys analysis/temporary_output_inclusion.txt --ref analysis/temporary_reference_inclusion.txt --sacrebleu > analysis/inclusion_result.txt\n",
        "    !fairseq-score --sys analysis/temporary_output_exclusion.txt --ref analysis/temporary_reference_exclusion.txt --sacrebleu > analysis/exclusion_result.txt\n",
        "\n",
        "    temporary_inclusion_result = open(\"analysis/inclusion_result.txt\")\n",
        "    temporary_exclusion_result = open(\"analysis/exclusion_result.txt\")\n",
        "    inclusion_result_string = [line for line in temporary_inclusion_result][1].split(\" \")[2]\n",
        "    exclusion_result_string = [line for line in temporary_exclusion_result][1].split(\" \")[2]\n",
        "\n",
        "    return float(exclusion_result_string), float(inclusion_result_string)\n",
        "\n",
        "\n",
        "def readTranslations(sentenceFile, featureArray):\n",
        "    translations = []\n",
        "    temp = []\n",
        "    index = 0\n",
        "    for line in sentenceFile:\n",
        "        if len(temp) < 3:\n",
        "            temp.append(line)\n",
        "        else:\n",
        "            score = float(line.strip(\"\\n\"))\n",
        "            translations.append(Translation(temp[0], temp[1], temp[2], score, featureArray[index]))\n",
        "            index += 1\n",
        "            temp = []\n",
        "    \n",
        "    return translations\n",
        "\n",
        "def getTrainTestSets(trainTranslations, testTranslations, threshold_train, threshold_test):\n",
        "    trainFeatures = []\n",
        "    trainY = []\n",
        "    testFeatures = []\n",
        "    testY = []\n",
        "\n",
        "    for translation in trainTranslations:\n",
        "        trainFeatures.append(translation.features)\n",
        "        # if translation.features[0] < threshold_train:\n",
        "        if translation.score < threshold_train:\n",
        "            trainY.append(0)\n",
        "        else:\n",
        "            trainY.append(1)\n",
        "    \n",
        "    for translation in testTranslations:\n",
        "        testFeatures.append(translation.features)\n",
        "        # if translation.features[0] < threshold_train:\n",
        "        if translation.score < threshold_test:\n",
        "            testY.append(0)\n",
        "        else:\n",
        "            testY.append(1)\n",
        "\n",
        "    return trainFeatures, trainY, testFeatures, testY\n",
        "\n",
        "featuresUsed = [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
        "# featuresUsed = [0]\n",
        "# featuresUsed = [0, 4]\n",
        "\n",
        "trainset = \"valid\"\n",
        "testset = \"test\"\n",
        "bleuThresholdTrain = 10\n",
        "bleuThresholdTest = 10\n",
        "\n",
        "trainFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/features.txt\")\n",
        "testFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/features.txt\")\n",
        "trainLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/result.txt\")\n",
        "testLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/result.txt\")\n",
        "\n",
        "trainSentences = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/sentences.txt\")\n",
        "testSentences = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/sentences.txt\")\n",
        "\n",
        "\n",
        "featuresTrain, _ = datasetReader(trainFeatures, trainLabels)\n",
        "featuresTest, _ = datasetReader(testFeatures, testLabels)\n",
        "\n",
        "featuresTrain = [[row[i] for i in featuresUsed] for row in featuresTrain]\n",
        "featuresTest = [[row[i] for i in featuresUsed] for row in featuresTest]\n",
        "\n",
        "trainTranslations = readTranslations(trainSentences, featuresTrain)\n",
        "testTranslations = readTranslations(testSentences, featuresTest)\n",
        "\n",
        "Thresholds_train = np.linspace(4, 22, 25).tolist()\n",
        "Thresholds_test = np.linspace(4, 22, 25).tolist()\n",
        "\n",
        "acceptedScores = []\n",
        "acceptedFraction = []\n",
        "\n",
        "\n",
        "for index in range(len(Thresholds_test)):\n",
        "    trainFeatures, trainY, testFeatures, testY = getTrainTestSets(trainTranslations, testTranslations, Thresholds_train[index], Thresholds_test[index])\n",
        "\n",
        "    clf = trainRandomForestClassifier(trainFeatures, trainY)\n",
        "    # print(\"Using Average Logprob Decision Stump of \" + str(Thresholds_train[index]))\n",
        "    print(\"BLEU score = \" + str(Thresholds_test[index]))\n",
        "    predictions = clf.predict(testFeatures)\n",
        "    calculateAccuracy(predictions, testY)\n",
        "    print(\"##########################################\")\n",
        "    acceptedTranslations = np.array(testTranslations)[np.array(predictions) > 0]\n",
        "    rejectedTranslations = np.array(testTranslations)[np.array(predictions) < 1]\n",
        "    rejectedScore, acceptedScore = compute_excluded_included_score(acceptedTranslations, rejectedTranslations)\n",
        "    acceptedScores.append(acceptedScore)\n",
        "    acceptedFraction.append(float(len(acceptedTranslations))/float(len(predictions)))\n",
        "\n",
        "plt.xlabel('Fraction Above Threshold') \n",
        "plt.ylabel('BLEU score (corpus)') \n",
        "plt.title('Average Logprob Thresholding') \n",
        "\n",
        "r = random.random()\n",
        "b = random.random()\n",
        "g = random.random()\n",
        "c = (r, g, b)\n",
        "plt.scatter(acceptedFraction, acceptedScores, label = \"Random Forest Analysis\", color=c)\n",
        "\n",
        "acceptedScores = [x for _,x in sorted(zip(acceptedFraction,acceptedScores))]\n",
        "acceptedFraction.sort()\n",
        "\n",
        "print('AUC for incuded fraction: {}'.format(auc(acceptedFraction, acceptedScores)))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Random Forest classifier\n",
            "BLEU score = 4.0\n",
            "Correctly accepted = 0.9996392496392497\n",
            "Incorrectly rejected = 0.0003607503607503393\n",
            "Correctly rejected = 0.09523809523809523\n",
            "Incorrectly accepted = 0.9047619047619048\n",
            "Total Accuracy = 0.9795414462081129\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 4.75\n",
            "Correctly accepted = 0.9978165938864629\n",
            "Incorrectly rejected = 0.0021834061135370675\n",
            "Correctly rejected = 0.08045977011494253\n",
            "Incorrectly accepted = 0.9195402298850575\n",
            "Total Accuracy = 0.9696649029982364\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 5.5\n",
            "Correctly accepted = 0.9981481481481481\n",
            "Incorrectly rejected = 0.0018518518518518823\n",
            "Correctly rejected = 0.07407407407407407\n",
            "Incorrectly accepted = 0.9259259259259259\n",
            "Total Accuracy = 0.9541446208112875\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 6.25\n",
            "Correctly accepted = 0.9923076923076923\n",
            "Incorrectly rejected = 0.007692307692307665\n",
            "Correctly rejected = 0.06808510638297872\n",
            "Incorrectly accepted = 0.9319148936170213\n",
            "Total Accuracy = 0.9156966490299824\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 7.0\n",
            "Correctly accepted = 0.979757085020243\n",
            "Incorrectly rejected = 0.020242914979757054\n",
            "Correctly rejected = 0.15342465753424658\n",
            "Incorrectly accepted = 0.8465753424657534\n",
            "Total Accuracy = 0.87336860670194\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 7.75\n",
            "Correctly accepted = 0.9703961689159774\n",
            "Incorrectly rejected = 0.029603831084022647\n",
            "Correctly rejected = 0.19888475836431227\n",
            "Incorrectly accepted = 0.8011152416356877\n",
            "Total Accuracy = 0.8239858906525573\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 8.5\n",
            "Correctly accepted = 0.922673031026253\n",
            "Incorrectly rejected = 0.07732696897374702\n",
            "Correctly rejected = 0.3824324324324324\n",
            "Incorrectly accepted = 0.6175675675675676\n",
            "Total Accuracy = 0.781657848324515\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 9.25\n",
            "Correctly accepted = 0.8394199785177229\n",
            "Incorrectly rejected = 0.16058002148227712\n",
            "Correctly rejected = 0.5169578622816033\n",
            "Incorrectly accepted = 0.48304213771839666\n",
            "Total Accuracy = 0.7287477954144621\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 10.0\n",
            "Correctly accepted = 0.6958105646630237\n",
            "Incorrectly rejected = 0.3041894353369763\n",
            "Correctly rejected = 0.6742424242424242\n",
            "Incorrectly accepted = 0.3257575757575758\n",
            "Total Accuracy = 0.6867724867724868\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 10.75\n",
            "Correctly accepted = 0.5993197278911565\n",
            "Incorrectly rejected = 0.4006802721088435\n",
            "Correctly rejected = 0.7838827838827839\n",
            "Incorrectly accepted = 0.21611721611721613\n",
            "Total Accuracy = 0.6881834215167548\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 11.5\n",
            "Correctly accepted = 0.48671875\n",
            "Incorrectly rejected = 0.51328125\n",
            "Correctly rejected = 0.8617363344051447\n",
            "Incorrectly accepted = 0.13826366559485526\n",
            "Total Accuracy = 0.6924162257495591\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 12.25\n",
            "Correctly accepted = 0.40821917808219177\n",
            "Incorrectly rejected = 0.5917808219178082\n",
            "Correctly rejected = 0.9080459770114943\n",
            "Incorrectly accepted = 0.09195402298850575\n",
            "Total Accuracy = 0.7149911816578484\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 13.0\n",
            "Correctly accepted = 0.3689727463312369\n",
            "Incorrectly rejected = 0.6310272536687631\n",
            "Correctly rejected = 0.9239766081871345\n",
            "Incorrectly accepted = 0.07602339181286555\n",
            "Total Accuracy = 0.7372134038800705\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 13.75\n",
            "Correctly accepted = 0.31776765375854216\n",
            "Incorrectly rejected = 0.6822323462414579\n",
            "Correctly rejected = 0.9422585590189065\n",
            "Incorrectly accepted = 0.05774144098109346\n",
            "Total Accuracy = 0.7488536155202822\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 14.5\n",
            "Correctly accepted = 0.2654639175257732\n",
            "Incorrectly rejected = 0.7345360824742269\n",
            "Correctly rejected = 0.9553181155900923\n",
            "Incorrectly accepted = 0.044681884409907724\n",
            "Total Accuracy = 0.7664902998236331\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 15.25\n",
            "Correctly accepted = 0.24857142857142858\n",
            "Incorrectly rejected = 0.7514285714285714\n",
            "Correctly rejected = 0.9639344262295082\n",
            "Incorrectly accepted = 0.0360655737704918\n",
            "Total Accuracy = 0.7873015873015873\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 16.0\n",
            "Correctly accepted = 0.19575856443719414\n",
            "Incorrectly rejected = 0.8042414355628058\n",
            "Correctly rejected = 0.9734473447344735\n",
            "Incorrectly accepted = 0.026552655265526526\n",
            "Total Accuracy = 0.8052910052910053\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 16.75\n",
            "Correctly accepted = 0.15296367112810708\n",
            "Incorrectly rejected = 0.847036328871893\n",
            "Correctly rejected = 0.9826989619377162\n",
            "Incorrectly accepted = 0.01730103806228378\n",
            "Total Accuracy = 0.8296296296296296\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 17.5\n",
            "Correctly accepted = 0.14038876889848811\n",
            "Incorrectly rejected = 0.8596112311015118\n",
            "Correctly rejected = 0.9890387858347386\n",
            "Incorrectly accepted = 0.010961214165261413\n",
            "Total Accuracy = 0.8504409171075837\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 18.25\n",
            "Correctly accepted = 0.1345707656612529\n",
            "Incorrectly rejected = 0.8654292343387471\n",
            "Correctly rejected = 0.9883527454242929\n",
            "Incorrectly accepted = 0.011647254575707144\n",
            "Total Accuracy = 0.8585537918871252\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 19.0\n",
            "Correctly accepted = 0.11780104712041885\n",
            "Incorrectly rejected = 0.8821989528795812\n",
            "Correctly rejected = 0.9918467183041174\n",
            "Incorrectly accepted = 0.008153281695882586\n",
            "Total Accuracy = 0.8740740740740741\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 19.75\n",
            "Correctly accepted = 0.09969788519637462\n",
            "Incorrectly rejected = 0.9003021148036254\n",
            "Correctly rejected = 0.9924121405750799\n",
            "Incorrectly accepted = 0.007587859424920129\n",
            "Total Accuracy = 0.8881834215167549\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 20.5\n",
            "Correctly accepted = 0.11221122112211221\n",
            "Incorrectly rejected = 0.8877887788778878\n",
            "Correctly rejected = 0.9964454976303317\n",
            "Incorrectly accepted = 0.0035545023696682554\n",
            "Total Accuracy = 0.9019400352733686\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 21.25\n",
            "Correctly accepted = 0.10877192982456141\n",
            "Incorrectly rejected = 0.8912280701754386\n",
            "Correctly rejected = 0.9949019607843137\n",
            "Incorrectly accepted = 0.005098039215686301\n",
            "Total Accuracy = 0.9058201058201059\n",
            "##########################################\n",
            "Training Random Forest classifier\n",
            "BLEU score = 22.0\n",
            "Correctly accepted = 0.10204081632653061\n",
            "Incorrectly rejected = 0.8979591836734694\n",
            "Correctly rejected = 0.9938223938223938\n",
            "Incorrectly accepted = 0.00617760617760621\n",
            "Total Accuracy = 0.9167548500881835\n",
            "##########################################\n",
            "AUC for incuded fraction: 11.687670194003527\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}