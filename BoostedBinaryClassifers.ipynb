{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BoostedBinaryClassifers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhruvaBansal00/ConfidentMT/blob/master/BoostedBinaryClassifers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEk99K4f0Hw_",
        "colab_type": "code",
        "outputId": "856753da-0e11-4321-f476-51ad2fca3873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!ls\n",
        "%cd drive/My Drive/ConfidentMachineTranslation/flores\n",
        "!ls\n",
        "!pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "drive  sample_data\n",
            "/content/drive/My Drive/ConfidentMachineTranslation/flores\n",
            "'=0.5.0'\t\t\t Ensembling\n",
            " analysis\t\t\t FLORES.ipynb\n",
            " Analysis\t\t\t LanguageAnalysis.ipynb\n",
            " backward_models\t\t language_models\n",
            " BoostedBinaryClassifers.ipynb\t LM_Thresholding.ipynb\n",
            " checkpoints\t\t\t NCD_Analysis.ipynb\n",
            " ClassificationDataset\t\t NNClassification.ipynb\n",
            " configs\t\t\t noisychannel\n",
            " data\t\t\t\t NoisyChannel.ipynb\n",
            " data-bin\t\t\t Resources\n",
            " Ensembles\t\t\t scripts\n",
            "/content/drive/My Drive/ConfidentMachineTranslation/flores\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0LVqC0npSH1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "58abc728-5b89-4a69-eb2e-39a6468c9fc9"
      },
      "source": [
        "pip install fairseq sacrebleu sentencepiece"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fairseq in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (1.4.9)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/88/49e772d686088e1278766ad68a463513642a2a877487decbd691dec02955/sentencepiece-0.1.90-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.41.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.5.0+cu101)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2019.12.20)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.17)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.18.4)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (1.7.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (0.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n",
            "Installing collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlcgFl162kdH",
        "colab_type": "code",
        "outputId": "5bce87c2-b269-4cbc-8ad7-a67dbe8edb9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# prints how much GPU RAM is available\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=e1cf63ccdfee4ddae9c966b81c0ad2535b5106e0ca42fca008f17ddd827c1ad0\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  | Proc size: 158.5 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xwd7lNk3EZn",
        "colab_type": "code",
        "outputId": "9c2de5e4-432c-47e9-a7d7-52431f07351d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "import numpy as np\n",
        "from itertools import zip_longest\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "class CustomEnsembleClassifier:\n",
        "    def __init__(self, clfs):\n",
        "        self.classifiers = clfs\n",
        "    \n",
        "    def predict(self, X):\n",
        "        probabilities = None\n",
        "        for clf in self.classifiers:\n",
        "            if probabilities is None:\n",
        "                probabilities = clf.predict_proba(X)\n",
        "            else:\n",
        "                probabilities += clf.predict_proba(X)\n",
        "        return np.argmax(np.array(probabilities), axis=1)\n",
        "\n",
        "\n",
        "\n",
        "def printDatasetClassProp(Y): \n",
        "    classes = {}\n",
        "    total = len(Y)\n",
        "    for i in Y:\n",
        "        if i in classes:\n",
        "            classes[i] += 1\n",
        "        else:\n",
        "            classes[i] = 1\n",
        "    \n",
        "    for cls in classes:\n",
        "        print(\"Proportion in class \" + str(cls) + \" = \" + str(classes[cls]/total))\n",
        "\n",
        "def datasetReader(featureFile, labelFile):\n",
        "    files = [featureFile, labelFile]\n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    for lines in zip_longest(*files, fillvalue=''):\n",
        "        currX, currY = lines[0], float(lines[1].strip(\"\\n\"))\n",
        "        Xarr = []\n",
        "        features = currX.split()\n",
        "        for feature in features:\n",
        "            Xarr.append(float(feature.strip(\",\").strip(\"\\n\")))\n",
        "        X.append(Xarr)\n",
        "        Y.append(currY)\n",
        "    \n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "\n",
        "def computeSimilarity(o1, o2):\n",
        "    total = len(o1)\n",
        "    same = 0\n",
        "    for i in range(len(o1)):\n",
        "        if o1[i] == o2[i]:\n",
        "            same += 1\n",
        "    print(same/total)\n",
        "\n",
        "\n",
        "def trainMLPClassifier(X, Y):\n",
        "    print(\"Training MLP Classifier\")\n",
        "    clf = MLPClassifier(hidden_layer_sizes=(30,30), random_state=1, max_iter=100)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainKNeighborsClassifier(X, Y):\n",
        "    print(\"Training KNeighbors Classifier\")\n",
        "    clf = KNeighborsClassifier(100)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainGaussianProcessClassifier(X, Y):\n",
        "    print(\"Training Gaussian Process Classifier\")\n",
        "    length_scale = [1 for i in range(len(X[0]))]\n",
        "    clf = GaussianProcessClassifier(1.0 * RBF(length_scale), warm_start=True, random_state=42, n_jobs=-1)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainCustomEnsemble(X, Y, maxDepth=8, estimators=100):\n",
        "    print(\"Training custom ensemble\")\n",
        "    rf = RandomForestClassifier(max_depth=maxDepth, random_state=42)\n",
        "    grad = GradientBoostingClassifier(random_state=42)\n",
        "    ada = AdaBoostClassifier(n_estimators=estimators, random_state=42)\n",
        "    # dl = MLPClassifier(hidden_layer_sizes=(100), random_state=1, max_iter=200)\n",
        "    # kn = KNeighborsClassifier(100)\n",
        "\n",
        "    classifiers = [rf, grad, ada]\n",
        "\n",
        "    for clf in classifiers:\n",
        "        clf.fit(X, Y)\n",
        "\n",
        "    return CustomEnsembleClassifier(classifiers)\n",
        "    \n",
        "\n",
        "def trainEnsembleClassifier(X, Y, maxDepth=8, estimators=100):\n",
        "    print(\"Training an ensemble of Random Forest and Gradient Boosting Classifiers\")\n",
        "\n",
        "    estimators = [\n",
        "     ('rf', RandomForestClassifier(max_depth=maxDepth, random_state=42)),\n",
        "     ('grad', GradientBoostingClassifier(random_state=42))]\n",
        "    clf = StackingClassifier(estimators=estimators, final_estimator=AdaBoostClassifier(n_estimators=50, random_state=42))\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "\n",
        "def trainRandomForestClassifier(X, Y, maxDepth=8):\n",
        "    print(\"Training Random Forest classifier\")\n",
        "    clf = RandomForestClassifier(max_depth=maxDepth, random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainAdaBoostClassifier(X, Y, estimators=100):\n",
        "    print(\"Training AdaBoosted Decision Tree classifier\")\n",
        "    clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=estimators, random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainGradientBoostingClassifier(X, Y):\n",
        "    print(\"Training Graident Boosted classifier\")\n",
        "    clf = GradientBoostingClassifier(random_state=42)\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def trainSVM(X, Y):\n",
        "    print(\"Training SVM classifier\")\n",
        "    clf = SVC(gamma='auto')\n",
        "    clf.fit(X, Y)\n",
        "    return clf\n",
        "\n",
        "def calculateAccuracy(predictedClasses, groundTruth):\n",
        "    correct_accepted = 0\n",
        "    total_accepted = 0\n",
        "\n",
        "    correct_rejected = 0\n",
        "    total_rejected = 0\n",
        "\n",
        "    for i in range(len(predictedClasses)):\n",
        "        if groundTruth[i] == 1:\n",
        "            total_accepted += 1\n",
        "            if predictedClasses[i] == groundTruth[i]:\n",
        "                correct_accepted += 1\n",
        "        else:\n",
        "            total_rejected += 1\n",
        "            if predictedClasses[i] == groundTruth[i]:\n",
        "                correct_rejected += 1\n",
        "\n",
        "\n",
        "    print(\"Correctly accepted = \" + str(correct_accepted/total_accepted))\n",
        "    print(\"Incorrectly rejected = \" + str(1 - correct_accepted/total_accepted))\n",
        "    print(\"Correctly rejected = \" + str(correct_rejected/total_rejected))\n",
        "    print(\"Incorrectly accepted = \" + str(1 - correct_rejected/total_rejected))\n",
        "\n",
        "    print(\"Total Accuracy = \" + str((correct_accepted + correct_rejected)/(total_accepted + total_rejected)))\n",
        "\n",
        "# featuresUsed = [0, 5, 6, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20]\n",
        "# featuresUsed = [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21] ##All\n",
        "featuresUsed = [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
        "# featuresUsed = [10, 11, 12]\n",
        "\n",
        "\n",
        "trainset = \"valid\"\n",
        "testset = \"test\"\n",
        "bleuThresholdTrain = 10\n",
        "bleuThresholdTest = 10\n",
        "\n",
        "trainFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/features.txt\")\n",
        "testFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/features.txt\")\n",
        "\n",
        "trainLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/result.txt\")\n",
        "testLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/result.txt\")\n",
        "\n",
        "trainX, trainY = datasetReader(trainFeatures, trainLabels)\n",
        "testX, testY = datasetReader(testFeatures, testLabels)\n",
        "# print(len(trainX[0]))\n",
        "# print(len(testX[0]))\n",
        "\n",
        "print(np.array(trainX).shape)\n",
        "print(np.array(testX).shape)\n",
        "\n",
        "trainX = [[row[i] for i in featuresUsed] for row in trainX]\n",
        "testX = [[row[i] for i in featuresUsed] for row in testX]\n",
        "\n",
        "print(np.array(trainX).shape)\n",
        "print(np.array(testX).shape)\n",
        "\n",
        "printDatasetClassProp(trainY)\n",
        "\n",
        "\n",
        "classifiers = [trainRandomForestClassifier, trainAdaBoostClassifier, trainGradientBoostingClassifier, trainCustomEnsemble]\n",
        "outputs = []\n",
        "models = []\n",
        "for classifier in classifiers:\n",
        "    print(\"#################################################\")\n",
        "    curr = classifier(trainX, trainY)\n",
        "    predictions = np.array(curr.predict(testX))\n",
        "    calculateAccuracy(predictions, testY)\n",
        "    outputs.append(predictions)\n",
        "    models.append(curr)\n",
        "    print(\"#################################################\")\n",
        "\n",
        "for output_1 in outputs:\n",
        "    for output_2 in outputs:\n",
        "        computeSimilarity(output_1, output_2)\n",
        "\n",
        "\n",
        "trainFeatures.close()\n",
        "trainLabels.close()\n",
        "testFeatures.close()\n",
        "testLabels.close()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2559, 22)\n",
            "(2835, 22)\n",
            "(2559, 19)\n",
            "(2835, 19)\n",
            "Proportion in class 1.0 = 0.5287221570926143\n",
            "Proportion in class 0.0 = 0.4712778429073857\n",
            "#################################################\n",
            "Training Random Forest classifier\n",
            "Correctly accepted = 0.7030965391621129\n",
            "Incorrectly rejected = 0.2969034608378871\n",
            "Correctly rejected = 0.7138047138047138\n",
            "Incorrectly accepted = 0.2861952861952862\n",
            "Total Accuracy = 0.7075837742504409\n",
            "#################################################\n",
            "#################################################\n",
            "Training AdaBoosted Decision Tree classifier\n",
            "Correctly accepted = 0.6642380085003036\n",
            "Incorrectly rejected = 0.33576199149969643\n",
            "Correctly rejected = 0.6464646464646465\n",
            "Incorrectly accepted = 0.3535353535353535\n",
            "Total Accuracy = 0.6567901234567901\n",
            "#################################################\n",
            "#################################################\n",
            "Training Graident Boosted classifier\n",
            "Correctly accepted = 0.7061323618700668\n",
            "Incorrectly rejected = 0.2938676381299332\n",
            "Correctly rejected = 0.7053872053872053\n",
            "Incorrectly accepted = 0.29461279461279466\n",
            "Total Accuracy = 0.7058201058201058\n",
            "#################################################\n",
            "#################################################\n",
            "Training custom ensemble\n",
            "Correctly accepted = 0.7128111718275653\n",
            "Incorrectly rejected = 0.28718882817243474\n",
            "Correctly rejected = 0.7121212121212122\n",
            "Incorrectly accepted = 0.28787878787878785\n",
            "Total Accuracy = 0.7125220458553791\n",
            "#################################################\n",
            "1.0\n",
            "0.7798941798941799\n",
            "0.9192239858906526\n",
            "0.9569664902998236\n",
            "0.7798941798941799\n",
            "1.0\n",
            "0.7668430335097002\n",
            "0.7756613756613756\n",
            "0.9192239858906526\n",
            "0.7668430335097002\n",
            "1.0\n",
            "0.962257495590829\n",
            "0.9569664902998236\n",
            "0.7756613756613756\n",
            "0.962257495590829\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuJiK-mALbhy",
        "colab_type": "code",
        "outputId": "2c4a7613-3298-4a33-9a42-95596c0cb467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class Translation:\n",
        "    def __init__(self, original, reference, translation, score, category):\n",
        "        self.original = original\n",
        "        self.reference = reference\n",
        "        self.translation = translation\n",
        "        self.score = score\n",
        "        self.category = category #0 - accepted correctly, 1 - incorrectly rejected, 2 - correctly rejected, 3 - incorrectly accepted\n",
        "        self.features = []\n",
        "\n",
        "currModel = models[0] ##Random Forest Clf\n",
        "currResult = outputs[0]\n",
        "groundTruth = testY\n",
        "sentences = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/sentences.txt\")\n",
        "translations = []\n",
        "temp = []\n",
        "index = 0\n",
        "for line in sentences:\n",
        "    if len(temp) < 3:\n",
        "        temp.append(line)\n",
        "    else:\n",
        "        score = float(line.strip(\"\\n\"))\n",
        "        category = 0\n",
        "        if currResult[index] != groundTruth[index]:\n",
        "            category = 1 if currResult[index] == 0 else 3\n",
        "        else:\n",
        "            category = 0 if currResult[index] == 1 else 2\n",
        "\n",
        "        translations.append(Translation(temp[0], temp[1], temp[2], score, category))\n",
        "        index += 1\n",
        "        temp = []\n",
        "###############verification#####################\n",
        "# temp = [0 for i in range(4)]\n",
        "# total = 0\n",
        "# for translation in translations:\n",
        "#     total += 1\n",
        "#     temp[translation.category] += 1\n",
        "# for i in temp:\n",
        "#     print(str(float(i)/float(total)) + \"\\n\")\n",
        "###############verification#####################\n",
        "labels = {0 : \"Accepted Correctly\", 1: \"Incorrectly Rejected\", 2: \"Correctly Rejected\", 3: \"Incorrectly Accepted\"}\n",
        "indices = [2]\n",
        "\n",
        "# for i in indices:\n",
        "#     # print(labels[i])\n",
        "#     for translation in translations:\n",
        "#         if translation.category == i:\n",
        "#             print(translation.reference)\n",
        "#             print(translation.translation)\n",
        "#             print(str(translation.score) + \"\\n\")\n",
        "\n",
        "\n",
        "totalScore = [0 for i in range(4)]\n",
        "totalNum = [0 for i in range(4)]\n",
        "\n",
        "for translation in translations:\n",
        "    totalScore[translation.category] += translation.score\n",
        "    totalNum[translation.category] += 1\n",
        "\n",
        "print(np.array(totalScore)/np.array(totalNum))\n",
        "sentences.close()\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[22.17986025 19.1385625   8.54718777 10.39010539]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ_gNXTbla-G",
        "colab_type": "code",
        "outputId": "3482af67-0f98-499d-f36b-6351bf27a87b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "set1 = \"valid\"\n",
        "set2 = \"test\"\n",
        "\n",
        "\n",
        "set1Features = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+set1+\"/features.txt\")\n",
        "set2Features = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+set2+\"/features.txt\")\n",
        "\n",
        "set1Labels = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+set1+\"/result.txt\")\n",
        "set2Labels = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+set2+\"/result.txt\")\n",
        "\n",
        "\n",
        "_,set1Labels = datasetReader(set1Features, set1Labels)\n",
        "_,set2Labels = datasetReader(set2Features, set2Labels)\n",
        "\n",
        "\n",
        "num_reject = 0\n",
        "for label in set1Labels:\n",
        "    if label == 0:\n",
        "        num_reject += 1\n",
        "\n",
        "num_accept = 0\n",
        "for label in set2Labels:\n",
        "    if label == 1:\n",
        "        num_accept += 1\n",
        "\n",
        "print(\"Num rejected in set 1 = \" + str(num_reject))\n",
        "print(\"Num accept in set 2 = \" + str(num_accept))\n",
        "set1Features.close()\n",
        "set2Features.close()\n",
        "set1Labels.close()\n",
        "set2Labels.close()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num rejected in set 1 = 2051\n",
            "Num accept in set 2 = 719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an1uY1tRPfEV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "d57926f2-3122-4d9d-add0-ceb643311f20"
      },
      "source": [
        "##make precision graphs\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import auc\n",
        "import random\n",
        "\n",
        "class Translation:\n",
        "    def __init__(self, original, reference, translation, score, features):\n",
        "        self.original = original\n",
        "        self.reference = reference\n",
        "        self.translation = translation\n",
        "        self.score = score\n",
        "        self.features = features\n",
        "\n",
        "def compute_excluded_included_score (acceptedTranslations, rejectedTranslations):\n",
        "    temporary_reference_inclusion = open(\"analysis/temporary_reference_inclusion.txt\", \"w\")\n",
        "    temporary_output_inclusion = open(\"analysis/temporary_output_inclusion.txt\", \"w\")\n",
        "\n",
        "    temporary_reference_exclusion = open(\"analysis/temporary_reference_exclusion.txt\", \"w\")\n",
        "    temporary_output_exclusion = open(\"analysis/temporary_output_exclusion.txt\", \"w\")\n",
        "    \n",
        "    for translation in acceptedTranslations:\n",
        "        temporary_reference_inclusion.write(translation.reference)\n",
        "        temporary_output_inclusion.write(translation.translation)\n",
        "\n",
        "    for translation in rejectedTranslations:\n",
        "        temporary_reference_exclusion.write(translation.reference)\n",
        "        temporary_output_exclusion.write(translation.translation)\n",
        "\n",
        "    \n",
        "    temporary_reference_inclusion.close()\n",
        "    temporary_output_inclusion.close()\n",
        "    temporary_reference_exclusion.close()\n",
        "    temporary_output_exclusion.close()\n",
        "\n",
        "    !fairseq-score --sys analysis/temporary_output_inclusion.txt --ref analysis/temporary_reference_inclusion.txt --sacrebleu > analysis/inclusion_result.txt\n",
        "    !fairseq-score --sys analysis/temporary_output_exclusion.txt --ref analysis/temporary_reference_exclusion.txt --sacrebleu > analysis/exclusion_result.txt\n",
        "\n",
        "    temporary_inclusion_result = open(\"analysis/inclusion_result.txt\")\n",
        "    temporary_exclusion_result = open(\"analysis/exclusion_result.txt\")\n",
        "    inclusion_result_string = [line for line in temporary_inclusion_result][1].split(\" \")[2]\n",
        "    exclusion_result_string = [line for line in temporary_exclusion_result][1].split(\" \")[2]\n",
        "\n",
        "    return float(exclusion_result_string), float(inclusion_result_string)\n",
        "\n",
        "\n",
        "def readTranslations(sentenceFile, featureArray):\n",
        "    translations = []\n",
        "    temp = []\n",
        "    index = 0\n",
        "    for line in sentenceFile:\n",
        "        if len(temp) < 3:\n",
        "            temp.append(line)\n",
        "        else:\n",
        "            score = float(line.strip(\"\\n\"))\n",
        "            translations.append(Translation(temp[0], temp[1], temp[2], score, featureArray[index]))\n",
        "            index += 1\n",
        "            temp = []\n",
        "    \n",
        "    return translations\n",
        "\n",
        "def getTrainTestSets(trainTranslations, testTranslations, threshold):\n",
        "    trainFeatures = []\n",
        "    trainY = []\n",
        "    testFeatures = []\n",
        "    testY = []\n",
        "\n",
        "    for translation in trainTranslations:\n",
        "        trainFeatures.append(translation.features)\n",
        "        if translation.score < threshold:\n",
        "            trainY.append(0)\n",
        "        else:\n",
        "            trainY.append(1)\n",
        "    \n",
        "    for translation in testTranslations:\n",
        "        testFeatures.append(translation.features)\n",
        "        if translation.score < threshold:\n",
        "            testY.append(0)\n",
        "        else:\n",
        "            testY.append(1)\n",
        "\n",
        "    return trainFeatures, trainY, testFeatures, testY\n",
        "\n",
        "featuresUsed = [0, 1, 2, 3, 5, 6, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20]\n",
        "# featuresUsed = [0]\n",
        "\n",
        "trainset = \"valid\"\n",
        "testset = \"test\"\n",
        "bleuThresholdTrain = 10\n",
        "bleuThresholdTest = 10\n",
        "\n",
        "trainFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/features.txt\")\n",
        "testFeatures = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/features.txt\")\n",
        "trainLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/result.txt\")\n",
        "testLabels = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/result.txt\")\n",
        "\n",
        "trainSentences = open(\"ClassificationDataset/\"+str(bleuThresholdTrain)+\"BLEU/\"+trainset+\"/sentences.txt\")\n",
        "testSentences = open(\"ClassificationDataset/\"+str(bleuThresholdTest)+\"BLEU/\"+testset+\"/sentences.txt\")\n",
        "\n",
        "\n",
        "featuresTrain, _ = datasetReader(trainFeatures, trainLabels)\n",
        "featuresTest, _ = datasetReader(testFeatures, testLabels)\n",
        "\n",
        "featuresTrain = [[row[i] for i in featuresUsed] for row in featuresTrain]\n",
        "featuresTest = [[row[i] for i in featuresUsed] for row in featuresTest]\n",
        "\n",
        "trainTranslations = readTranslations(trainSentences, featuresTrain)\n",
        "testTranslations = readTranslations(testSentences, featuresTest)\n",
        "\n",
        "BLEUThresholds = np.linspace(4, 25, 10).tolist()\n",
        "\n",
        "acceptedScores = []\n",
        "acceptedFraction = []\n",
        "\n",
        "\n",
        "for threshold in BLEUThresholds:\n",
        "    trainFeatures, trainY, testFeatures, testY = getTrainTestSets(trainTranslations, testTranslations, threshold)\n",
        "\n",
        "    clf = trainCustomEnsemble(trainFeatures, trainY)\n",
        "\n",
        "    predictions = clf.predict(testFeatures)\n",
        "    acceptedTranslations = np.array(testTranslations)[np.array(predictions) > 0]\n",
        "    rejectedTranslations = np.array(testTranslations)[np.array(predictions) < 1]\n",
        "    rejectedScore, acceptedScore = compute_excluded_included_score(acceptedTranslations, rejectedTranslations)\n",
        "    acceptedScores.append(acceptedScore)\n",
        "    acceptedFraction.append(float(len(acceptedTranslations))/float(len(predictions)))\n",
        "\n",
        "plt.xlabel('Fraction Above Threshold') \n",
        "plt.ylabel('BLEU score (corpus)') \n",
        "plt.title('Random Forest Analysis') \n",
        "\n",
        "r = random.random()\n",
        "b = random.random()\n",
        "g = random.random()\n",
        "c = (r, g, b)\n",
        "plt.scatter(acceptedFraction, acceptedScores, label = \"Random Forest Analysis\", color=c)\n",
        "\n",
        "\n",
        "print('AUC for incuded fraction: {}'.format(auc(acceptedFraction, acceptedScores)))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training custom ensemble\n",
            "Training custom ensemble\n",
            "Training custom ensemble\n",
            "Training custom ensemble\n",
            "Training custom ensemble\n",
            "Training custom ensemble\n",
            "Training custom ensemble\n",
            "Training custom ensemble\n",
            "Training custom ensemble\n",
            "Training custom ensemble\n",
            "AUC for incuded fraction: 11.784400352733687\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}